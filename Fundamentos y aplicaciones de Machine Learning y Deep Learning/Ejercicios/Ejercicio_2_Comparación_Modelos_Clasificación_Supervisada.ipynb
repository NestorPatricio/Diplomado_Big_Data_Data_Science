{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.3.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEA4r6FfIRE5"
      },
      "source": [
        "# Ejercicio 2 - Mejoras y Comparación de Modelos de Clasificación\n",
        "\n",
        "Este ejercicio considera completar acciones para mejorar el rendimiento de modelos de clasificación supervisada, (similar al ejercicio 1), pero se enfoca en realizar un análisis comparativo entre diferentes modelos utilizados para entender las ventajas/desventajas de unos y otros sobre este dataset y sus condiciones.\n",
        "\n",
        "## Contexto: Análisis de éxito en campaña de marketing\n",
        "\n",
        "Fuente: https://archive.ics.uci.edu/ml/datasets/Bank+Marketing\n",
        "\n",
        "El foco está en la implementación de varios clasificadores para predecir el valor de un atributo de interés, desde un *dataset* de información de un resultados de personas contactadas por una campaña de marketing y que compraron la oferta (atributo \"OK\"), con cerca de 41.200 registros de personas contactadas.\n",
        "\n",
        "Este conjunto de datos (abierto para este tipo de usos instruccionales), consiste en 20 atributos y 1 clase de etiquetas (totalizando 21 columnas) y corresponde a los datos de una campaña telefónica a diversos clientes en Portugal, ofreciéndoles la compra de un producto bancario. En varios casos, un cliente fue contactado varias veces antes de aceptar el depósito a plazo ofrecido por la campaña (OK = yes).\n",
        "\n",
        "Algunos de los atributos relevantes son (combinando atributos categóricos, con numéricos):\n",
        "* **Datos personales**: Edad, Ocupación, Estado Civil, Nivel de Educación.\n",
        "* **Datos financieros**: Su casa tiene crédito hipotecario, default: si el crédito ha caído en quiebra; tiene un crédito de consumo.\n",
        "* **Datos de contactos de la campaña actual**: Tipo de Comunicación (celular o teléfono fijo); Mes del último contacto; Día de la semana del contacto; duración de la llamada (segundos); Contacto: N° de contactos durante la campaña; DíasAtrás: días transcurridos desde último contacto; Resultado: resultado de la última llamada (falló, no-existe, éxito)\n",
        "* **Datos socioeconómicos**: EmpTasaVar: tasa de variación de empleabilidad; IPC: índice de precios consumidor mensual; ICC: índice de confianza consumidor mensual; Euribor3m: tasa euribor de 3 meses indicador diario; NumEmpleados: cantidad de gente empleada, en indicador trimestral.\n",
        "\n",
        "Esta adaptación en particular, por el equipo de R:Solver (RSolver.com), enfrenta diferentes objetivos de aprendizaje dentro de los cursos de Big Data y Machine Learning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhFF63rsMfbI"
      },
      "source": [
        "## Instrucciones Generales\n",
        "En este caso, se busca entender el comportamiento y desempeño de diferentes modelos de clasificación sobre este conjunto de datos, para predecir la variable de interés: **OK**, que servirá para predecir en casos futuros, según los datos de contactabilidad de un cliente, si el cliente aceptará o no contratar el depósito a plazo.\n",
        "\n",
        "La entrega (grupal o individual, según corresponda) se materializa en un informe donde se contestan las preguntas que se indican en las secciones de \"Preguntas\", más adelante. Se puede recurrir a ejercicios de otras fuentes, así como al material de clases.\n",
        "\n",
        "Dentro del informe se puede considerar una tabla de datos de ejecuciones comparadas de los modelos y con diferentes condiciones (balance de clases, proporciones de % entrenamiento-evaluación), apoyando las respuestas a las preguntas correspondientes.\n",
        "\n",
        "La entrega se realiza en forma de un **informe en formato PDF, adjunto por email** utilizando la plantilla de informe que está en http://dcc.rsolver.com/dcc/docs/InformeActividad.docx\n",
        "\n",
        "El informe en formato PDF debe ser subido por sólo uno de los integrantes a la siguiente URL\n",
        "\n",
        "http://aiker.rsolver.com/AIKER/DocUpload.aspx (*)\n",
        "\n",
        "(*)Si hay problemas en la carga, enviar el PDF a rsandova@ing.puc.cl y cc: ayudante@aiker.ai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbsvny1wYwsT"
      },
      "source": [
        "## Paso 1: Instación de las librerías de modelos de clasificación\n",
        "\n",
        "Esto se ejecuta sólo una vez al comienzo de la sesión de cada persona. No se necesita volver a ejecutar con cada nueva prueba del resto de los scripts. Aquí se incluyen liberías para ejecutar todos los modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr8D6ajXY2T9"
      },
      "source": [
        "install.packages('e1071')\n",
        "install.packages('caret')\n",
        "install.packages('rpart')\n",
        "install.packages('rpart.plot')\n",
        "install.packages('randomForest')\n",
        "install.packages('class')\n",
        "install.packages(\"nnet\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso 2: Carga y preprocesamiento de los datos ##\n",
        "\n",
        "A continuación se cargan el conjunto de datos desde la URL de origen. Esta versión preprocesa el dataset, realizando actividades de limpieza de datos, eliminando filas con algún NA y eliminando unas pocas columnas que se determinan como no-relevantes en el desempeño de modelos de clasificación.\n",
        "\n",
        "Adicionalmente, se realiza un balance entre las clases, reduciendo la cantidad de ejemplos de la clase mayoritaria para aproximarse a la otra.\n",
        "\n",
        "Se entiende que con estas acciones de preprocesamiento del dataset, ya se llega en mejores condiciones a este nuevo ejercicio.\n",
        "\n",
        "Este código se puede ejecutar sólo una vez para uso del dataset resultante en los siguientes pasos."
      ],
      "metadata": {
        "id": "qdnM3scrKEgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se declara la URL de dónde obtener los datos\n",
        "theUrlMain <- \"http://www.rsolver.com/dcc/docs/bank-additional-full.csv\"\n",
        "\n",
        "# Se declaran los nombres de las columnas\n",
        "columnas = c(\"Edad\",\"Ocupación\",\"EstadoCivil\",\"Educación\",\"Default\",\"Hipotecario\",\"Consumo\",\"Contacto\",\"Mes\",\"Día\",\n",
        "             \"Duración\",\"NumContactos\",\"DíasAtrás\",\"Previo\",\"ResultadoPrevio\",\n",
        "             \"EmpTasaVar\", \"IPC\", \"ICC\", \"Euribor3m\", \"NumEmpleados\", \"OK\")\n",
        "\n",
        "# Se cargan datos principales a una estructura o dataset (marketing.data), asignando nombres de atributos a las columnas.\n",
        "# Nótese que se incluye la conversión de valores \"unknown\" a \"NA\" para facilitar la gestión vacíos más adelante.\n",
        "marketing.data <- read.table(file = theUrlMain, header = TRUE, sep = \";\", col.names = columnas, na.strings=c(\"unknown\",\"NA\"))\n",
        "\n",
        "# Se eliminan aquellos atributos que no aportan en el desempeño de los modelos\n",
        "# Esto se determinó en un trabajo previo, fuera de esta actividad\n",
        "marketing.data$Default <- NULL\n",
        "marketing.data$DíasAtrás <- NULL\n",
        "marketing.data$Previo <- NULL\n",
        "marketing.data$Euribor3m <- NULL\n",
        "\n",
        "# Se eliminan los registros que tienen algún NA (antes: 'unknown')\n",
        "marketing.clean <- na.omit(marketing.data)\n",
        "dim(marketing.clean) # Sólo quedan poco más de 38.000 filas (de las 41.000 originales)\n",
        "\n",
        "# Se muestran las primeras líneas del dataset, incluyendo sólo las columnas que quedaron.\n",
        "head(marketing.clean, 20)\n",
        "dim(marketing.clean)\n",
        "\n",
        "# Aquí se arman dos subconjuntos con los datos de cada una de las dos clases.\n",
        "# Se pueden ver los respectivos tamaños al terminar, evidenciando un desbalance.\n",
        "clean.data.YES <- marketing.clean[marketing.clean$OK == 'yes',]\n",
        "clean.data.NO <- marketing.clean[marketing.clean$OK == 'no',]\n",
        "cat(\"Cantidad de ejemplos por clase\\n\")\n",
        "dim(clean.data.YES) # Este es el conjunto más pequeño con poco más de 4.000 ejemplos\n",
        "dim(clean.data.NO)  # Este es mayoritario con casi 34.000 ejemplos, evidenciando desbalance entre clases\n",
        "\n",
        "# A continuación se realiza un re-balanceo de las clases (random subsampling),\n",
        "# que consiste en reducir la cantidad de ejemplos de la clase más masiva, para acercarla a la minoritaria.\n",
        "balance_ratio <- 1.2 # Se elige un balanceo de 20% más de ejemplos de la clase negativa que la positiva\n",
        "\n",
        "clean.subdata.YES <- clean.data.YES  # No se aplica sample(): se usan todos los ejemplos de la clase OK (que es la que tiene menos ejemplos)\n",
        "clean.subdata.NO <- clean.data.NO[sample(nrow(clean.data.NO), balance_ratio*dim(clean.data.YES)[1]), ] # Se elige un subconjunto de los NO\n",
        "\n",
        "# Muestra cantidad de ejemplos contenidos en cada subconjunto\n",
        "cat(\"Cantidad de ejemplos por clase luego del balance entre clases\\n\")\n",
        "dim(clean.subdata.YES)\n",
        "dim(clean.subdata.NO)\n",
        "\n",
        "# Se juntan para el conjunto de referencia, ahora más balanceado\n",
        "clean.subdata <- rbind(clean.subdata.YES, clean.subdata.NO)\n",
        "\n",
        "summary(clean.subdata)\n"
      ],
      "metadata": {
        "id": "qWhjKB9AKc_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX9lYmofTUJx"
      },
      "source": [
        "## Ejercicio 1: Preparación conjuntos de entrenamiento y evaluación\n",
        "\n",
        "En este caso, lo importante es considerar que **es posible cambiar la proporción de datos de entrenamiento y test** viendo el efecto que tiene en el desempeño de los modelos (del ejercicio 2: RandomForest, SVM, NB), viendo que alguno o varios de los modelos entregan mejores resultados considerando lo que más puede interesar, entre Accuracy, Sensitivity, Specificity.\n",
        "\n",
        "**Pregunta 1** (1.5 puntos)\n",
        "\n",
        "¿Cuál es la proporción entrenamiento/test que logra mejor desempeño y con cuál de los modelos entre RandomForest, SVM, NB?\n",
        "\n",
        "El objetivo es probar varias combinaciones cambiando la proporción de datos. Preliminarmente 4 combinaciones, desde 60%/40% hasta 90%/10%, pero cada alumno tene la libertad de probar otras combinaciones complementarias. Según los resultados de la ejecución de todos los modelos de clasificación más adelante, determinar y explicitar cuál es la proporción que logra mejores resultados o desmpeño de clasificación y cuál es la influencia del cambio de proporción de entrenamiento/test. Particularmente se espera que los alumnos determinen cómo se elige el mejor modelo (comparando Sensitivity, Specificity, Accuracy).\n",
        "\n",
        "Se pide documentar en una tabla todas las combinaciones, viendo los indicadores de desempeño más relevantes: Accuracy, Sensitivity, Specificity, **determinando cuál combinación da mejores resultados para cuál de los modelos** (RandomForest, NB, SVM), considerando que el desempeño se logra por maximizar el desempeño de la predicción de YES, además de un buen modelo balanceado (accuracy).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bREGDVWofFwH"
      },
      "source": [
        "# Primero, se saca una copia del dataset para trabajar sin modificar el original\n",
        "# Esto permite hacer más modificaciones y correr este código varias veces sin alterar clean.subdata\n",
        "working.data <- clean.subdata\n",
        "\n",
        "# EJERCICIO 1\n",
        "# Ahora se configuran los conjuntos de entrenamiento y testing en una proporción\n",
        "# (por ej: 0.70 = 70% para training y el resto para evaluación o testing)\n",
        "# Se pide probar diferentes combinaciones (60/40, 70/30, 80/20, 90/10)\n",
        "# hasta determinar cuál es la mejor en cuál de los modelos.\n",
        "ratio = sample(1:nrow(working.data), size = 0.70*nrow(working.data))\n",
        "training.data = working.data[ratio,]\n",
        "testing.data = working.data[-ratio,]\n",
        "\n",
        "# Se comparan los tamaños de ejemplos para entrenamiento y evaluación.\n",
        "dim(training.data)\n",
        "dim(testing.data)\n",
        "\n",
        "head(training.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82LcskQOnNmH"
      },
      "source": [
        "## Ejercicio 2: Comparación de desempeño de modelos de clasificación y su explicación\n",
        "\n",
        "Habiendo definido los conjuntos de entrenamiento y de test, a continuación se ejecutan unos modelos de clasificación: un RandomForest, un Naive Bayes, y un Support Vector Machine. Cada uno obtiene sus resultados, mostrando sus precisiones en desempeño. No es necesario modificar estos bloques de código. Basta con hacer los cambios en la parte del ejercicio 1 (proporción entrenamiento/test) y volver a ejecutar estos modelos para evaluar su desempeño.\n",
        "\n",
        "Una vez completado el ejercicio 1 anterior (habiendo quedado con una ejecución de mejor desempeño y habiendo realizado la comparación de los indicadores), se pueden contestar las preguntas a continuación, que se centran en interpretar y analizar comparativamente del desempeño de estos modelos.\n",
        "\n",
        "**Pregunta 2.1** (1 punto)\n",
        "\n",
        "Viendo que un balance de clases de 1.2 (sólo un 20% más de ejemplos de la clase negativa sobre la positiva), donde reduce notoriamente la cantidad de ejemplos de la clase negativa, ¿por qué considera que se logra esa mejoría, a pesar de eliminar de entrenamiento y evaluación esa cantidad de ejemplos originales? (Justifique con claridad, según lo que se conoce sobre la forma en que se entrenan los modelos).\n",
        "\n",
        "**Pregunta 2.2** (1 punto)\n",
        "\n",
        "Habiendo determinado en el ejercicio 1 cuál es el modelo que tiene mejor desempeño entre todos, con una mejor proporción de entrenamiento/test ¿qué características del modelo apoyan su mejor desempeño sobre los otros modelos, aunque la diferencia haya sido menor? (Justifique con claridad, según lo que se conoce sobre las características particulares de los modelos y por qué ese modelo muestra mejor desempeño que los otros).\n",
        "\n",
        "Recuerde que sólo se comparan los 3 modelos a continuación.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM91HnJqh7D6"
      },
      "source": [
        "**Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUkbhaJ0CGDm"
      },
      "source": [
        "library(randomForest)\n",
        "library(caret)\n",
        "\n",
        "# Random Forest\n",
        "RF_model <- randomForest(as.factor(OK) ~ ., data=training.data, method=\"class\")\n",
        "RF_predict <- predict(RF_model, testing.data, type = \"class\")\n",
        "confusionMatrix(RF_predict, as.factor(testing.data$OK), positive = 'yes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgdCy3jOmM61"
      },
      "source": [
        "**Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKfTuGGxEo-f"
      },
      "source": [
        "library(e1071)\n",
        "\n",
        "# Naive Bayes\n",
        "NB_model <- naiveBayes(as.factor(OK) ~ ., data=training.data)\n",
        "NB_predict <- predict(NB_model, testing.data, type = \"class\")\n",
        "confusionMatrix(NB_predict, as.factor(testing.data$OK), positive = 'yes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Support Vector Machine**"
      ],
      "metadata": {
        "id": "FJPXgCYIYU78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "library(e1071)\n",
        "\n",
        "# Support Vector Machine (NOTA: toma algunos minutos su ejecución)\n",
        "SVM_model <- svm(as.factor(OK) ~ ., data = training.data, cost = 10, scale = FALSE)\n",
        "SVM_predict <- predict(SVM_model, testing.data, type = \"class\")\n",
        "confusionMatrix(SVM_predict, as.factor(testing.data$OK), positive = 'yes')\n"
      ],
      "metadata": {
        "id": "p_46U2nQYT3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 3: Implementación de una Red Neuronal\n",
        "A continuación se declara, entrena y evalúa un modelo de Red Neuronal. Esta primera declaración viene con una configuración inicial, que se podrá modificar para ver posibles mejoras en el desempeño de esta red.\n",
        "\n",
        "Esta configuración considera lo siguiente:\n",
        "\n",
        "*     **Nótese que sólo se utilizan algunos atributos del dataset**, que vienen en la declaración de la fórmula (1er argumento) de nnet(). Se pueden eliminar algunos y ver si mejora el desempeño.\n",
        "\n",
        "*     Se usa una única capa escondida o intermedia. Su cantidad de nodos está dada por el atributo 'size'. Se puede agrandar o reducir para ver posibles mejoras.\n",
        "\n",
        "*     La cantidad de iteraciones para mejorar el entrenamiento se da por el atributo 'maxit'. Se puede aumentar, esperando mejorar el desempeño.\n",
        "\n",
        "*     El atributo 'maxNWts' limita el tamaño interno de la red, que dadas las restricciones de capacidad de procesamiento que entrega Google Colab, conviene acotarlo, para evitar sobrepasar la memora y tener una ejecución fallida. No es necesario modificar este atributo.\n",
        "\n",
        "Hay otros atributos posibles de analizar y modificar en https://www.rdocumentation.org/packages/nnet/versions/7.3-14/topics/nnet. Nótese que la configuración por defecto usa una activación logística, pero es posible aplicar softmax o linout, pero eso requiere de parámetros adicionales.\n",
        "\n",
        "Ojo/recomendación: dada la naturaleza aleatoria del comportamiento del entrenamiento, en ocasiones la red neuronal no entrega resultados para la clase menos representada y genera un error. En cuyo caso, sólo basta con volver a ejecutar el código, para que - aleatoriamente - logre dar resultados en dicha clase.\n",
        "\n",
        "**Ejercicio 3:**\n",
        "\n",
        "Probar diferentes versiones del modelo, cambiando:\n",
        "*     Los atributos considerados. Por simplicidad se recomienda sólo eliminar algunos de la lista original, para ver si en alguna ejecución esa eliminación genera mejores resultados.\n",
        "*     La cantidad de nodos de la capa escondida (size).\n",
        "*     La cantidad de iteraciones (maxit).\n",
        "\n",
        "Por simplicidad de este ejercicio, se recomienda sólo probar hasta 8 combinaciones de cada uno de los 3 elementos a cambiar. Se pueden elegir los valores de esos cambios y documentar en una tabla de ejecuciones comparadas para contestar la pregunta 3.1.\n",
        "\n",
        "**Preg 3.1** (1.8 puntos): ¿Cuáles son los parámetros de ejecución del modelo que dan el mejor desempeño de la Red Neuronal?\n",
        "\n",
        "**Preg 3.2** (0.7 puntos): ¿Logra superar al mejor modelo de los primeros 3 modelos? ¿Por qué considera que si o no y qué caracteristica distinta entre estos 2 modelos hace la diferencia? (En cualquier caso, se pide una posible y teórica explicación de por qué es mejor/peor que ese otro modelo.)"
      ],
      "metadata": {
        "id": "C0lOmoAidQun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "library(nnet)\n",
        "\n",
        "# Red Neuronal\n",
        "# Lista original de atributos: Edad+Ocupación+EstadoCivil+Educación+Duración+NumContactos+NumContactos+EmpTasaVar+NumEmpleados\n",
        "NN_model <- nnet(as.factor(OK) ~ Edad+Ocupación+EstadoCivil+Educación+Duración+NumContactos+NumContactos+EmpTasaVar+NumEmpleados,\n",
        "                  data=training.data, size=25, maxit=3000, MaxNWts=10000)\n",
        "NN_predict <- predict(NN_model, testing.data, type=\"class\")\n",
        "\n",
        "# A continuación se muestra el resultado de evaluación\n",
        "cat(\"Resultados Red Neuronal\\n\")\n",
        "confTable <- table(NN_predict, testing.data$OK)\n",
        "confTable\n",
        "\n",
        "accuracy <- (confTable[1,1] + confTable[2,2]) / dim(testing.data)[1]\n",
        "cat(\"\\nAccuracy:    \", accuracy)\n",
        "\n",
        "sensitivity <- confTable[1,1] / (confTable[1,1] + confTable[1,2])\n",
        "cat(\"\\nSensitivity: \", sensitivity)\n",
        "\n",
        "specificity <- confTable[2,2] / (confTable[2,1] + confTable[2,2])\n",
        "cat(\"\\nSpecificity: \", specificity)\n"
      ],
      "metadata": {
        "id": "WkQR7kxddP_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEKlHstgEOG1"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "**Complemento: Ejercicio de comprobación manual**\n",
        "\n",
        "\n",
        "Para verificar que alguno de los modelos realmente predice correctamente, se comprueba con los datos de una persona en particular, pidiendo la predicción al modelo. A continuación hay dos ejemplos, que se pueden modificar para ver su resultado, cambiando valores y también, cambiando el modelo a utilizar en la predicción. No se necesita modificar, ni comentar esta parte en la entrega, sino que se entrega como complemento para quienes tengan el interés de ver cómo se aplica un modelo entrenado en un contexto práctico (en producción)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZaYo2bG58aA"
      },
      "source": [
        "# Ejemplo 1: La predicción debería ser \"YES\"\n",
        "sample_x <- clean.subdata[1,]\n",
        "sample_x[1,1] <- 32       # Edad\n",
        "sample_x[1,2] <- 'admin.' # Ocupación\n",
        "sample_x[1,3] <- 'single' # EstadoCivil\n",
        "sample_x[1,4] <- 'university.degree'  # Educación\n",
        "sample_x\n",
        "\n",
        "prediction <- predict(RF_model, sample_x)\n",
        "prediction\n",
        "\n",
        "\n",
        "# Ejemplo 2: La predicción debería ser \"NO\"\n",
        "sample_x2 <- clean.subdata[1,]\n",
        "sample_x2[1,10] <- 10   # Duración\n",
        "sample_x2\n",
        "\n",
        "prediction <- predict(RF_model, sample_x2)\n",
        "prediction\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}