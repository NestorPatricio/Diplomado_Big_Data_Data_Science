{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.3.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEA4r6FfIRE5"
      },
      "source": [
        "# Ejercicio Complementario 3 - Reducción Dimensional con PCA\n",
        "\n",
        "Este ejercicio se centra en el análisis de la relevancia de diferentes atributos de un conjunto de datos de campañas de marketing de productos bancarios, buscando la reducción de los atributos, dejando los esenciales para un posterior modelo predictivo.\n",
        "\n",
        "## Contexto: Análisis de éxito en campaña de marketing\n",
        "\n",
        "Fuente: https://archive.ics.uci.edu/ml/datasets/Bank+Marketing\n",
        "\n",
        "El foco está en la implementación de una red neuronal para clasificación y la comparación de su desempeño con otro modelo de clasificación para predicir el valor de un atributo, desde un *dataset* de información de un resultados de personas contactadas por una campaña de marketing y que compraron la oferta (atributo \"OK\"), con cerca de 41.200 registros de personas contactadas.\n",
        "\n",
        "Este conjunto de datos (abierto para este tipo de usos instruccionales), consiste en 20 atributos y 1 clase de etiquetas (totalizando 21 columnas) y corresponde a los datos de una campaña telefónica a diversos clientes en Portugal, ofreciéndoles la compra de un producto bancario. En varios casos, un cliente fue contactado varias veces antes de aceptar el el depósito a plazo ofrecido por la campaña (OK = yes).\n",
        "\n",
        "Algunos de los atributos relevantes son (combinando atributos categóricos, con numéricos):\n",
        "* **Datos personales**: Edad, Ocupación, Estado Civil, Nivel de Educación.\n",
        "* **Datos financieros**: Su casa tiene crédito hipotecario, default: si el crédito ha caído en quiebra; tiene un crédito de consumo.\n",
        "* **Datos de contactos de la campaña actual**: Tipo de Comunicación (celular o teléfono fijo); Mes del último contacto; Día de la semana del contacto; duración de la llamada (segundos); Contacto: N° de contactos durante la campaña; DíasAtrás: días transcurridos desde último contacto; Resultado: resultado de la última llamada (falló, no-existe, éxito)\n",
        "* **Datos socioeconómicos**: EmpTasaVar: tasa de variación de empleabilidad; IPC: índice de precios consumidor mensual; ICC: índice de confianza consumidor mensual; Euribor3m: tasa euribor de 3 meses indicador diario; NumEmpleados: cantidad de gente empleada, en indicador trimestral.\n",
        "\n",
        "Esta adaptación en particular, por el equipo de R:Solver (RSolver.com), enfrenta diferentes objetivos de aprendizaje dentro de los cursos de Big Data y Machine Learning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhFF63rsMfbI"
      },
      "source": [
        "## Instrucciones Generales\n",
        "En este caso, se busca entender el comportamiento y desempeño de un modelo de clasificación sobre una versión compactada o de dimensión reducidad del dataet original, para predecir la variable de interés: **OK**, que servirá para predecir en casos futuros, según los datos de contactabilidad de un cliente, si el cliente aceptará o no contratar el depósito a plazo. Por ello, se recomienda seguir los pasos y buscar la información para contestar las preguntas.\n",
        "\n",
        "**Este ejercicio es sin nota: no se envía informe**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbsvny1wYwsT"
      },
      "source": [
        "## Paso 0: Instalar las librerías de modelos y funciones necesarias\n",
        "\n",
        "Esto se ejecuta sólo una vez al comienzo de la sesión de cada persona. No se necesita volver a ejecutar con cada nueva prueba del resto de los scripts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr8D6ajXY2T9"
      },
      "source": [
        "install.packages('e1071')\n",
        "install.packages('caret')\n",
        "install.packages('randomForest')\n",
        "install.packages('mass')\n",
        "install.packages('ggfortify')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q3bYb0RM5bx"
      },
      "source": [
        "## Paso 1: Carga de los datos\n",
        "\n",
        "La siguiente celda de código, carga los datos desde la URL de origen y luego muestra un encabezado con las primeras filas del dataset, para demostrar la disponibilidad de los datos. Nótese que quedan dos datasets: marketing.reduced tiene los datos originales, menos algunas columnas y mejor balanceado en clases, y marketing.pca queda para utilizar en el análisis PCA.\n",
        "\n",
        "Esto también puede ser ejecutado una sola vez, si es conveniente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIIKPnj-IRE8"
      },
      "source": [
        "# Se declara la URL de dónde obtener los datos\n",
        "theUrlMain <- \"http://www.rsolver.com/dcc/docs/bank-additional-full-numbers.csv\"\n",
        "\n",
        "# Se declaran los nombres de las columnas\n",
        "columnas = c(\"Edad\",\"Ocupación\",\"EstadoCivil\",\"Educación\",\"Default\",\"Hipotecario\",\"Consumo\",\"Contacto\",\"Mes\",\"Día\",\n",
        "             \"Duración\",\"NumContactos\",\"DíasAtrás\",\"Previo\",\"ResultadoPrevio\", \"EmpTasaVar\", \"IPC\", \"ICC\", \"Euribor3m\", \"NumEmpleados\", \"OK\")\n",
        "\n",
        "# Se cargan datos principales a una estructura (marketing.data), asignando nombres de atributos a las columnas\n",
        "marketing.data <- read.table(file = theUrlMain, header = TRUE, sep = \";\", col.names = columnas, na.strings = c(\"unknown\",\"NA\"))\n",
        "\n",
        "# Se eliminan los registros que tienen algún NA (unknown)\n",
        "marketing.clean <- na.omit(marketing.data) # Sólo quedan poco más de 30.000 filas (de las 41.000 originales)\n",
        "\n",
        "# Aquí se arman dos subconjuntos con los datos de cada una de las dos clases.\n",
        "# Se pueden ver los respectivos tamaños al terminar, evidenciando un desbalance.\n",
        "clean.data.YES <- marketing.clean[marketing.clean$OK == 1,]\n",
        "clean.data.NO <- marketing.clean[marketing.clean$OK == 0,]\n",
        "dim(clean.data.YES) # Se ve que este es el conjunto más pequeño\n",
        "dim(clean.data.NO)\n",
        "\n",
        "# Se balancean las clases para entrenar: se busca acercar la cantidad de ejemplos positivos, con los negativos.\n",
        "# Para esto se puede definir la cantidad de ejemplos de la clase más abundante (NO)\n",
        "# en una proporción (balance_ratio) de la cantidad de registros de la clase menos abundante (YES)\n",
        "# balance_ratio = 1.0 implica la misma cantidad para NO y para YES. Según haber probado, se puede elegir un número distinto de 1\n",
        "balance_ratio <- 1.0\n",
        "\n",
        "clean.subdata.YES <- clean.data.YES  # No se aplica sample(): se usan todos los ejemplos de la clase OK (que es la que tiene menos ejemplos)\n",
        "clean.subdata.NO <- clean.data.NO[sample(nrow(clean.data.NO), balance_ratio*dim(clean.data.YES)[1]), ]\n",
        "\n",
        "# Muestra cantidad de ejemplos contenidos en cada subconjunto\n",
        "dim(clean.subdata.YES)\n",
        "dim(clean.subdata.NO)\n",
        "\n",
        "# Se juntan para el conjunto de referencia, ahora más balanceado\n",
        "clean.subdata <- rbind(clean.subdata.YES, clean.subdata.NO)\n",
        "\n",
        "# Se genera un dataset de trabajo (marketing.reduced) que no considera las columnas categóricas,\n",
        "# para trabajar sólo con columnas numéricas\n",
        "marketing.reduced <- clean.subdata\n",
        "marketing.reduced$Default <- NULL\n",
        "marketing.reduced$Ocupación <- NULL\n",
        "marketing.reduced$EstadoCivil <- NULL\n",
        "marketing.reduced$Educación <- NULL\n",
        "marketing.reduced$Contacto <- NULL\n",
        "marketing.reduced$Mes <- NULL\n",
        "marketing.reduced$Día <- NULL\n",
        "marketing.reduced$ResultadoPrevio <- NULL\n",
        "\n",
        "# Nótese la existencia de 2 datasets:\n",
        "# uno con la variable de interés OK (reduced) y el otro sin esa variable (pca)\n",
        "marketing.pca <- marketing.reduced[,1:12]\n",
        "\n",
        "# Se muestran las primeras líneas del dataset, incluyendo nombres asignados a las columnas\n",
        "head(marketing.pca, 10)\n",
        "\n",
        "# Se muestra un resumen de las columnas del dataset, describiendo los datos que se encuentran\n",
        "summary(marketing.reduced)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aw1lpLW0dX1l"
      },
      "source": [
        "## Paso 2: Uso de Random Forest para clasificación de referencia\n",
        "\n",
        "Esta ejecución usa un Random Forest sobre el dataset original, ya balanceado, pero con todas las dimensiones definidas, antes de aplicar PCA, de modo de poder compararlo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiN6Oek3djfR"
      },
      "source": [
        "working.data <- marketing.reduced\n",
        "\n",
        "# Ahora se configuran los conjuntos de entrenamiento y testing en una proporción\n",
        "# (por ej: 0.70 = 70% para training y el resto para evaluación o testing)\n",
        "ratio = sample(1:nrow(working.data), size = 0.70*nrow(working.data))\n",
        "training.data = working.data[ratio,]\n",
        "testing.data = working.data[-ratio,]\n",
        "\n",
        "library(randomForest)\n",
        "library(caret)\n",
        "\n",
        "# Random Forest\n",
        "RF_model <- randomForest(as.factor(OK) ~ ., data=training.data, method=\"class\")\n",
        "RF_predict <- predict(RF_model, testing.data, type = \"class\")\n",
        "confusionMatrix(RF_predict, as.factor(testing.data$OK), positive = '1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1kssYCDO4pC"
      },
      "source": [
        "## Paso 3: Test de relevancia por p-value\n",
        "\n",
        "Aquí es factible observar las variables o atributos con p-value > 0.05, es decir, con relación a un nivel de significancia de 0.05.\n",
        "\n",
        "Entonces, aquellos atributos o variables con un valor mucho menor que 0.05 son consideradas relevantes.\n",
        "\n",
        "**Preguntas a responder**\n",
        "\n",
        "Desde el análisis por relevancia, ¿cuántos y cuáles deberían ser los atributos significativos de considerar un posible mapeo a otras dimensiones (componentes principales)? ¿Por qué?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NahFhqweKhM8"
      },
      "source": [
        "model <- lm(formula = OK ~., data = marketing.reduced)\n",
        "summary(model)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGEaVf3kR9tJ"
      },
      "source": [
        "## Paso 4: Análisis PCA\n",
        "\n",
        "A continuación se calculan los principales componentes desde los datos, gracias a la función prcomp(). En estas líneas, se ejecutan y muestra lo siguiente:\n",
        "\n",
        "*   prcomp(marketing.pca, center = TRUE, scale. = TRUE): construye los componentes principales. center = TRUE los calcula de forma tal que el promedio calza en el centro del modelo. scale. = TRUE realiza una normalización numérica (todos los atributos en la misma escala numérica) antes de realizar el análisis.\n",
        "*   summary(pca_result): muestra el comportamiento numérico de cada uno de los componentes principales (PC) según cada uno de los 14 atributos analizados. Se puede ver que se muestra la desviación estándar, pero más importante, se muestra la proporción de la varianza. Se nota que PC1 tiene una proporción de varianza mayor que el resto.\n",
        "*   plot(pca_result, type='l'): muestra los mismos datos en forma de gráfico lineal, demostrando que el primer PC es el que tiene mayor proporción de varianza comparado con los otros.\n",
        "*   print(pca_result$rotation): muestra la composición o pesos de cada atributo en relación al respectivo PC. Nótense aquellos casos en que los pesos son relativamente equivalentes entre ellos.\n",
        "\n",
        "**Preguntas y Análisis**\n",
        "\n",
        "Dado el análisis de PCA de la sección anterior, ¿cuáles de los PC valdría la pena considerar y - eventualmente - cuáles no, para un nuevo proceso de clasificación supervisada?\n",
        "\n",
        "De aquí se construye el nuevo dataset, para entrenamiento y evaluación, considerando sólo los atributos (PC) que se determine sean significativos, apuntando así, a un proceso de clasificación más confiable, de entrenamiento con menor esuferzo y potencialmente menos propenso al overfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a6Yn8LgBhnx"
      },
      "source": [
        "library(ggfortify)\n",
        "\n",
        "# Se construye el modelo PCA\n",
        "pca_result <- prcomp(marketing.pca, center = TRUE, scale. = TRUE)\n",
        "\n",
        "# Análisis de comportamiento numérico o importancia numérica de cada PC\n",
        "summary(pca_result)\n",
        "\n",
        "# Composición (pesos) de cada PC en relación a los 14 atributos\n",
        "print(pca_result$rotation)\n",
        "\n",
        "# Valores propios de los datos originales\n",
        "print('Eigen Values')\n",
        "eigen(cor(marketing.reduced))$values\n",
        "\n",
        "# Gráfico de línea que muestra la proporción de varianza de cada PC\n",
        "plot(pca_result, type='l')\n",
        "\n",
        "autoplot(pca_result)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX9lYmofTUJx"
      },
      "source": [
        "## Parte 4: Preparación conjuntos de entrenamiento y evaluación\n",
        "\n",
        "El siguiente código prepara los datos para el entrenamiento y evaluación. Se pueden probar diferentes proporciones de entrenamiento vs. evaluación, pero toso están trabajando sobre el dataset reducido en dimensiones, gracias al proceso PCA.\n",
        "\n",
        "**Pregunta a responder y aplicar**\n",
        "\n",
        "¿Cuáles deberían ser los PC a mantener en el dataset y que den buenos resultados en un modelo entrenado?\n",
        "\n",
        "Nótese que cualquier reducción de las 13 columnas originales implica un menor tiempo de entrenamiento del modelo, pero no necesariamente mejor desempeño."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V55CGwB_bPOJ"
      },
      "source": [
        "\n",
        "# Proporción Training/Testing. Por ej: 0.75 = 75% entrenamiento y 25% validación\n",
        "ratio = sample(1:nrow(marketing.reduced), size = 0.75*nrow(marketing.reduced))\n",
        "trainingSet = marketing.reduced[ratio,]\n",
        "testingSet = marketing.reduced[-ratio,]\n",
        "\n",
        "# Aquí se construyen los nuevos training y testing set, pero sólo con datos mapeados de los PCA\n",
        "trSet <- predict(pca_result, trainingSet)\n",
        "trSet <- data.frame(trSet, trainingSet$OK)\n",
        "teSet <- predict(pca_result, testingSet)\n",
        "teSet <- data.frame(teSet, testingSet$OK)\n",
        "\n",
        "# Si no todos los PCA son relevantes, se pueden dejar sólo aquellos más influyentes.\n",
        "# A continuación hay instrucciones para eliminar algunos PC, dejando el resto.\n",
        "# Se puede probar y ver qué combinación produce mejores resultados en el RF\n",
        "trSet$PC12 <- NULL\n",
        "trSet$PC11 <- NULL\n",
        "trSet$PC10 <- NULL\n",
        "#trSet$PC9 <- NULL\n",
        "#trSet$PC8 <- NULL\n",
        "#trSet$PC7 <- NULL\n",
        "#trSet$PC6 <- NULL\n",
        "#trSet$PC5 <- NULL\n",
        "#trSet$PC4 <- NULL\n",
        "#trSet$PC3 <- NULL\n",
        "#trSet$PC2 <- NULL\n",
        "\n",
        "teSet$PC12 <- NULL\n",
        "teSet$PC11 <- NULL\n",
        "teSet$PC10 <- NULL\n",
        "#teSet$PC9 <- NULL\n",
        "#teSet$PC8 <- NULL\n",
        "#teSet$PC7 <- NULL\n",
        "#teSet$PC6 <- NULL\n",
        "#teSet$PC5 <- NULL\n",
        "#teSet$PC4 <- NULL\n",
        "#teSet$PC3 <- NULL\n",
        "#teSet$PC2 <- NULL\n",
        "\n",
        "\n",
        "head(trSet, 20)\n",
        "head(teSet, 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82LcskQOnNmH"
      },
      "source": [
        "## Parte 5: Implementación de un modelo de clasificación para ver su desempeño sobre el problema de dimensión reducida\n",
        "\n",
        "Esta sección implementa un Árbol de Decisión, como modelo de clasificación de referencia, recordando que en los ejercicios anteriores, este árbol de decisión logró un Accuracy cercano al 91% en las mejores condiciones. La pregunta que se plantea para este ejercicio completo es si - gracias a una reducción dimensional por medio de PCA - se logra mejorar ese desempeño.\n",
        "\n",
        "**No se necesita modificar esta sección**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM91HnJqh7D6"
      },
      "source": [
        "**Random Forest sobre dataset con PCA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUkbhaJ0CGDm"
      },
      "source": [
        "library(randomForest)\n",
        "library(caret)\n",
        "\n",
        "# Random Forest\n",
        "RF_model <- randomForest(as.factor(trainingSet.OK) ~ ., data=trSet, method=\"class\")\n",
        "RF_predict <- predict(RF_model, teSet, type = \"class\")\n",
        "confusionMatrix(RF_predict, as.factor(teSet$testingSet.OK), positive = '1')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}