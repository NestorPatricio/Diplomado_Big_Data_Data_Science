{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEA4r6FfIRE5"
   },
   "source": [
    "# Ejercicio 2 - Mejoras y Comparación de Modelos de Clasificación\n",
    "\n",
    "Este ejercicio considera completar acciones para mejorar el rendimiento de modelos de clasificación supervisada, (similar al ejercicio 1), pero se enfoca en realizar un análisis comparativo entre diferentes modelos utilizados para entender las ventajas/desventajas de unos y otros sobre este dataset y sus condiciones.\n",
    "\n",
    "## Contexto: Análisis de éxito en campaña de marketing\n",
    "\n",
    "Fuente: https://archive.ics.uci.edu/ml/datasets/Bank+Marketing\n",
    "\n",
    "El foco está en la implementación de varios clasificadores para predecir el valor de un atributo de interés, desde un *dataset* de información de un resultados de personas contactadas por una campaña de marketing y que compraron la oferta (atributo \"OK\"), con cerca de 41.200 registros de personas contactadas.\n",
    "\n",
    "Este conjunto de datos (abierto para este tipo de usos instruccionales), consiste en 20 atributos y 1 clase de etiquetas (totalizando 21 columnas) y corresponde a los datos de una campaña telefónica a diversos clientes en Portugal, ofreciéndoles la compra de un producto bancario. En varios casos, un cliente fue contactado varias veces antes de aceptar el depósito a plazo ofrecido por la campaña (OK = yes).\n",
    "\n",
    "Algunos de los atributos relevantes son (combinando atributos categóricos, con numéricos):\n",
    "* **Datos personales**: Edad, Ocupación, Estado Civil, Nivel de Educación.\n",
    "* **Datos financieros**: Su casa tiene crédito hipotecario, default: si el crédito ha caído en quiebra; tiene un crédito de consumo.\n",
    "* **Datos de contactos de la campaña actual**: Tipo de Comunicación (celular o teléfono fijo); Mes del último contacto; Día de la semana del contacto; duración de la llamada (segundos); Contacto: N° de contactos durante la campaña; DíasAtrás: días transcurridos desde último contacto; Resultado: resultado de la última llamada (falló, no-existe, éxito)\n",
    "* **Datos socioeconómicos**: EmpTasaVar: tasa de variación de empleabilidad; IPC: índice de precios consumidor mensual; ICC: índice de confianza consumidor mensual; Euribor3m: tasa euribor de 3 meses indicador diario; NumEmpleados: cantidad de gente empleada, en indicador trimestral.\n",
    "\n",
    "Esta adaptación en particular, por el equipo de R:Solver (RSolver.com), enfrenta diferentes objetivos de aprendizaje dentro de los cursos de Big Data y Machine Learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhFF63rsMfbI"
   },
   "source": [
    "## Instrucciones Generales\n",
    "En este caso, se busca entender el comportamiento y desempeño de diferentes modelos de clasificación sobre este conjunto de datos, para predecir la variable de interés: **OK**, que servirá para predecir en casos futuros, según los datos de contactabilidad de un cliente, si el cliente aceptará o no contratar el depósito a plazo.\n",
    "\n",
    "La entrega (grupal o individual, según corresponda) se materializa en un informe donde se contestan las preguntas que se indican en las secciones de \"Preguntas\", más adelante. Se puede recurrir a ejercicios de otras fuentes, así como al material de clases.\n",
    "\n",
    "Dentro del informe se puede considerar una tabla de datos de ejecuciones comparadas de los modelos y con diferentes condiciones (balance de clases, proporciones de % entrenamiento-evaluación), apoyando las respuestas a las preguntas correspondientes.\n",
    "\n",
    "La entrega se realiza en forma de un **informe en formato PDF, adjunto por email** utilizando la plantilla de informe que está en http://dcc.rsolver.com/dcc/docs/InformeActividad.docx\n",
    "\n",
    "El informe en formato PDF debe ser subido por sólo uno de los integrantes a la siguiente URL\n",
    "\n",
    "http://aiker.resolver.com/aiker/DocUpload.aspx (*)\n",
    "\n",
    "(*)Si hay problemas en la carga, enviar el PDF a rsandova@ing.puc.cl y cc: ayudante@aiker.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbsvny1wYwsT"
   },
   "source": [
    "## Paso 1: Instación de las librerías de modelos de clasificación\n",
    "\n",
    "Esto se ejecuta sólo una vez al comienzo de la sesión de cada persona. No se necesita volver a ejecutar con cada nueva prueba del resto de los scripts. Aquí se incluyen liberías para ejecutar todos los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "Yr8D6ajXY2T9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/home/nestorprr/R/x86_64-pc-linux-gnu-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "Installing package into ‘/home/nestorprr/R/x86_64-pc-linux-gnu-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "Installing package into ‘/home/nestorprr/R/x86_64-pc-linux-gnu-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "Installing package into ‘/home/nestorprr/R/x86_64-pc-linux-gnu-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "Installing package into ‘/home/nestorprr/R/x86_64-pc-linux-gnu-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages('e1071')\n",
    "install.packages('caret')\n",
    "install.packages('randomForest')\n",
    "install.packages('class')\n",
    "install.packages(\"nnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdnM3scrKEgl"
   },
   "source": [
    "##Paso 2: Carga y preprocesamiento de los datos ##\n",
    "\n",
    "A continuación se cargan el conjunto de datos desde la URL de origen. Esta versión preprocesa el dataset, realizando actividades de limpieza de datos, eliminando filas con algún NA y eliminando unas pocas columnas que se determinan como no-relevantes en el desempeño de modelos de clasificación.\n",
    "\n",
    "Adicionalmente, se realiza un balance entre las clases, reduciendo la cantidad de ejemplos de la clase mayoritaria para aproximarse a la otra.\n",
    "\n",
    "Se entiende que con estas acciones de preprocesamiento del dataset, ya se llega en mejores condiciones a este nuevo ejercicio.\n",
    "\n",
    "Este código se puede ejecutar sólo una vez para uso del dataset resultante en los siguientes pasos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cargan las librerías\n",
    "\n",
    "library(randomForest)\n",
    "library(caret)\n",
    "library(e1071)\n",
    "library(nnet)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>38245</li><li>17</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 38245\n",
       "\\item 17\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 38245\n",
       "2. 17\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 38245    17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 20 × 17</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Edad</th><th scope=col>Ocupación</th><th scope=col>EstadoCivil</th><th scope=col>Educación</th><th scope=col>Hipotecario</th><th scope=col>Consumo</th><th scope=col>Contacto</th><th scope=col>Mes</th><th scope=col>Día</th><th scope=col>Duración</th><th scope=col>NumContactos</th><th scope=col>ResultadoPrevio</th><th scope=col>EmpTasaVar</th><th scope=col>IPC</th><th scope=col>ICC</th><th scope=col>NumEmpleados</th><th scope=col>OK</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>56</td><td>housemaid  </td><td>married </td><td>basic.4y           </td><td>no </td><td>no </td><td>telephone</td><td>may</td><td>mon</td><td>261</td><td>1</td><td>nonexistent</td><td>1.1</td><td>93.994</td><td>-36.4</td><td>5191</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>57</td><td>services   </td><td>married </td><td>high.school        </td><td>no </td><td>no </td><td>telephone</td><td>may</td><td>mon</td><td>149</td><td>1</td><td>nonexistent</td><td>1.1</td><td>93.994</td><td>-36.4</td><td>5191</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>37</td><td>services   </td><td>married </td><td>high.school        </td><td>yes</td><td>no </td><td>telephone</td><td>may</td><td>mon</td><td>226</td><td>1</td><td>nonexistent</td><td>1.1</td><td>93.994</td><td>-36.4</td><td>5191</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>40</td><td>admin.     </td><td>married </td><td>basic.6y           </td><td>no </td><td>no </td><td>telephone</td><td>may</td><td>mon</td><td>151</td><td>1</td><td>nonexistent</td><td>1.1</td><td>93.994</td><td>-36.4</td><td>5191</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>56</td><td>services   </td><td>married </td><td>high.school        </td><td>no </td><td>yes</td><td>telephone</td><td>may</td><td>mon</td><td>307</td><td>1</td><td>nonexistent</td><td>1.1</td><td>93.994</td><td>-36.4</td><td>5191</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>45</td><td>services   </td><td>married </td><td>basic.9y           </td><td>no </td><td>no </td><td>telephone</td><td>may</td><td>mon</td><td>198</td><td>1</td><td>nonexistent</td><td>1.1</td><td>93.994</td><td>-36.4</td><td>5191</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>59</td><td>admin.     </td><td>married </td><td>professional.course</td><td>no </td><td>no </td><td>telephone</td><td>may</td><td>mon</td><td>139</td><td>1</td><td>nonexistent</td><td>1.1</td><td>93.994</td><td>-36.4</td><td>5191</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>9</th><td>24</td><td>technician </td><td>single  </td><td>professional.course</td><td>yes</td><td>no </td><td>telephone</td><td>may</td><td>mon</td><td>380</td><td>1</td><td>nonexistent</td><td>1.1</td><td>93.994</td><td>-36.4</td><td>5191</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>10</th><td>25</td><td>services   </td><td>single  </td><td>high.school        </td><td>yes</td><td>no </td><td>telephone</td><td>may</td><td>mon</td><td> 50</td><td>1</td><td>nonexistent</td><td>1.1</td><td>93.994</td><td>-36.4</td><td>5191</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>12</th><td>25</td><td>services   </td><td>single  </td><td>high.school        </td><td>yes</td><td>no </td><td>telephone</td><td>may</td><td>mon</td><td>222</td><td>1</td><td>nonexistent</td><td>1.1</td><td>93.994</td><td>-36.4</td><td>5191</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>13</th><td>29</td><td>blue-collar</td><td>single  </td><td>high.school        </td><td>no </td><td>yes</td><td>telephone</td><td>may</td><td>mon</td><td>137</td><td>1</td><td>nonexistent</td><td>1.1</td><td>93.994</td><td>-36.4</td><td>5191</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>14</th><td>57</td><td>housemaid  </td><td>divorced</td><td>basic.4y           </td><td>yes</td><td>no </td><td>telephone</td><td>may</td><td>mon</td><td>293</td><td>1</td><td>nonexistent</td><td>1.1</td><td>93.994</td><td>-36.4</td><td>5191</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>15</th><td>35</td><td>blue-collar</td><td>married </td><td>basic.6y           </td><td>yes</td><td>no </td><td>telephone</td><td>may</td><td>mon</td><td>146</td><td>1</td><td>nonexistent</td><td>1.1</td><td>93.994</td><td>-36.4</td><td>5191</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>16</th><td>54</td><td>retired    </td><td>married </td><td>basic.9y           </td><td>yes</td><td>yes</td><td>telephone</td><td>may</td><td>mon</td><td>174</td><td>1</td><td>nonexistent</td><td>1.1</td><td>93.994</td><td>-36.4</td><td>5191</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>17</th><td>35</td><td>blue-collar</td><td>married </td><td>basic.6y           </td><td>yes</td><td>no </td><td>telephone</td><td>may</td><td>mon</td><td>312</td><td>1</td><td>nonexistent</td><td>1.1</td><td>93.994</td><td>-36.4</td><td>5191</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>18</th><td>46</td><td>blue-collar</td><td>married </td><td>basic.6y           </td><td>yes</td><td>yes</td><td>telephone</td><td>may</td><td>mon</td><td>440</td><td>1</td><td>nonexistent</td><td>1.1</td><td>93.994</td><td>-36.4</td><td>5191</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>19</th><td>50</td><td>blue-collar</td><td>married </td><td>basic.9y           </td><td>yes</td><td>yes</td><td>telephone</td><td>may</td><td>mon</td><td>353</td><td>1</td><td>nonexistent</td><td>1.1</td><td>93.994</td><td>-36.4</td><td>5191</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>20</th><td>39</td><td>management </td><td>single  </td><td>basic.9y           </td><td>no </td><td>no </td><td>telephone</td><td>may</td><td>mon</td><td>195</td><td>1</td><td>nonexistent</td><td>1.1</td><td>93.994</td><td>-36.4</td><td>5191</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>21</th><td>30</td><td>unemployed </td><td>married </td><td>high.school        </td><td>no </td><td>no </td><td>telephone</td><td>may</td><td>mon</td><td> 38</td><td>1</td><td>nonexistent</td><td>1.1</td><td>93.994</td><td>-36.4</td><td>5191</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>22</th><td>55</td><td>blue-collar</td><td>married </td><td>basic.4y           </td><td>yes</td><td>no </td><td>telephone</td><td>may</td><td>mon</td><td>262</td><td>1</td><td>nonexistent</td><td>1.1</td><td>93.994</td><td>-36.4</td><td>5191</td><td>no</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 20 × 17\n",
       "\\begin{tabular}{r|lllllllllllllllll}\n",
       "  & Edad & Ocupación & EstadoCivil & Educación & Hipotecario & Consumo & Contacto & Mes & Día & Duración & NumContactos & ResultadoPrevio & EmpTasaVar & IPC & ICC & NumEmpleados & OK\\\\\n",
       "  & <int> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <int> & <int> & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & 56 & housemaid   & married  & basic.4y            & no  & no  & telephone & may & mon & 261 & 1 & nonexistent & 1.1 & 93.994 & -36.4 & 5191 & no\\\\\n",
       "\t2 & 57 & services    & married  & high.school         & no  & no  & telephone & may & mon & 149 & 1 & nonexistent & 1.1 & 93.994 & -36.4 & 5191 & no\\\\\n",
       "\t3 & 37 & services    & married  & high.school         & yes & no  & telephone & may & mon & 226 & 1 & nonexistent & 1.1 & 93.994 & -36.4 & 5191 & no\\\\\n",
       "\t4 & 40 & admin.      & married  & basic.6y            & no  & no  & telephone & may & mon & 151 & 1 & nonexistent & 1.1 & 93.994 & -36.4 & 5191 & no\\\\\n",
       "\t5 & 56 & services    & married  & high.school         & no  & yes & telephone & may & mon & 307 & 1 & nonexistent & 1.1 & 93.994 & -36.4 & 5191 & no\\\\\n",
       "\t6 & 45 & services    & married  & basic.9y            & no  & no  & telephone & may & mon & 198 & 1 & nonexistent & 1.1 & 93.994 & -36.4 & 5191 & no\\\\\n",
       "\t7 & 59 & admin.      & married  & professional.course & no  & no  & telephone & may & mon & 139 & 1 & nonexistent & 1.1 & 93.994 & -36.4 & 5191 & no\\\\\n",
       "\t9 & 24 & technician  & single   & professional.course & yes & no  & telephone & may & mon & 380 & 1 & nonexistent & 1.1 & 93.994 & -36.4 & 5191 & no\\\\\n",
       "\t10 & 25 & services    & single   & high.school         & yes & no  & telephone & may & mon &  50 & 1 & nonexistent & 1.1 & 93.994 & -36.4 & 5191 & no\\\\\n",
       "\t12 & 25 & services    & single   & high.school         & yes & no  & telephone & may & mon & 222 & 1 & nonexistent & 1.1 & 93.994 & -36.4 & 5191 & no\\\\\n",
       "\t13 & 29 & blue-collar & single   & high.school         & no  & yes & telephone & may & mon & 137 & 1 & nonexistent & 1.1 & 93.994 & -36.4 & 5191 & no\\\\\n",
       "\t14 & 57 & housemaid   & divorced & basic.4y            & yes & no  & telephone & may & mon & 293 & 1 & nonexistent & 1.1 & 93.994 & -36.4 & 5191 & no\\\\\n",
       "\t15 & 35 & blue-collar & married  & basic.6y            & yes & no  & telephone & may & mon & 146 & 1 & nonexistent & 1.1 & 93.994 & -36.4 & 5191 & no\\\\\n",
       "\t16 & 54 & retired     & married  & basic.9y            & yes & yes & telephone & may & mon & 174 & 1 & nonexistent & 1.1 & 93.994 & -36.4 & 5191 & no\\\\\n",
       "\t17 & 35 & blue-collar & married  & basic.6y            & yes & no  & telephone & may & mon & 312 & 1 & nonexistent & 1.1 & 93.994 & -36.4 & 5191 & no\\\\\n",
       "\t18 & 46 & blue-collar & married  & basic.6y            & yes & yes & telephone & may & mon & 440 & 1 & nonexistent & 1.1 & 93.994 & -36.4 & 5191 & no\\\\\n",
       "\t19 & 50 & blue-collar & married  & basic.9y            & yes & yes & telephone & may & mon & 353 & 1 & nonexistent & 1.1 & 93.994 & -36.4 & 5191 & no\\\\\n",
       "\t20 & 39 & management  & single   & basic.9y            & no  & no  & telephone & may & mon & 195 & 1 & nonexistent & 1.1 & 93.994 & -36.4 & 5191 & no\\\\\n",
       "\t21 & 30 & unemployed  & married  & high.school         & no  & no  & telephone & may & mon &  38 & 1 & nonexistent & 1.1 & 93.994 & -36.4 & 5191 & no\\\\\n",
       "\t22 & 55 & blue-collar & married  & basic.4y            & yes & no  & telephone & may & mon & 262 & 1 & nonexistent & 1.1 & 93.994 & -36.4 & 5191 & no\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 20 × 17\n",
       "\n",
       "| <!--/--> | Edad &lt;int&gt; | Ocupación &lt;chr&gt; | EstadoCivil &lt;chr&gt; | Educación &lt;chr&gt; | Hipotecario &lt;chr&gt; | Consumo &lt;chr&gt; | Contacto &lt;chr&gt; | Mes &lt;chr&gt; | Día &lt;chr&gt; | Duración &lt;int&gt; | NumContactos &lt;int&gt; | ResultadoPrevio &lt;chr&gt; | EmpTasaVar &lt;dbl&gt; | IPC &lt;dbl&gt; | ICC &lt;dbl&gt; | NumEmpleados &lt;dbl&gt; | OK &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 56 | housemaid   | married  | basic.4y            | no  | no  | telephone | may | mon | 261 | 1 | nonexistent | 1.1 | 93.994 | -36.4 | 5191 | no |\n",
       "| 2 | 57 | services    | married  | high.school         | no  | no  | telephone | may | mon | 149 | 1 | nonexistent | 1.1 | 93.994 | -36.4 | 5191 | no |\n",
       "| 3 | 37 | services    | married  | high.school         | yes | no  | telephone | may | mon | 226 | 1 | nonexistent | 1.1 | 93.994 | -36.4 | 5191 | no |\n",
       "| 4 | 40 | admin.      | married  | basic.6y            | no  | no  | telephone | may | mon | 151 | 1 | nonexistent | 1.1 | 93.994 | -36.4 | 5191 | no |\n",
       "| 5 | 56 | services    | married  | high.school         | no  | yes | telephone | may | mon | 307 | 1 | nonexistent | 1.1 | 93.994 | -36.4 | 5191 | no |\n",
       "| 6 | 45 | services    | married  | basic.9y            | no  | no  | telephone | may | mon | 198 | 1 | nonexistent | 1.1 | 93.994 | -36.4 | 5191 | no |\n",
       "| 7 | 59 | admin.      | married  | professional.course | no  | no  | telephone | may | mon | 139 | 1 | nonexistent | 1.1 | 93.994 | -36.4 | 5191 | no |\n",
       "| 9 | 24 | technician  | single   | professional.course | yes | no  | telephone | may | mon | 380 | 1 | nonexistent | 1.1 | 93.994 | -36.4 | 5191 | no |\n",
       "| 10 | 25 | services    | single   | high.school         | yes | no  | telephone | may | mon |  50 | 1 | nonexistent | 1.1 | 93.994 | -36.4 | 5191 | no |\n",
       "| 12 | 25 | services    | single   | high.school         | yes | no  | telephone | may | mon | 222 | 1 | nonexistent | 1.1 | 93.994 | -36.4 | 5191 | no |\n",
       "| 13 | 29 | blue-collar | single   | high.school         | no  | yes | telephone | may | mon | 137 | 1 | nonexistent | 1.1 | 93.994 | -36.4 | 5191 | no |\n",
       "| 14 | 57 | housemaid   | divorced | basic.4y            | yes | no  | telephone | may | mon | 293 | 1 | nonexistent | 1.1 | 93.994 | -36.4 | 5191 | no |\n",
       "| 15 | 35 | blue-collar | married  | basic.6y            | yes | no  | telephone | may | mon | 146 | 1 | nonexistent | 1.1 | 93.994 | -36.4 | 5191 | no |\n",
       "| 16 | 54 | retired     | married  | basic.9y            | yes | yes | telephone | may | mon | 174 | 1 | nonexistent | 1.1 | 93.994 | -36.4 | 5191 | no |\n",
       "| 17 | 35 | blue-collar | married  | basic.6y            | yes | no  | telephone | may | mon | 312 | 1 | nonexistent | 1.1 | 93.994 | -36.4 | 5191 | no |\n",
       "| 18 | 46 | blue-collar | married  | basic.6y            | yes | yes | telephone | may | mon | 440 | 1 | nonexistent | 1.1 | 93.994 | -36.4 | 5191 | no |\n",
       "| 19 | 50 | blue-collar | married  | basic.9y            | yes | yes | telephone | may | mon | 353 | 1 | nonexistent | 1.1 | 93.994 | -36.4 | 5191 | no |\n",
       "| 20 | 39 | management  | single   | basic.9y            | no  | no  | telephone | may | mon | 195 | 1 | nonexistent | 1.1 | 93.994 | -36.4 | 5191 | no |\n",
       "| 21 | 30 | unemployed  | married  | high.school         | no  | no  | telephone | may | mon |  38 | 1 | nonexistent | 1.1 | 93.994 | -36.4 | 5191 | no |\n",
       "| 22 | 55 | blue-collar | married  | basic.4y            | yes | no  | telephone | may | mon | 262 | 1 | nonexistent | 1.1 | 93.994 | -36.4 | 5191 | no |\n",
       "\n"
      ],
      "text/plain": [
       "   Edad Ocupación   EstadoCivil Educación           Hipotecario Consumo\n",
       "1  56   housemaid   married     basic.4y            no          no     \n",
       "2  57   services    married     high.school         no          no     \n",
       "3  37   services    married     high.school         yes         no     \n",
       "4  40   admin.      married     basic.6y            no          no     \n",
       "5  56   services    married     high.school         no          yes    \n",
       "6  45   services    married     basic.9y            no          no     \n",
       "7  59   admin.      married     professional.course no          no     \n",
       "9  24   technician  single      professional.course yes         no     \n",
       "10 25   services    single      high.school         yes         no     \n",
       "12 25   services    single      high.school         yes         no     \n",
       "13 29   blue-collar single      high.school         no          yes    \n",
       "14 57   housemaid   divorced    basic.4y            yes         no     \n",
       "15 35   blue-collar married     basic.6y            yes         no     \n",
       "16 54   retired     married     basic.9y            yes         yes    \n",
       "17 35   blue-collar married     basic.6y            yes         no     \n",
       "18 46   blue-collar married     basic.6y            yes         yes    \n",
       "19 50   blue-collar married     basic.9y            yes         yes    \n",
       "20 39   management  single      basic.9y            no          no     \n",
       "21 30   unemployed  married     high.school         no          no     \n",
       "22 55   blue-collar married     basic.4y            yes         no     \n",
       "   Contacto  Mes Día Duración NumContactos ResultadoPrevio EmpTasaVar IPC   \n",
       "1  telephone may mon 261      1            nonexistent     1.1        93.994\n",
       "2  telephone may mon 149      1            nonexistent     1.1        93.994\n",
       "3  telephone may mon 226      1            nonexistent     1.1        93.994\n",
       "4  telephone may mon 151      1            nonexistent     1.1        93.994\n",
       "5  telephone may mon 307      1            nonexistent     1.1        93.994\n",
       "6  telephone may mon 198      1            nonexistent     1.1        93.994\n",
       "7  telephone may mon 139      1            nonexistent     1.1        93.994\n",
       "9  telephone may mon 380      1            nonexistent     1.1        93.994\n",
       "10 telephone may mon  50      1            nonexistent     1.1        93.994\n",
       "12 telephone may mon 222      1            nonexistent     1.1        93.994\n",
       "13 telephone may mon 137      1            nonexistent     1.1        93.994\n",
       "14 telephone may mon 293      1            nonexistent     1.1        93.994\n",
       "15 telephone may mon 146      1            nonexistent     1.1        93.994\n",
       "16 telephone may mon 174      1            nonexistent     1.1        93.994\n",
       "17 telephone may mon 312      1            nonexistent     1.1        93.994\n",
       "18 telephone may mon 440      1            nonexistent     1.1        93.994\n",
       "19 telephone may mon 353      1            nonexistent     1.1        93.994\n",
       "20 telephone may mon 195      1            nonexistent     1.1        93.994\n",
       "21 telephone may mon  38      1            nonexistent     1.1        93.994\n",
       "22 telephone may mon 262      1            nonexistent     1.1        93.994\n",
       "   ICC   NumEmpleados OK\n",
       "1  -36.4 5191         no\n",
       "2  -36.4 5191         no\n",
       "3  -36.4 5191         no\n",
       "4  -36.4 5191         no\n",
       "5  -36.4 5191         no\n",
       "6  -36.4 5191         no\n",
       "7  -36.4 5191         no\n",
       "9  -36.4 5191         no\n",
       "10 -36.4 5191         no\n",
       "12 -36.4 5191         no\n",
       "13 -36.4 5191         no\n",
       "14 -36.4 5191         no\n",
       "15 -36.4 5191         no\n",
       "16 -36.4 5191         no\n",
       "17 -36.4 5191         no\n",
       "18 -36.4 5191         no\n",
       "19 -36.4 5191         no\n",
       "20 -36.4 5191         no\n",
       "21 -36.4 5191         no\n",
       "22 -36.4 5191         no"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se declara la URL de dónde obtener los datos\n",
    "theUrlMain <- \"http://www.rsolver.com/dcc/docs/bank-additional-full.csv\"\n",
    "\n",
    "# Se declaran los nombres de las columnas\n",
    "columnas = c(\"Edad\",\"Ocupación\",\"EstadoCivil\",\"Educación\",\"Default\",\"Hipotecario\",\"Consumo\",\"Contacto\",\"Mes\",\"Día\",\n",
    "             \"Duración\",\"NumContactos\",\"DíasAtrás\",\"Previo\",\"ResultadoPrevio\",\n",
    "             \"EmpTasaVar\", \"IPC\", \"ICC\", \"Euribor3m\", \"NumEmpleados\", \"OK\")\n",
    "\n",
    "# Se cargan datos principales a una estructura o dataset (marketing.data), asignando nombres de atributos a las columnas.\n",
    "# Nótese que se incluye la conversión de valores \"unknown\" a \"NA\" para facilitar la gestión vacíos más adelante.\n",
    "marketing.data <- read.table(file = theUrlMain, header = TRUE, sep = \";\", col.names = columnas, na.strings=c(\"unknown\",\"NA\"))\n",
    "\n",
    "# Se eliminan aquellos atributos que no aportan en el desempeño de los modelos\n",
    "# Esto se determinó en un trabajo previo, fuera de esta actividad\n",
    "marketing.data$Default <- NULL\n",
    "marketing.data$DíasAtrás <- NULL\n",
    "marketing.data$Previo <- NULL\n",
    "marketing.data$Euribor3m <- NULL\n",
    "\n",
    "# Se eliminan los registros que tienen algún NA (antes: 'unknown')\n",
    "# Nótese que se hace esta limpieza posterior a la eliminación de columnas,\n",
    "# logrando conservar la enorme mayoría de los registros.\n",
    "marketing.clean <- na.omit(marketing.data)\n",
    "dim(marketing.clean) # Sólo quedan poco más de 38.000 filas (de las 41.000 originales)\n",
    "\n",
    "# Se muestran las primeras líneas del dataset, incluyendo sólo las columnas que quedaron.\n",
    "head(marketing.clean, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qWhjKB9AKc_Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de ejemplos por clase: YES & NO\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>4258</li><li>17</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 4258\n",
       "\\item 17\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 4258\n",
       "2. 17\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 4258   17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>33987</li><li>17</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 33987\n",
       "\\item 17\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 33987\n",
       "2. 17\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 33987    17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de ejemplos por clase luego del balance entre clases: YES & NO\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>4258</li><li>17</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 4258\n",
       "\\item 17\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 4258\n",
       "2. 17\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 4258   17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>5109</li><li>17</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 5109\n",
       "\\item 17\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 5109\n",
       "2. 17\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 5109   17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen del dataset ya limpio"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      Edad       Ocupación         EstadoCivil         Educación        \n",
       " Min.   :18.0   Length:9367        Length:9367        Length:9367       \n",
       " 1st Qu.:32.0   Class :character   Class :character   Class :character  \n",
       " Median :37.0   Mode  :character   Mode  :character   Mode  :character  \n",
       " Mean   :40.2                                                           \n",
       " 3rd Qu.:48.0                                                           \n",
       " Max.   :98.0                                                           \n",
       " Hipotecario          Consumo            Contacto             Mes           \n",
       " Length:9367        Length:9367        Length:9367        Length:9367       \n",
       " Class :character   Class :character   Class :character   Class :character  \n",
       " Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n",
       "                                                                            \n",
       "                                                                            \n",
       "                                                                            \n",
       "     Día               Duración       NumContactos    ResultadoPrevio   \n",
       " Length:9367        Min.   :   1.0   Min.   : 1.000   Length:9367       \n",
       " Class :character   1st Qu.: 137.0   1st Qu.: 1.000   Class :character  \n",
       " Mode  :character   Median : 254.0   Median : 2.000   Mode  :character  \n",
       "                    Mean   : 373.1   Mean   : 2.371                     \n",
       "                    3rd Qu.: 501.0   3rd Qu.: 3.000                     \n",
       "                    Max.   :4199.0   Max.   :41.000                     \n",
       "   EmpTasaVar           IPC             ICC          NumEmpleados \n",
       " Min.   :-3.4000   Min.   :92.20   Min.   :-50.80   Min.   :4964  \n",
       " 1st Qu.:-1.8000   1st Qu.:92.89   1st Qu.:-42.70   1st Qu.:5099  \n",
       " Median :-0.1000   Median :93.44   Median :-41.80   Median :5191  \n",
       " Mean   :-0.4167   Mean   :93.49   Mean   :-40.29   Mean   :5140  \n",
       " 3rd Qu.: 1.4000   3rd Qu.:93.99   3rd Qu.:-36.40   3rd Qu.:5228  \n",
       " Max.   : 1.4000   Max.   :94.77   Max.   :-26.90   Max.   :5228  \n",
       "      OK           \n",
       " Length:9367       \n",
       " Class :character  \n",
       " Mode  :character  \n",
       "                   \n",
       "                   \n",
       "                   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aquí se arman dos subconjuntos con los datos de cada una de las dos clases.\n",
    "# Se pueden ver los respectivos tamaños al terminar, evidenciando un desbalance.\n",
    "set.seed(123)\n",
    "clean.data.YES <- marketing.clean[marketing.clean$OK == 'yes',]\n",
    "clean.data.NO <- marketing.clean[marketing.clean$OK == 'no',]\n",
    "cat(\"Cantidad de ejemplos por clase: YES & NO\\n\")\n",
    "dim(clean.data.YES) # Este es el conjunto más pequeño con poco más de 4.000 ejemplos\n",
    "dim(clean.data.NO)  # Este es mayoritario con casi 34.000 ejemplos, evidenciando desbalance entre clases\n",
    "\n",
    "# A continuación se realiza un re-balanceo de las clases (random subsampling),\n",
    "# que consiste en reducir la cantidad de ejemplos de la clase más masiva, para acercarla a la minoritaria.\n",
    "balance_ratio <- 1.2 # Se elige un balanceo de 20% más de ejemplos de la clase negativa que la positiva\n",
    "\n",
    "clean.subdata.YES <- clean.data.YES  # No se aplica sample(); se usan todos los ejemplos de la clase YES (que es la que tiene menos ejemplos)\n",
    "clean.subdata.NO <- clean.data.NO[sample(nrow(clean.data.NO), balance_ratio*dim(clean.data.YES)[1]), ] # Se elige un subconjunto de los NO\n",
    "\n",
    "# Muestra cantidad de ejemplos contenidos en cada subconjunto\n",
    "cat(\"Cantidad de ejemplos por clase luego del balance entre clases: YES & NO\\n\")\n",
    "dim(clean.subdata.YES)\n",
    "dim(clean.subdata.NO)\n",
    "\n",
    "# Se juntan para el conjunto de referencia, ahora más balanceado\n",
    "clean.subdata <- rbind(clean.subdata.YES, clean.subdata.NO)\n",
    "\n",
    "cat(\"Resumen del dataset ya limpio\")\n",
    "summary(clean.subdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iX9lYmofTUJx"
   },
   "source": [
    "## Ejercicio 1: Preparación conjuntos de entrenamiento y evaluación\n",
    "\n",
    "En este caso, lo importante es considerar que **es posible cambiar la proporción de datos de entrenamiento y test** viendo el efecto que tiene en el desempeño de los modelos (del ejercicio 2: RandomForest, SVM, NB), viendo que alguno o varios de los modelos entregan mejores resultados considerando lo que más puede interesar, entre Accuracy, Sensitivity, Specificity.\n",
    "\n",
    "**Pregunta 1** (1.5 puntos)\n",
    "\n",
    "¿Cuál es la proporción entrenamiento/test que logra mejor desempeño y con cuál de los modelos entre RandomForest, SVM, NB?\n",
    "\n",
    "El objetivo es probar varias combinaciones cambiando la proporción de datos. Preliminarmente 4 combinaciones, desde 60%/40% hasta 90%/10%. Según los resultados de la ejecución de todos los modelos de clasificación más adelante, determinar y explicitar cuál es la proporción que logra mejores resultados o desmpeño de clasificación y cuál es la influencia del cambio de proporción de entrenamiento/test. Particularmente se espera que los alumnos determinen cómo se elige el mejor modelo (comparando Sensitivity, Specificity, Accuracy).\n",
    "\n",
    "Se pide documentar en una tabla todas las combinaciones, viendo los indicadores de desempeño más relevantes: Accuracy, Sensitivity, Specificity, **determinando cuál combinación da mejores resultados para cuál de los modelos** (RandomForest, NB, SVM), considerando que el desempeño se logra por maximizar el desempeño de la predicción de YES, además de un buen modelo balanceado (accuracy).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bREGDVWofFwH"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>7493</li><li>17</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 7493\n",
       "\\item 17\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 7493\n",
       "2. 17\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 7493   17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1874</li><li>17</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1874\n",
       "\\item 17\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1874\n",
       "2. 17\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1874   17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 17</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Edad</th><th scope=col>Ocupación</th><th scope=col>EstadoCivil</th><th scope=col>Educación</th><th scope=col>Hipotecario</th><th scope=col>Consumo</th><th scope=col>Contacto</th><th scope=col>Mes</th><th scope=col>Día</th><th scope=col>Duración</th><th scope=col>NumContactos</th><th scope=col>ResultadoPrevio</th><th scope=col>EmpTasaVar</th><th scope=col>IPC</th><th scope=col>ICC</th><th scope=col>NumEmpleados</th><th scope=col>OK</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>36743</th><td>27</td><td>admin.       </td><td>single </td><td>university.degree</td><td>no </td><td>no </td><td>cellular </td><td>jun</td><td>mon</td><td>138</td><td>3</td><td>nonexistent</td><td>-2.9</td><td>92.963</td><td>-40.8</td><td>5076.2</td><td>yes</td></tr>\n",
       "\t<tr><th scope=row>36892</th><td>25</td><td>student      </td><td>single </td><td>university.degree</td><td>no </td><td>yes</td><td>telephone</td><td>jun</td><td>thu</td><td>280</td><td>6</td><td>failure    </td><td>-2.9</td><td>92.963</td><td>-40.8</td><td>5076.2</td><td>yes</td></tr>\n",
       "\t<tr><th scope=row>15801</th><td>39</td><td>self-employed</td><td>married</td><td>high.school      </td><td>no </td><td>no </td><td>cellular </td><td>jul</td><td>mon</td><td>761</td><td>2</td><td>nonexistent</td><td> 1.4</td><td>93.918</td><td>-42.7</td><td>5228.1</td><td>no </td></tr>\n",
       "\t<tr><th scope=row>38405</th><td>39</td><td>admin.       </td><td>single </td><td>high.school      </td><td>yes</td><td>no </td><td>cellular </td><td>oct</td><td>tue</td><td>386</td><td>1</td><td>nonexistent</td><td>-3.4</td><td>92.431</td><td>-26.9</td><td>5017.5</td><td>yes</td></tr>\n",
       "\t<tr><th scope=row>30730</th><td>58</td><td>admin.       </td><td>single </td><td>university.degree</td><td>yes</td><td>no </td><td>cellular </td><td>may</td><td>tue</td><td>851</td><td>1</td><td>nonexistent</td><td>-1.8</td><td>92.893</td><td>-46.2</td><td>5099.1</td><td>yes</td></tr>\n",
       "\t<tr><th scope=row>10495</th><td>31</td><td>services     </td><td>married</td><td>high.school      </td><td>no </td><td>no </td><td>telephone</td><td>jun</td><td>tue</td><td> 37</td><td>6</td><td>nonexistent</td><td> 1.4</td><td>94.465</td><td>-41.8</td><td>5228.1</td><td>no </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 17\n",
       "\\begin{tabular}{r|lllllllllllllllll}\n",
       "  & Edad & Ocupación & EstadoCivil & Educación & Hipotecario & Consumo & Contacto & Mes & Día & Duración & NumContactos & ResultadoPrevio & EmpTasaVar & IPC & ICC & NumEmpleados & OK\\\\\n",
       "  & <int> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <int> & <int> & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t36743 & 27 & admin.        & single  & university.degree & no  & no  & cellular  & jun & mon & 138 & 3 & nonexistent & -2.9 & 92.963 & -40.8 & 5076.2 & yes\\\\\n",
       "\t36892 & 25 & student       & single  & university.degree & no  & yes & telephone & jun & thu & 280 & 6 & failure     & -2.9 & 92.963 & -40.8 & 5076.2 & yes\\\\\n",
       "\t15801 & 39 & self-employed & married & high.school       & no  & no  & cellular  & jul & mon & 761 & 2 & nonexistent &  1.4 & 93.918 & -42.7 & 5228.1 & no \\\\\n",
       "\t38405 & 39 & admin.        & single  & high.school       & yes & no  & cellular  & oct & tue & 386 & 1 & nonexistent & -3.4 & 92.431 & -26.9 & 5017.5 & yes\\\\\n",
       "\t30730 & 58 & admin.        & single  & university.degree & yes & no  & cellular  & may & tue & 851 & 1 & nonexistent & -1.8 & 92.893 & -46.2 & 5099.1 & yes\\\\\n",
       "\t10495 & 31 & services      & married & high.school       & no  & no  & telephone & jun & tue &  37 & 6 & nonexistent &  1.4 & 94.465 & -41.8 & 5228.1 & no \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 17\n",
       "\n",
       "| <!--/--> | Edad &lt;int&gt; | Ocupación &lt;chr&gt; | EstadoCivil &lt;chr&gt; | Educación &lt;chr&gt; | Hipotecario &lt;chr&gt; | Consumo &lt;chr&gt; | Contacto &lt;chr&gt; | Mes &lt;chr&gt; | Día &lt;chr&gt; | Duración &lt;int&gt; | NumContactos &lt;int&gt; | ResultadoPrevio &lt;chr&gt; | EmpTasaVar &lt;dbl&gt; | IPC &lt;dbl&gt; | ICC &lt;dbl&gt; | NumEmpleados &lt;dbl&gt; | OK &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 36743 | 27 | admin.        | single  | university.degree | no  | no  | cellular  | jun | mon | 138 | 3 | nonexistent | -2.9 | 92.963 | -40.8 | 5076.2 | yes |\n",
       "| 36892 | 25 | student       | single  | university.degree | no  | yes | telephone | jun | thu | 280 | 6 | failure     | -2.9 | 92.963 | -40.8 | 5076.2 | yes |\n",
       "| 15801 | 39 | self-employed | married | high.school       | no  | no  | cellular  | jul | mon | 761 | 2 | nonexistent |  1.4 | 93.918 | -42.7 | 5228.1 | no  |\n",
       "| 38405 | 39 | admin.        | single  | high.school       | yes | no  | cellular  | oct | tue | 386 | 1 | nonexistent | -3.4 | 92.431 | -26.9 | 5017.5 | yes |\n",
       "| 30730 | 58 | admin.        | single  | university.degree | yes | no  | cellular  | may | tue | 851 | 1 | nonexistent | -1.8 | 92.893 | -46.2 | 5099.1 | yes |\n",
       "| 10495 | 31 | services      | married | high.school       | no  | no  | telephone | jun | tue |  37 | 6 | nonexistent |  1.4 | 94.465 | -41.8 | 5228.1 | no  |\n",
       "\n"
      ],
      "text/plain": [
       "      Edad Ocupación     EstadoCivil Educación         Hipotecario Consumo\n",
       "36743 27   admin.        single      university.degree no          no     \n",
       "36892 25   student       single      university.degree no          yes    \n",
       "15801 39   self-employed married     high.school       no          no     \n",
       "38405 39   admin.        single      high.school       yes         no     \n",
       "30730 58   admin.        single      university.degree yes         no     \n",
       "10495 31   services      married     high.school       no          no     \n",
       "      Contacto  Mes Día Duración NumContactos ResultadoPrevio EmpTasaVar IPC   \n",
       "36743 cellular  jun mon 138      3            nonexistent     -2.9       92.963\n",
       "36892 telephone jun thu 280      6            failure         -2.9       92.963\n",
       "15801 cellular  jul mon 761      2            nonexistent      1.4       93.918\n",
       "38405 cellular  oct tue 386      1            nonexistent     -3.4       92.431\n",
       "30730 cellular  may tue 851      1            nonexistent     -1.8       92.893\n",
       "10495 telephone jun tue  37      6            nonexistent      1.4       94.465\n",
       "      ICC   NumEmpleados OK \n",
       "36743 -40.8 5076.2       yes\n",
       "36892 -40.8 5076.2       yes\n",
       "15801 -42.7 5228.1       no \n",
       "38405 -26.9 5017.5       yes\n",
       "30730 -46.2 5099.1       yes\n",
       "10495 -41.8 5228.1       no "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Primero, se saca una copia del dataset para trabajar sin modificar el original\n",
    "# Esto permite hacer más modificaciones y correr este código varias veces sin alterar clean.subdata\n",
    "set.seed(123)\n",
    "working.data <- clean.subdata\n",
    "\n",
    "# EJERCICIO 1\n",
    "# Ahora se configuran los conjuntos de entrenamiento y testing en una proporción\n",
    "# (por ej: 0.70 = 70% para training y el resto para evaluación o testing)\n",
    "# Se pide probar diferentes combinaciones (60/40, 70/30, 80/20, 90/10)\n",
    "# hasta determinar cuál es la mejor en cuál de los modelos.\n",
    "ratio1 = sample(1:nrow(working.data), size = 0.80*nrow(working.data))\n",
    "training.data1 = working.data[ratio1,]\n",
    "testing.data1 = working.data[-ratio1,]\n",
    "\n",
    "# Se comparan los tamaños de ejemplos para entrenamiento y evaluación.\n",
    "dim(training.data1)\n",
    "dim(testing.data1)\n",
    "\n",
    "head(training.data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82LcskQOnNmH"
   },
   "source": [
    "## Ejercicio 2: Comparación de desempeño de modelos de clasificación y su explicación\n",
    "\n",
    "Habiendo definido los conjuntos de entrenamiento y de test, a continuación se ejecutan unos modelos de clasificación: un RandomForest, un Naive Bayes, y un Support Vector Machine. Cada uno obtiene sus resultados, mostrando sus precisiones en desempeño. No es necesario modificar estos bloques de código. Basta con hacer los cambios en la parte del ejercicio 1 (proporción entrenamiento/test) y volver a ejecutar estos modelos para evaluar su desempeño.\n",
    "\n",
    "Una vez completado el ejercicio 1 anterior (habiendo quedado con una ejecución de mejor desempeño y habiendo realizado la comparación de los indicadores), se pueden contestar las preguntas a continuación, que se centran en interpretar y analizar comparativamente del desempeño de estos modelos.\n",
    "\n",
    "**Pregunta 2.1** (1 punto)\n",
    "\n",
    "Viendo que un balance de clases de 1.2 (sólo un 20% más de ejemplos de la clase negativa sobre la positiva), donde reduce notoriamente la cantidad de ejemplos de la clase negativa, ¿por qué considera que se logra esa mejoría, a pesar de eliminar de entrenamiento y evaluación esa cantidad de ejemplos originales? (Justifique con claridad, según lo que se conoce sobre la forma en que se entrenan los modelos).\n",
    "\n",
    "**Pregunta 2.2** (1 punto)\n",
    "\n",
    "Habiendo determinado en el ejercicio 1 cuál es el modelo que tiene mejor desempeño entre todos, con una mejor proporción de entrenamiento/test ¿qué características del modelo apoyan su mejor desempeño sobre los otros modelos, aunque la diferencia haya sido menor? (Justifique con claridad, según lo que se conoce sobre las características particulares de los modelos y por qué ese modelo muestra mejor desempeño que los otros).\n",
    "\n",
    "Recuerde que sólo se comparan los 3 modelos a continuación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EM91HnJqh7D6"
   },
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table style=\"width: 100%;\"><tr><td>randomForest {randomForest}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2 id='randomForest'>Classification and Regression with Random Forest</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p><code>randomForest</code> implements Breiman's random forest algorithm (based on\n",
       "Breiman and Cutler's original Fortran code) for classification and\n",
       "regression.  It can also be used in unsupervised mode for assessing\n",
       "proximities among data points.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre><code class='language-R'>## S3 method for class 'formula'\n",
       "randomForest(formula, data=NULL, ..., subset, na.action=na.fail)\n",
       "## Default S3 method:\n",
       "randomForest(x, y=NULL,  xtest=NULL, ytest=NULL, ntree=500,\n",
       "             mtry=if (!is.null(y) &amp;&amp; !is.factor(y))\n",
       "             max(floor(ncol(x)/3), 1) else floor(sqrt(ncol(x))),\n",
       "             weights=NULL,\n",
       "             replace=TRUE, classwt=NULL, cutoff, strata,\n",
       "             sampsize = if (replace) nrow(x) else ceiling(.632*nrow(x)),\n",
       "             nodesize = if (!is.null(y) &amp;&amp; !is.factor(y)) 5 else 1,\n",
       "             maxnodes = NULL,\n",
       "             importance=FALSE, localImp=FALSE, nPerm=1,\n",
       "             proximity, oob.prox=proximity,\n",
       "             norm.votes=TRUE, do.trace=FALSE,\n",
       "             keep.forest=!is.null(y) &amp;&amp; is.null(xtest), corr.bias=FALSE,\n",
       "             keep.inbag=FALSE, ...)\n",
       "## S3 method for class 'randomForest'\n",
       "print(x, ...)\n",
       "</code></pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table>\n",
       "<tr><td><code id=\"randomForest_:_data\">data</code></td>\n",
       "<td>\n",
       "<p>an optional data frame containing the variables in the model.\n",
       "By default the variables are taken from the environment which\n",
       "<code>randomForest</code> is called from.</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_subset\">subset</code></td>\n",
       "<td>\n",
       "<p>an index vector indicating which rows should be used.\n",
       "(NOTE: If given, this argument must be named.)</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_na.action\">na.action</code></td>\n",
       "<td>\n",
       "<p>A function to specify the action to be taken if NAs\n",
       "are found.  (NOTE: If given, this argument must be named.)</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_x\">x</code>, <code id=\"randomForest_:_formula\">formula</code></td>\n",
       "<td>\n",
       "<p>a data frame or a matrix of predictors, or a formula\n",
       "describing the model to be fitted (for the\n",
       "<code>print</code> method, an <code>randomForest</code> object).</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_y\">y</code></td>\n",
       "<td>\n",
       "<p>A response vector.  If a factor, classification is assumed,\n",
       "otherwise regression is assumed.  If omitted, <code>randomForest</code>\n",
       "will run in unsupervised mode.</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_xtest\">xtest</code></td>\n",
       "<td>\n",
       "<p>a data frame or matrix (like <code>x</code>) containing\n",
       "predictors for the test set.</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_ytest\">ytest</code></td>\n",
       "<td>\n",
       "<p>response for the test set.</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_ntree\">ntree</code></td>\n",
       "<td>\n",
       "<p>Number of trees to grow.  This should not be set to too\n",
       "small a number, to ensure that every input row gets predicted at\n",
       "least a few times. </p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_mtry\">mtry</code></td>\n",
       "<td>\n",
       "<p>Number of variables randomly sampled as candidates at each\n",
       "split.  Note that the default values are different for\n",
       "classification (sqrt(p) where p is number of variables in <code>x</code>)\n",
       "and regression (p/3)</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_weights\">weights</code></td>\n",
       "<td>\n",
       "<p>A vector of length same as <code>y</code> that are positive \n",
       "weights used only in sampling data to grow each tree (not used in any\n",
       "other calculation)</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_replace\">replace</code></td>\n",
       "<td>\n",
       "<p>Should sampling of cases be done with or without\n",
       "replacement?</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_classwt\">classwt</code></td>\n",
       "<td>\n",
       "<p>Priors of the classes.  Need not add up to one.\n",
       "Ignored for regression.</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_cutoff\">cutoff</code></td>\n",
       "<td>\n",
       "<p>(Classification only)  A vector of length equal to\n",
       "number of classes.  The &lsquo;winning&rsquo; class for an observation is the\n",
       "one with the maximum ratio of proportion of votes to cutoff.\n",
       "Default is 1/k where k is the number of classes (i.e., majority vote\n",
       "wins).</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_strata\">strata</code></td>\n",
       "<td>\n",
       "<p>A (factor) variable that is used for stratified sampling.</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_sampsize\">sampsize</code></td>\n",
       "<td>\n",
       "<p>Size(s) of sample to draw.  For classification, if\n",
       "sampsize is a vector of the length the number of strata, then\n",
       "sampling is stratified by strata, and the elements of sampsize\n",
       "indicate the numbers to be drawn from the strata.</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_nodesize\">nodesize</code></td>\n",
       "<td>\n",
       "<p>Minimum size of terminal nodes.  Setting this number\n",
       "larger causes smaller trees to be grown (and thus take less time).\n",
       "Note that the default values are different for classification (1)\n",
       "and regression (5).</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_maxnodes\">maxnodes</code></td>\n",
       "<td>\n",
       "<p>Maximum number of terminal nodes trees in the forest\n",
       "can have.  If not given, trees are grown to the maximum possible\n",
       "(subject to limits by <code>nodesize</code>).  If set larger than maximum\n",
       "possible, a warning is issued.</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_importance\">importance</code></td>\n",
       "<td>\n",
       "<p>Should importance of predictors be assessed? </p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_localImp\">localImp</code></td>\n",
       "<td>\n",
       "<p>Should casewise importance measure be computed?\n",
       "(Setting this to <code>TRUE</code> will override <code>importance</code>.) </p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_nPerm\">nPerm</code></td>\n",
       "<td>\n",
       "<p>Number of times the OOB data are permuted per tree for\n",
       "assessing variable importance.  Number larger than 1 gives slightly\n",
       "more stable estimate, but not very effective.  Currently only\n",
       "implemented for regression.</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_proximity\">proximity</code></td>\n",
       "<td>\n",
       "<p>Should proximity measure among the rows be\n",
       "calculated?</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_oob.prox\">oob.prox</code></td>\n",
       "<td>\n",
       "<p>Should proximity be calculated only on &ldquo;out-of-bag&rdquo;\n",
       "data?</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_norm.votes\">norm.votes</code></td>\n",
       "<td>\n",
       "<p>If <code>TRUE</code> (default), the final result of votes\n",
       "are expressed as fractions.  If <code>FALSE</code>, raw vote counts are\n",
       "returned (useful for combining results from different runs).\n",
       "Ignored for regression.</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_do.trace\">do.trace</code></td>\n",
       "<td>\n",
       "<p>If set to <code>TRUE</code>, give a more verbose output as\n",
       "<code>randomForest</code> is run.  If set to some integer, then running\n",
       "output is printed for every <code>do.trace</code> trees.</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_keep.forest\">keep.forest</code></td>\n",
       "<td>\n",
       "<p>If set to <code>FALSE</code>, the forest will not be\n",
       "retained in the output object.  If <code>xtest</code> is given, defaults\n",
       "to <code>FALSE</code>.</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_corr.bias\">corr.bias</code></td>\n",
       "<td>\n",
       "<p>perform bias correction for regression?  Note:\n",
       "Experimental.  Use at your own risk.</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_keep.inbag\">keep.inbag</code></td>\n",
       "<td>\n",
       "<p>Should an <code>n</code> by <code>ntree</code> matrix be\n",
       "returned that keeps track of which samples are &ldquo;in-bag&rdquo; in which\n",
       "trees (but not how many times, if sampling with replacement)</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"randomForest_:_...\">...</code></td>\n",
       "<td>\n",
       "<p>optional parameters to be passed to the low level function\n",
       "<code>randomForest.default</code>.</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Value</h3>\n",
       "\n",
       "<p>An object of class <code>randomForest</code>, which is a list with the\n",
       "following components:\n",
       "</p>\n",
       "<table>\n",
       "<tr><td><code>call</code></td>\n",
       "<td>\n",
       "<p>the original call to <code>randomForest</code></p>\n",
       "</td></tr>\n",
       "<tr><td><code>type</code></td>\n",
       "<td>\n",
       "<p>one of <code>regression</code>, <code>classification</code>, or\n",
       "<code>unsupervised</code>.</p>\n",
       "</td></tr>\n",
       "<tr><td><code>predicted</code></td>\n",
       "<td>\n",
       "<p>the predicted values of the input data based on\n",
       "out-of-bag samples.</p>\n",
       "</td></tr>\n",
       "<tr><td><code>importance</code></td>\n",
       "<td>\n",
       "<p>a matrix with <code>nclass</code> + 2 (for classification)\n",
       "or two (for regression) columns.  For classification, the first\n",
       "<code>nclass</code> columns are the class-specific measures computed as\n",
       "mean descrease in accuracy.  The <code>nclass</code> + 1st column is the\n",
       "mean descrease in accuracy over all classes.  The last column is the\n",
       "mean decrease in Gini index.  For Regression, the first column is\n",
       "the mean decrease in accuracy and the second the mean decrease in MSE.\n",
       "If <code>importance=FALSE</code>, the last measure is still returned as a\n",
       "vector.</p>\n",
       "</td></tr>\n",
       "<tr><td><code>importanceSD</code></td>\n",
       "<td>\n",
       "<p>The &ldquo;standard errors&rdquo; of the permutation-based\n",
       "importance measure.  For classification, a <code>p</code> by <code>nclass\n",
       "      + 1</code> matrix corresponding to the first <code>nclass + 1</code> columns\n",
       "of the importance matrix.  For regression, a length <code>p</code> vector.</p>\n",
       "</td></tr>\n",
       "<tr><td><code>localImp</code></td>\n",
       "<td>\n",
       "<p>a p by n matrix containing the casewise importance\n",
       "measures, the [i,j] element of which is the importance of i-th\n",
       "variable on the j-th case. <code>NULL</code> if <code>localImp=FALSE</code>.</p>\n",
       "</td></tr>\n",
       "<tr><td><code>ntree</code></td>\n",
       "<td>\n",
       "<p>number of trees grown.</p>\n",
       "</td></tr>\n",
       "<tr><td><code>mtry</code></td>\n",
       "<td>\n",
       "<p>number of predictors sampled for spliting at each node.</p>\n",
       "</td></tr>\n",
       "<tr><td><code>forest</code></td>\n",
       "<td>\n",
       "<p>(a list that contains the entire forest; <code>NULL</code> if\n",
       "<code>randomForest</code> is run in unsupervised mode or if\n",
       "<code>keep.forest=FALSE</code>.</p>\n",
       "</td></tr>\n",
       "<tr><td><code>err.rate</code></td>\n",
       "<td>\n",
       "<p>(classification only) vector error rates of the\n",
       "prediction on the input data, the i-th element being the (OOB) error rate\n",
       "for all trees up to the i-th.</p>\n",
       "</td></tr>\n",
       "<tr><td><code>confusion</code></td>\n",
       "<td>\n",
       "<p>(classification only) the confusion matrix of the\n",
       "prediction (based on OOB data).</p>\n",
       "</td></tr>\n",
       "<tr><td><code>votes</code></td>\n",
       "<td>\n",
       "<p>(classification only) a matrix with one row for each\n",
       "input data point and one column for each class, giving the fraction\n",
       "or number of (OOB) &lsquo;votes&rsquo; from the random forest.</p>\n",
       "</td></tr>\n",
       "<tr><td><code>oob.times</code></td>\n",
       "<td>\n",
       "<p>number of times cases are &lsquo;out-of-bag&rsquo; (and thus used\n",
       "in computing OOB error estimate)</p>\n",
       "</td></tr>\n",
       "<tr><td><code>proximity</code></td>\n",
       "<td>\n",
       "<p>if <code>proximity=TRUE</code> when\n",
       "<code>randomForest</code> is called, a matrix of proximity measures among\n",
       "the input (based on the frequency that pairs of data points are in\n",
       "the same terminal nodes).</p>\n",
       "</td></tr>\n",
       "<tr><td><code>mse</code></td>\n",
       "<td>\n",
       "<p>(regression only) vector of mean square errors: sum of squared\n",
       "residuals divided by <code>n</code>.</p>\n",
       "</td></tr>\n",
       "<tr><td><code>rsq</code></td>\n",
       "<td>\n",
       "<p>(regression only) &ldquo;pseudo R-squared&rdquo;: 1 - <code>mse</code> /\n",
       "Var(y).</p>\n",
       "</td></tr>\n",
       "<tr><td><code>test</code></td>\n",
       "<td>\n",
       "<p>if test set is given (through the <code>xtest</code> or additionally\n",
       "<code>ytest</code> arguments), this component is a list which contains the\n",
       "corresponding <code>predicted</code>, <code>err.rate</code>, <code>confusion</code>,\n",
       "<code>votes</code> (for classification) or <code>predicted</code>, <code>mse</code> and\n",
       "<code>rsq</code> (for regression) for the test set.  If\n",
       "<code>proximity=TRUE</code>, there is also a component, <code>proximity</code>,\n",
       "which contains the proximity among the test set as well as proximity\n",
       "between test and training data.</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Note</h3>\n",
       "\n",
       "<p>The <code>forest</code> structure is slightly different between\n",
       "classification and regression.  For details on how the trees are\n",
       "stored, see the help page for <code>getTree</code>.\n",
       "</p>\n",
       "<p>If <code>xtest</code> is given, prediction of the test set is done &ldquo;in\n",
       "place&rdquo; as the trees are grown.  If <code>ytest</code> is also given, and\n",
       "<code>do.trace</code> is set to some positive integer, then for every\n",
       "<code>do.trace</code> trees, the test set error is printed.  Results for the\n",
       "test set is returned in the <code>test</code> component of the resulting\n",
       "<code>randomForest</code> object.  For classification, the <code>votes</code>\n",
       "component (for training or test set data) contain the votes the cases\n",
       "received for the classes.  If <code>norm.votes=TRUE</code>, the fraction is\n",
       "given, which can be taken as predicted probabilities for the classes.\n",
       "</p>\n",
       "<p>For large data sets, especially those with large number of variables,\n",
       "calling <code>randomForest</code> via the formula interface is not advised:\n",
       "There may be too much overhead in handling the formula.\n",
       "</p>\n",
       "<p>The &ldquo;local&rdquo; (or casewise) variable importance is computed as\n",
       "follows:  For classification, it is the increase in percent of times a\n",
       "case is OOB and misclassified when the variable is permuted.  For\n",
       "regression, it is the average increase in squared OOB residuals when\n",
       "the variable is permuted.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Author(s)</h3>\n",
       "\n",
       "<p>Andy Liaw <a href=\"mailto:andy_liaw@merck.com\">andy_liaw@merck.com</a> and Matthew Wiener\n",
       "<a href=\"mailto:matthew_wiener@merck.com\">matthew_wiener@merck.com</a>, based on original Fortran code by\n",
       "Leo Breiman and Adele Cutler.</p>\n",
       "\n",
       "\n",
       "<h3>References</h3>\n",
       "\n",
       "<p>Breiman, L. (2001), <em>Random Forests</em>, Machine Learning 45(1),\n",
       "5-32.\n",
       "</p>\n",
       "<p>Breiman, L (2002), &ldquo;Manual On Setting Up, Using, And Understanding\n",
       "Random Forests V3.1&rdquo;, <a href=\"https://www.stat.berkeley.edu/~breiman/Using_random_forests_V3.1.pdf\">https://www.stat.berkeley.edu/~breiman/Using_random_forests_V3.1.pdf</a>.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>See Also</h3>\n",
       "\n",
       "<p><code>predict.randomForest</code>, <code>varImpPlot</code></p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre><code class='language-R'>## Classification:\n",
       "##data(iris)\n",
       "set.seed(71)\n",
       "iris.rf &lt;- randomForest(Species ~ ., data=iris, importance=TRUE,\n",
       "                        proximity=TRUE)\n",
       "print(iris.rf)\n",
       "## Look at variable importance:\n",
       "round(importance(iris.rf), 2)\n",
       "## Do MDS on 1 - proximity:\n",
       "iris.mds &lt;- cmdscale(1 - iris.rf$proximity, eig=TRUE)\n",
       "op &lt;- par(pty=\"s\")\n",
       "pairs(cbind(iris[,1:4], iris.mds$points), cex=0.6, gap=0,\n",
       "      col=c(\"red\", \"green\", \"blue\")[as.numeric(iris$Species)],\n",
       "      main=\"Iris Data: Predictors and MDS of Proximity Based on RandomForest\")\n",
       "par(op)\n",
       "print(iris.mds$GOF)\n",
       "\n",
       "## The `unsupervised' case:\n",
       "set.seed(17)\n",
       "iris.urf &lt;- randomForest(iris[, -5])\n",
       "MDSplot(iris.urf, iris$Species)\n",
       "\n",
       "## stratified sampling: draw 20, 30, and 20 of the species to grow each tree.\n",
       "(iris.rf2 &lt;- randomForest(iris[1:4], iris$Species, \n",
       "                          sampsize=c(20, 30, 20)))\n",
       "\n",
       "## Regression:\n",
       "## data(airquality)\n",
       "set.seed(131)\n",
       "ozone.rf &lt;- randomForest(Ozone ~ ., data=airquality, mtry=3,\n",
       "                         importance=TRUE, na.action=na.omit)\n",
       "print(ozone.rf)\n",
       "## Show \"importance\" of variables: higher value mean more important:\n",
       "round(importance(ozone.rf), 2)\n",
       "\n",
       "## \"x\" can be a matrix instead of a data frame:\n",
       "set.seed(17)\n",
       "x &lt;- matrix(runif(5e2), 100)\n",
       "y &lt;- gl(2, 50)\n",
       "(myrf &lt;- randomForest(x, y))\n",
       "(predict(myrf, x))\n",
       "\n",
       "## \"complicated\" formula:\n",
       "(swiss.rf &lt;- randomForest(sqrt(Fertility) ~ . - Catholic + I(Catholic &lt; 50),\n",
       "                          data=swiss))\n",
       "(predict(swiss.rf, swiss))\n",
       "## Test use of 32-level factor as a predictor:\n",
       "set.seed(1)\n",
       "x &lt;- data.frame(x1=gl(53, 10), x2=runif(530), y=rnorm(530))\n",
       "(rf1 &lt;- randomForest(x[-3], x[[3]], ntree=10))\n",
       "\n",
       "## Grow no more than 4 nodes per tree:\n",
       "(treesize(randomForest(Species ~ ., data=iris, maxnodes=4, ntree=30)))\n",
       "\n",
       "## test proximity in regression\n",
       "iris.rrf &lt;- randomForest(iris[-1], iris[[1]], ntree=101, proximity=TRUE, oob.prox=FALSE)\n",
       "str(iris.rrf$proximity)\n",
       "\n",
       "## Using weights: make versicolors having 3 times larger weights\n",
       "iris_wt &lt;- ifelse( iris$Species == \"versicolor\", 3, 1 )\n",
       "set.seed(15)\n",
       "iris.wcrf &lt;- randomForest(iris[-5], iris[[5]], weights=iris_wt, keep.inbag=TRUE)\n",
       "print(rowSums(iris.wcrf$inbag))\n",
       "set.seed(15)\n",
       "iris.wrrf &lt;- randomForest(iris[-1], iris[[1]], weights=iris_wt, keep.inbag=TRUE)\n",
       "print(rowSums(iris.wrrf$inbag))\n",
       "</code></pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>randomForest</em> version 4.7-1.1 ]</div>\n",
       "</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{randomForest}{Classification and Regression with Random Forest}{randomForest}\n",
       "\\aliasA{print.randomForest}{randomForest}{print.randomForest}\n",
       "\\methaliasA{randomForest.default}{randomForest}{randomForest.default}\n",
       "\\methaliasA{randomForest.formula}{randomForest}{randomForest.formula}\n",
       "\\keyword{classif}{randomForest}\n",
       "\\keyword{regression}{randomForest}\n",
       "\\keyword{tree}{randomForest}\n",
       "%\n",
       "\\begin{Description}\n",
       "\\code{randomForest} implements Breiman's random forest algorithm (based on\n",
       "Breiman and Cutler's original Fortran code) for classification and\n",
       "regression.  It can also be used in unsupervised mode for assessing\n",
       "proximities among data points.\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "## S3 method for class 'formula'\n",
       "randomForest(formula, data=NULL, ..., subset, na.action=na.fail)\n",
       "## Default S3 method:\n",
       "randomForest(x, y=NULL,  xtest=NULL, ytest=NULL, ntree=500,\n",
       "             mtry=if (!is.null(y) && !is.factor(y))\n",
       "             max(floor(ncol(x)/3), 1) else floor(sqrt(ncol(x))),\n",
       "             weights=NULL,\n",
       "             replace=TRUE, classwt=NULL, cutoff, strata,\n",
       "             sampsize = if (replace) nrow(x) else ceiling(.632*nrow(x)),\n",
       "             nodesize = if (!is.null(y) && !is.factor(y)) 5 else 1,\n",
       "             maxnodes = NULL,\n",
       "             importance=FALSE, localImp=FALSE, nPerm=1,\n",
       "             proximity, oob.prox=proximity,\n",
       "             norm.votes=TRUE, do.trace=FALSE,\n",
       "             keep.forest=!is.null(y) && is.null(xtest), corr.bias=FALSE,\n",
       "             keep.inbag=FALSE, ...)\n",
       "## S3 method for class 'randomForest'\n",
       "print(x, ...)\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{data}] an optional data frame containing the variables in the model.\n",
       "By default the variables are taken from the environment which\n",
       "\\code{randomForest} is called from.\n",
       "\\item[\\code{subset}] an index vector indicating which rows should be used.\n",
       "(NOTE: If given, this argument must be named.)\n",
       "\\item[\\code{na.action}] A function to specify the action to be taken if NAs\n",
       "are found.  (NOTE: If given, this argument must be named.)\n",
       "\\item[\\code{x, formula}] a data frame or a matrix of predictors, or a formula\n",
       "describing the model to be fitted (for the\n",
       "\\code{print} method, an \\code{randomForest} object).\n",
       "\\item[\\code{y}] A response vector.  If a factor, classification is assumed,\n",
       "otherwise regression is assumed.  If omitted, \\code{randomForest}\n",
       "will run in unsupervised mode.\n",
       "\\item[\\code{xtest}] a data frame or matrix (like \\code{x}) containing\n",
       "predictors for the test set.\n",
       "\\item[\\code{ytest}] response for the test set.\n",
       "\\item[\\code{ntree}] Number of trees to grow.  This should not be set to too\n",
       "small a number, to ensure that every input row gets predicted at\n",
       "least a few times. \n",
       "\\item[\\code{mtry}] Number of variables randomly sampled as candidates at each\n",
       "split.  Note that the default values are different for\n",
       "classification (sqrt(p) where p is number of variables in \\code{x})\n",
       "and regression (p/3)\n",
       "\\item[\\code{weights}] A vector of length same as \\code{y} that are positive \n",
       "weights used only in sampling data to grow each tree (not used in any\n",
       "other calculation)\n",
       "\\item[\\code{replace}] Should sampling of cases be done with or without\n",
       "replacement?\n",
       "\\item[\\code{classwt}] Priors of the classes.  Need not add up to one.\n",
       "Ignored for regression.\n",
       "\\item[\\code{cutoff}] (Classification only)  A vector of length equal to\n",
       "number of classes.  The `winning' class for an observation is the\n",
       "one with the maximum ratio of proportion of votes to cutoff.\n",
       "Default is 1/k where k is the number of classes (i.e., majority vote\n",
       "wins).\n",
       "\\item[\\code{strata}] A (factor) variable that is used for stratified sampling.\n",
       "\\item[\\code{sampsize}] Size(s) of sample to draw.  For classification, if\n",
       "sampsize is a vector of the length the number of strata, then\n",
       "sampling is stratified by strata, and the elements of sampsize\n",
       "indicate the numbers to be drawn from the strata.\n",
       "\\item[\\code{nodesize}] Minimum size of terminal nodes.  Setting this number\n",
       "larger causes smaller trees to be grown (and thus take less time).\n",
       "Note that the default values are different for classification (1)\n",
       "and regression (5).\n",
       "\\item[\\code{maxnodes}] Maximum number of terminal nodes trees in the forest\n",
       "can have.  If not given, trees are grown to the maximum possible\n",
       "(subject to limits by \\code{nodesize}).  If set larger than maximum\n",
       "possible, a warning is issued.\n",
       "\\item[\\code{importance}] Should importance of predictors be assessed? \n",
       "\\item[\\code{localImp}] Should casewise importance measure be computed?\n",
       "(Setting this to \\code{TRUE} will override \\code{importance}.) \n",
       "\\item[\\code{nPerm}] Number of times the OOB data are permuted per tree for\n",
       "assessing variable importance.  Number larger than 1 gives slightly\n",
       "more stable estimate, but not very effective.  Currently only\n",
       "implemented for regression.\n",
       "\\item[\\code{proximity}] Should proximity measure among the rows be\n",
       "calculated?\n",
       "\\item[\\code{oob.prox}] Should proximity be calculated only on ``out-of-bag''\n",
       "data?\n",
       "\\item[\\code{norm.votes}] If \\code{TRUE} (default), the final result of votes\n",
       "are expressed as fractions.  If \\code{FALSE}, raw vote counts are\n",
       "returned (useful for combining results from different runs).\n",
       "Ignored for regression.\n",
       "\\item[\\code{do.trace}] If set to \\code{TRUE}, give a more verbose output as\n",
       "\\code{randomForest} is run.  If set to some integer, then running\n",
       "output is printed for every \\code{do.trace} trees.\n",
       "\\item[\\code{keep.forest}] If set to \\code{FALSE}, the forest will not be\n",
       "retained in the output object.  If \\code{xtest} is given, defaults\n",
       "to \\code{FALSE}.\n",
       "\\item[\\code{corr.bias}] perform bias correction for regression?  Note:\n",
       "Experimental.  Use at your own risk.\n",
       "\\item[\\code{keep.inbag}] Should an \\code{n} by \\code{ntree} matrix be\n",
       "returned that keeps track of which samples are ``in-bag'' in which\n",
       "trees (but not how many times, if sampling with replacement)\n",
       "\\item[\\code{...}] optional parameters to be passed to the low level function\n",
       "\\code{randomForest.default}.\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Value}\n",
       "An object of class \\code{randomForest}, which is a list with the\n",
       "following components:\n",
       "\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{call}] the original call to \\code{randomForest}\n",
       "\\item[\\code{type}] one of \\code{regression}, \\code{classification}, or\n",
       "\\code{unsupervised}.\n",
       "\\item[\\code{predicted}] the predicted values of the input data based on\n",
       "out-of-bag samples.\n",
       "\\item[\\code{importance}] a matrix with \\code{nclass} + 2 (for classification)\n",
       "or two (for regression) columns.  For classification, the first\n",
       "\\code{nclass} columns are the class-specific measures computed as\n",
       "mean descrease in accuracy.  The \\code{nclass} + 1st column is the\n",
       "mean descrease in accuracy over all classes.  The last column is the\n",
       "mean decrease in Gini index.  For Regression, the first column is\n",
       "the mean decrease in accuracy and the second the mean decrease in MSE.\n",
       "If \\code{importance=FALSE}, the last measure is still returned as a\n",
       "vector.\n",
       "\\item[\\code{importanceSD}] The ``standard errors'' of the permutation-based\n",
       "importance measure.  For classification, a \\code{p} by \\code{nclass\n",
       "      + 1} matrix corresponding to the first \\code{nclass + 1} columns\n",
       "of the importance matrix.  For regression, a length \\code{p} vector.\n",
       "\\item[\\code{localImp}] a p by n matrix containing the casewise importance\n",
       "measures, the [i,j] element of which is the importance of i-th\n",
       "variable on the j-th case. \\code{NULL} if \\code{localImp=FALSE}.\n",
       "\\item[\\code{ntree}] number of trees grown.\n",
       "\\item[\\code{mtry}] number of predictors sampled for spliting at each node.\n",
       "\\item[\\code{forest}] (a list that contains the entire forest; \\code{NULL} if\n",
       "\\code{randomForest} is run in unsupervised mode or if\n",
       "\\code{keep.forest=FALSE}.\n",
       "\\item[\\code{err.rate}] (classification only) vector error rates of the\n",
       "prediction on the input data, the i-th element being the (OOB) error rate\n",
       "for all trees up to the i-th.\n",
       "\\item[\\code{confusion}] (classification only) the confusion matrix of the\n",
       "prediction (based on OOB data).\n",
       "\\item[\\code{votes}] (classification only) a matrix with one row for each\n",
       "input data point and one column for each class, giving the fraction\n",
       "or number of (OOB) `votes' from the random forest.\n",
       "\\item[\\code{oob.times}] number of times cases are `out-of-bag' (and thus used\n",
       "in computing OOB error estimate)\n",
       "\\item[\\code{proximity}] if \\code{proximity=TRUE} when\n",
       "\\code{randomForest} is called, a matrix of proximity measures among\n",
       "the input (based on the frequency that pairs of data points are in\n",
       "the same terminal nodes).\n",
       "\n",
       "\\item[\\code{mse}] (regression only) vector of mean square errors: sum of squared\n",
       "residuals divided by \\code{n}.\n",
       "\\item[\\code{rsq}] (regression only) ``pseudo R-squared'': 1 - \\code{mse} /\n",
       "Var(y).\n",
       "\\item[\\code{test}] if test set is given (through the \\code{xtest} or additionally\n",
       "\\code{ytest} arguments), this component is a list which contains the\n",
       "corresponding \\code{predicted}, \\code{err.rate}, \\code{confusion},\n",
       "\\code{votes} (for classification) or \\code{predicted}, \\code{mse} and\n",
       "\\code{rsq} (for regression) for the test set.  If\n",
       "\\code{proximity=TRUE}, there is also a component, \\code{proximity},\n",
       "which contains the proximity among the test set as well as proximity\n",
       "between test and training data.\n",
       "\\end{ldescription}\n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{Note}\n",
       "The \\code{forest} structure is slightly different between\n",
       "classification and regression.  For details on how the trees are\n",
       "stored, see the help page for \\code{\\LinkA{getTree}{getTree}}.\n",
       "\n",
       "If \\code{xtest} is given, prediction of the test set is done ``in\n",
       "place'' as the trees are grown.  If \\code{ytest} is also given, and\n",
       "\\code{do.trace} is set to some positive integer, then for every\n",
       "\\code{do.trace} trees, the test set error is printed.  Results for the\n",
       "test set is returned in the \\code{test} component of the resulting\n",
       "\\code{randomForest} object.  For classification, the \\code{votes}\n",
       "component (for training or test set data) contain the votes the cases\n",
       "received for the classes.  If \\code{norm.votes=TRUE}, the fraction is\n",
       "given, which can be taken as predicted probabilities for the classes.\n",
       "\n",
       "\n",
       "For large data sets, especially those with large number of variables,\n",
       "calling \\code{randomForest} via the formula interface is not advised:\n",
       "There may be too much overhead in handling the formula.\n",
       "\n",
       "The ``local'' (or casewise) variable importance is computed as\n",
       "follows:  For classification, it is the increase in percent of times a\n",
       "case is OOB and misclassified when the variable is permuted.  For\n",
       "regression, it is the average increase in squared OOB residuals when\n",
       "the variable is permuted.\n",
       "\\end{Note}\n",
       "%\n",
       "\\begin{Author}\n",
       "Andy Liaw \\email{andy\\_liaw@merck.com} and Matthew Wiener\n",
       "\\email{matthew\\_wiener@merck.com}, based on original Fortran code by\n",
       "Leo Breiman and Adele Cutler.\n",
       "\\end{Author}\n",
       "%\n",
       "\\begin{References}\n",
       "Breiman, L. (2001), \\emph{Random Forests}, Machine Learning 45(1),\n",
       "5-32.\n",
       "\n",
       "Breiman, L (2002), ``Manual On Setting Up, Using, And Understanding\n",
       "Random Forests V3.1'', \\url{https://www.stat.berkeley.edu/~breiman/Using_random_forests_V3.1.pdf}.\n",
       "\\end{References}\n",
       "%\n",
       "\\begin{SeeAlso}\n",
       "\\code{\\LinkA{predict.randomForest}{predict.randomForest}}, \\code{\\LinkA{varImpPlot}{varImpPlot}}\n",
       "\\end{SeeAlso}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "## Classification:\n",
       "##data(iris)\n",
       "set.seed(71)\n",
       "iris.rf <- randomForest(Species ~ ., data=iris, importance=TRUE,\n",
       "                        proximity=TRUE)\n",
       "print(iris.rf)\n",
       "## Look at variable importance:\n",
       "round(importance(iris.rf), 2)\n",
       "## Do MDS on 1 - proximity:\n",
       "iris.mds <- cmdscale(1 - iris.rf$proximity, eig=TRUE)\n",
       "op <- par(pty=\"s\")\n",
       "pairs(cbind(iris[,1:4], iris.mds$points), cex=0.6, gap=0,\n",
       "      col=c(\"red\", \"green\", \"blue\")[as.numeric(iris$Species)],\n",
       "      main=\"Iris Data: Predictors and MDS of Proximity Based on RandomForest\")\n",
       "par(op)\n",
       "print(iris.mds$GOF)\n",
       "\n",
       "## The `unsupervised' case:\n",
       "set.seed(17)\n",
       "iris.urf <- randomForest(iris[, -5])\n",
       "MDSplot(iris.urf, iris$Species)\n",
       "\n",
       "## stratified sampling: draw 20, 30, and 20 of the species to grow each tree.\n",
       "(iris.rf2 <- randomForest(iris[1:4], iris$Species, \n",
       "                          sampsize=c(20, 30, 20)))\n",
       "\n",
       "## Regression:\n",
       "## data(airquality)\n",
       "set.seed(131)\n",
       "ozone.rf <- randomForest(Ozone ~ ., data=airquality, mtry=3,\n",
       "                         importance=TRUE, na.action=na.omit)\n",
       "print(ozone.rf)\n",
       "## Show \"importance\" of variables: higher value mean more important:\n",
       "round(importance(ozone.rf), 2)\n",
       "\n",
       "## \"x\" can be a matrix instead of a data frame:\n",
       "set.seed(17)\n",
       "x <- matrix(runif(5e2), 100)\n",
       "y <- gl(2, 50)\n",
       "(myrf <- randomForest(x, y))\n",
       "(predict(myrf, x))\n",
       "\n",
       "## \"complicated\" formula:\n",
       "(swiss.rf <- randomForest(sqrt(Fertility) ~ . - Catholic + I(Catholic < 50),\n",
       "                          data=swiss))\n",
       "(predict(swiss.rf, swiss))\n",
       "## Test use of 32-level factor as a predictor:\n",
       "set.seed(1)\n",
       "x <- data.frame(x1=gl(53, 10), x2=runif(530), y=rnorm(530))\n",
       "(rf1 <- randomForest(x[-3], x[[3]], ntree=10))\n",
       "\n",
       "## Grow no more than 4 nodes per tree:\n",
       "(treesize(randomForest(Species ~ ., data=iris, maxnodes=4, ntree=30)))\n",
       "\n",
       "## test proximity in regression\n",
       "iris.rrf <- randomForest(iris[-1], iris[[1]], ntree=101, proximity=TRUE, oob.prox=FALSE)\n",
       "str(iris.rrf$proximity)\n",
       "\n",
       "## Using weights: make versicolors having 3 times larger weights\n",
       "iris_wt <- ifelse( iris$Species == \"versicolor\", 3, 1 )\n",
       "set.seed(15)\n",
       "iris.wcrf <- randomForest(iris[-5], iris[[5]], weights=iris_wt, keep.inbag=TRUE)\n",
       "print(rowSums(iris.wcrf$inbag))\n",
       "set.seed(15)\n",
       "iris.wrrf <- randomForest(iris[-1], iris[[1]], weights=iris_wt, keep.inbag=TRUE)\n",
       "print(rowSums(iris.wrrf$inbag))\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "randomForest           package:randomForest            R Documentation\n",
       "\n",
       "_\bC_\bl_\ba_\bs_\bs_\bi_\bf_\bi_\bc_\ba_\bt_\bi_\bo_\bn _\ba_\bn_\bd _\bR_\be_\bg_\br_\be_\bs_\bs_\bi_\bo_\bn _\bw_\bi_\bt_\bh _\bR_\ba_\bn_\bd_\bo_\bm _\bF_\bo_\br_\be_\bs_\bt\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     ‘randomForest’ implements Breiman's random forest algorithm (based\n",
       "     on Breiman and Cutler's original Fortran code) for classification\n",
       "     and regression.  It can also be used in unsupervised mode for\n",
       "     assessing proximities among data points.\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     ## S3 method for class 'formula'\n",
       "     randomForest(formula, data=NULL, ..., subset, na.action=na.fail)\n",
       "     ## Default S3 method:\n",
       "     randomForest(x, y=NULL,  xtest=NULL, ytest=NULL, ntree=500,\n",
       "                  mtry=if (!is.null(y) && !is.factor(y))\n",
       "                  max(floor(ncol(x)/3), 1) else floor(sqrt(ncol(x))),\n",
       "                  weights=NULL,\n",
       "                  replace=TRUE, classwt=NULL, cutoff, strata,\n",
       "                  sampsize = if (replace) nrow(x) else ceiling(.632*nrow(x)),\n",
       "                  nodesize = if (!is.null(y) && !is.factor(y)) 5 else 1,\n",
       "                  maxnodes = NULL,\n",
       "                  importance=FALSE, localImp=FALSE, nPerm=1,\n",
       "                  proximity, oob.prox=proximity,\n",
       "                  norm.votes=TRUE, do.trace=FALSE,\n",
       "                  keep.forest=!is.null(y) && is.null(xtest), corr.bias=FALSE,\n",
       "                  keep.inbag=FALSE, ...)\n",
       "     ## S3 method for class 'randomForest'\n",
       "     print(x, ...)\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       "    data: an optional data frame containing the variables in the model.\n",
       "          By default the variables are taken from the environment which\n",
       "          ‘randomForest’ is called from.\n",
       "\n",
       "  subset: an index vector indicating which rows should be used.  (NOTE:\n",
       "          If given, this argument must be named.)\n",
       "\n",
       "na.action: A function to specify the action to be taken if NAs are\n",
       "          found.  (NOTE: If given, this argument must be named.)\n",
       "\n",
       "x, formula: a data frame or a matrix of predictors, or a formula\n",
       "          describing the model to be fitted (for the ‘print’ method, an\n",
       "          ‘randomForest’ object).\n",
       "\n",
       "       y: A response vector.  If a factor, classification is assumed,\n",
       "          otherwise regression is assumed.  If omitted, ‘randomForest’\n",
       "          will run in unsupervised mode.\n",
       "\n",
       "   xtest: a data frame or matrix (like ‘x’) containing predictors for\n",
       "          the test set.\n",
       "\n",
       "   ytest: response for the test set.\n",
       "\n",
       "   ntree: Number of trees to grow.  This should not be set to too small\n",
       "          a number, to ensure that every input row gets predicted at\n",
       "          least a few times.\n",
       "\n",
       "    mtry: Number of variables randomly sampled as candidates at each\n",
       "          split.  Note that the default values are different for\n",
       "          classification (sqrt(p) where p is number of variables in\n",
       "          ‘x’) and regression (p/3)\n",
       "\n",
       " weights: A vector of length same as ‘y’ that are positive weights used\n",
       "          only in sampling data to grow each tree (not used in any\n",
       "          other calculation)\n",
       "\n",
       " replace: Should sampling of cases be done with or without replacement?\n",
       "\n",
       " classwt: Priors of the classes.  Need not add up to one.  Ignored for\n",
       "          regression.\n",
       "\n",
       "  cutoff: (Classification only) A vector of length equal to number of\n",
       "          classes.  The `winning' class for an observation is the one\n",
       "          with the maximum ratio of proportion of votes to cutoff.\n",
       "          Default is 1/k where k is the number of classes (i.e.,\n",
       "          majority vote wins).\n",
       "\n",
       "  strata: A (factor) variable that is used for stratified sampling.\n",
       "\n",
       "sampsize: Size(s) of sample to draw.  For classification, if sampsize\n",
       "          is a vector of the length the number of strata, then sampling\n",
       "          is stratified by strata, and the elements of sampsize\n",
       "          indicate the numbers to be drawn from the strata.\n",
       "\n",
       "nodesize: Minimum size of terminal nodes.  Setting this number larger\n",
       "          causes smaller trees to be grown (and thus take less time).\n",
       "          Note that the default values are different for classification\n",
       "          (1) and regression (5).\n",
       "\n",
       "maxnodes: Maximum number of terminal nodes trees in the forest can\n",
       "          have.  If not given, trees are grown to the maximum possible\n",
       "          (subject to limits by ‘nodesize’).  If set larger than\n",
       "          maximum possible, a warning is issued.\n",
       "\n",
       "importance: Should importance of predictors be assessed?\n",
       "\n",
       "localImp: Should casewise importance measure be computed?  (Setting\n",
       "          this to ‘TRUE’ will override ‘importance’.)\n",
       "\n",
       "   nPerm: Number of times the OOB data are permuted per tree for\n",
       "          assessing variable importance.  Number larger than 1 gives\n",
       "          slightly more stable estimate, but not very effective.\n",
       "          Currently only implemented for regression.\n",
       "\n",
       "proximity: Should proximity measure among the rows be calculated?\n",
       "\n",
       "oob.prox: Should proximity be calculated only on ``out-of-bag'' data?\n",
       "\n",
       "norm.votes: If ‘TRUE’ (default), the final result of votes are\n",
       "          expressed as fractions.  If ‘FALSE’, raw vote counts are\n",
       "          returned (useful for combining results from different runs).\n",
       "          Ignored for regression.\n",
       "\n",
       "do.trace: If set to ‘TRUE’, give a more verbose output as\n",
       "          ‘randomForest’ is run.  If set to some integer, then running\n",
       "          output is printed for every ‘do.trace’ trees.\n",
       "\n",
       "keep.forest: If set to ‘FALSE’, the forest will not be retained in the\n",
       "          output object.  If ‘xtest’ is given, defaults to ‘FALSE’.\n",
       "\n",
       "corr.bias: perform bias correction for regression?  Note: Experimental.\n",
       "          Use at your own risk.\n",
       "\n",
       "keep.inbag: Should an ‘n’ by ‘ntree’ matrix be returned that keeps\n",
       "          track of which samples are ``in-bag'' in which trees (but not\n",
       "          how many times, if sampling with replacement)\n",
       "\n",
       "     ...: optional parameters to be passed to the low level function\n",
       "          ‘randomForest.default’.\n",
       "\n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     An object of class ‘randomForest’, which is a list with the\n",
       "     following components:\n",
       "\n",
       "    call: the original call to ‘randomForest’\n",
       "\n",
       "    type: one of ‘regression’, ‘classification’, or ‘unsupervised’.\n",
       "\n",
       "predicted: the predicted values of the input data based on out-of-bag\n",
       "          samples.\n",
       "\n",
       "importance: a matrix with ‘nclass’ + 2 (for classification) or two (for\n",
       "          regression) columns.  For classification, the first ‘nclass’\n",
       "          columns are the class-specific measures computed as mean\n",
       "          descrease in accuracy.  The ‘nclass’ + 1st column is the mean\n",
       "          descrease in accuracy over all classes.  The last column is\n",
       "          the mean decrease in Gini index.  For Regression, the first\n",
       "          column is the mean decrease in accuracy and the second the\n",
       "          mean decrease in MSE.  If ‘importance=FALSE’, the last\n",
       "          measure is still returned as a vector.\n",
       "\n",
       "importanceSD: The ``standard errors'' of the permutation-based\n",
       "          importance measure.  For classification, a ‘p’ by ‘nclass +\n",
       "          1’ matrix corresponding to the first ‘nclass + 1’ columns of\n",
       "          the importance matrix.  For regression, a length ‘p’ vector.\n",
       "\n",
       "localImp: a p by n matrix containing the casewise importance measures,\n",
       "          the [i,j] element of which is the importance of i-th variable\n",
       "          on the j-th case. ‘NULL’ if ‘localImp=FALSE’.\n",
       "\n",
       "   ntree: number of trees grown.\n",
       "\n",
       "    mtry: number of predictors sampled for spliting at each node.\n",
       "\n",
       "  forest: (a list that contains the entire forest; ‘NULL’ if\n",
       "          ‘randomForest’ is run in unsupervised mode or if\n",
       "          ‘keep.forest=FALSE’.\n",
       "\n",
       "err.rate: (classification only) vector error rates of the prediction on\n",
       "          the input data, the i-th element being the (OOB) error rate\n",
       "          for all trees up to the i-th.\n",
       "\n",
       "confusion: (classification only) the confusion matrix of the prediction\n",
       "          (based on OOB data).\n",
       "\n",
       "   votes: (classification only) a matrix with one row for each input\n",
       "          data point and one column for each class, giving the fraction\n",
       "          or number of (OOB) `votes' from the random forest.\n",
       "\n",
       "oob.times: number of times cases are `out-of-bag' (and thus used in\n",
       "          computing OOB error estimate)\n",
       "\n",
       "proximity: if ‘proximity=TRUE’ when ‘randomForest’ is called, a matrix\n",
       "          of proximity measures among the input (based on the frequency\n",
       "          that pairs of data points are in the same terminal nodes).\n",
       "\n",
       "     mse: (regression only) vector of mean square errors: sum of\n",
       "          squared residuals divided by ‘n’.\n",
       "\n",
       "     rsq: (regression only) ``pseudo R-squared'': 1 - ‘mse’ / Var(y).\n",
       "\n",
       "    test: if test set is given (through the ‘xtest’ or additionally\n",
       "          ‘ytest’ arguments), this component is a list which contains\n",
       "          the corresponding ‘predicted’, ‘err.rate’, ‘confusion’,\n",
       "          ‘votes’ (for classification) or ‘predicted’, ‘mse’ and ‘rsq’\n",
       "          (for regression) for the test set.  If ‘proximity=TRUE’,\n",
       "          there is also a component, ‘proximity’, which contains the\n",
       "          proximity among the test set as well as proximity between\n",
       "          test and training data.\n",
       "\n",
       "_\bN_\bo_\bt_\be:\n",
       "\n",
       "     The ‘forest’ structure is slightly different between\n",
       "     classification and regression.  For details on how the trees are\n",
       "     stored, see the help page for ‘getTree’.\n",
       "\n",
       "     If ‘xtest’ is given, prediction of the test set is done ``in\n",
       "     place'' as the trees are grown.  If ‘ytest’ is also given, and\n",
       "     ‘do.trace’ is set to some positive integer, then for every\n",
       "     ‘do.trace’ trees, the test set error is printed.  Results for the\n",
       "     test set is returned in the ‘test’ component of the resulting\n",
       "     ‘randomForest’ object.  For classification, the ‘votes’ component\n",
       "     (for training or test set data) contain the votes the cases\n",
       "     received for the classes.  If ‘norm.votes=TRUE’, the fraction is\n",
       "     given, which can be taken as predicted probabilities for the\n",
       "     classes.\n",
       "\n",
       "     For large data sets, especially those with large number of\n",
       "     variables, calling ‘randomForest’ via the formula interface is not\n",
       "     advised: There may be too much overhead in handling the formula.\n",
       "\n",
       "     The ``local'' (or casewise) variable importance is computed as\n",
       "     follows: For classification, it is the increase in percent of\n",
       "     times a case is OOB and misclassified when the variable is\n",
       "     permuted.  For regression, it is the average increase in squared\n",
       "     OOB residuals when the variable is permuted.\n",
       "\n",
       "_\bA_\bu_\bt_\bh_\bo_\br(_\bs):\n",
       "\n",
       "     Andy Liaw <mailto:andy_liaw@merck.com> and Matthew Wiener\n",
       "     <mailto:matthew_wiener@merck.com>, based on original Fortran code\n",
       "     by Leo Breiman and Adele Cutler.\n",
       "\n",
       "_\bR_\be_\bf_\be_\br_\be_\bn_\bc_\be_\bs:\n",
       "\n",
       "     Breiman, L. (2001), _Random Forests_, Machine Learning 45(1),\n",
       "     5-32.\n",
       "\n",
       "     Breiman, L (2002), ``Manual On Setting Up, Using, And\n",
       "     Understanding Random Forests V3.1'',\n",
       "     <https://www.stat.berkeley.edu/~breiman/Using_random_forests_V3.1.pdf>.\n",
       "\n",
       "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
       "\n",
       "     ‘predict.randomForest’, ‘varImpPlot’\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     ## Classification:\n",
       "     ##data(iris)\n",
       "     set.seed(71)\n",
       "     iris.rf <- randomForest(Species ~ ., data=iris, importance=TRUE,\n",
       "                             proximity=TRUE)\n",
       "     print(iris.rf)\n",
       "     ## Look at variable importance:\n",
       "     round(importance(iris.rf), 2)\n",
       "     ## Do MDS on 1 - proximity:\n",
       "     iris.mds <- cmdscale(1 - iris.rf$proximity, eig=TRUE)\n",
       "     op <- par(pty=\"s\")\n",
       "     pairs(cbind(iris[,1:4], iris.mds$points), cex=0.6, gap=0,\n",
       "           col=c(\"red\", \"green\", \"blue\")[as.numeric(iris$Species)],\n",
       "           main=\"Iris Data: Predictors and MDS of Proximity Based on RandomForest\")\n",
       "     par(op)\n",
       "     print(iris.mds$GOF)\n",
       "     \n",
       "     ## The `unsupervised' case:\n",
       "     set.seed(17)\n",
       "     iris.urf <- randomForest(iris[, -5])\n",
       "     MDSplot(iris.urf, iris$Species)\n",
       "     \n",
       "     ## stratified sampling: draw 20, 30, and 20 of the species to grow each tree.\n",
       "     (iris.rf2 <- randomForest(iris[1:4], iris$Species, \n",
       "                               sampsize=c(20, 30, 20)))\n",
       "     \n",
       "     ## Regression:\n",
       "     ## data(airquality)\n",
       "     set.seed(131)\n",
       "     ozone.rf <- randomForest(Ozone ~ ., data=airquality, mtry=3,\n",
       "                              importance=TRUE, na.action=na.omit)\n",
       "     print(ozone.rf)\n",
       "     ## Show \"importance\" of variables: higher value mean more important:\n",
       "     round(importance(ozone.rf), 2)\n",
       "     \n",
       "     ## \"x\" can be a matrix instead of a data frame:\n",
       "     set.seed(17)\n",
       "     x <- matrix(runif(5e2), 100)\n",
       "     y <- gl(2, 50)\n",
       "     (myrf <- randomForest(x, y))\n",
       "     (predict(myrf, x))\n",
       "     \n",
       "     ## \"complicated\" formula:\n",
       "     (swiss.rf <- randomForest(sqrt(Fertility) ~ . - Catholic + I(Catholic < 50),\n",
       "                               data=swiss))\n",
       "     (predict(swiss.rf, swiss))\n",
       "     ## Test use of 32-level factor as a predictor:\n",
       "     set.seed(1)\n",
       "     x <- data.frame(x1=gl(53, 10), x2=runif(530), y=rnorm(530))\n",
       "     (rf1 <- randomForest(x[-3], x[[3]], ntree=10))\n",
       "     \n",
       "     ## Grow no more than 4 nodes per tree:\n",
       "     (treesize(randomForest(Species ~ ., data=iris, maxnodes=4, ntree=30)))\n",
       "     \n",
       "     ## test proximity in regression\n",
       "     iris.rrf <- randomForest(iris[-1], iris[[1]], ntree=101, proximity=TRUE, oob.prox=FALSE)\n",
       "     str(iris.rrf$proximity)\n",
       "     \n",
       "     ## Using weights: make versicolors having 3 times larger weights\n",
       "     iris_wt <- ifelse( iris$Species == \"versicolor\", 3, 1 )\n",
       "     set.seed(15)\n",
       "     iris.wcrf <- randomForest(iris[-5], iris[[5]], weights=iris_wt, keep.inbag=TRUE)\n",
       "     print(rowSums(iris.wcrf$inbag))\n",
       "     set.seed(15)\n",
       "     iris.wrrf <- randomForest(iris[-1], iris[[1]], weights=iris_wt, keep.inbag=TRUE)\n",
       "     print(rowSums(iris.wrrf$inbag))\n",
       "     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?randomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XUkbhaJ0CGDm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction  no yes\n",
       "       no  891  78\n",
       "       yes 132 773\n",
       "                                          \n",
       "               Accuracy : 0.8879          \n",
       "                 95% CI : (0.8728, 0.9019)\n",
       "    No Information Rate : 0.5459          \n",
       "    P-Value [Acc > NIR] : < 2.2e-16       \n",
       "                                          \n",
       "                  Kappa : 0.7752          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.0002548       \n",
       "                                          \n",
       "            Sensitivity : 0.9083          \n",
       "            Specificity : 0.8710          \n",
       "         Pos Pred Value : 0.8541          \n",
       "         Neg Pred Value : 0.9195          \n",
       "             Prevalence : 0.4541          \n",
       "         Detection Rate : 0.4125          \n",
       "   Detection Prevalence : 0.4829          \n",
       "      Balanced Accuracy : 0.8897          \n",
       "                                          \n",
       "       'Positive' Class : yes             \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random Forest\n",
    "set.seed(123)\n",
    "RF_model1 <- randomForest(as.factor(OK) ~ ., data=training.data1, method=\"class\")\n",
    "RF_predict1 <- predict(RF_model1, testing.data1, type = \"class\")\n",
    "confusionMatrix(RF_predict1, as.factor(testing.data1$OK), positive = 'yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgdCy3jOmM61"
   },
   "source": [
    "**Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gKfTuGGxEo-f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction  no yes\n",
       "       no  794 146\n",
       "       yes 229 705\n",
       "                                         \n",
       "               Accuracy : 0.7999         \n",
       "                 95% CI : (0.781, 0.8178)\n",
       "    No Information Rate : 0.5459         \n",
       "    P-Value [Acc > NIR] : < 2.2e-16      \n",
       "                                         \n",
       "                  Kappa : 0.5997         \n",
       "                                         \n",
       " Mcnemar's Test P-Value : 2.291e-05      \n",
       "                                         \n",
       "            Sensitivity : 0.8284         \n",
       "            Specificity : 0.7761         \n",
       "         Pos Pred Value : 0.7548         \n",
       "         Neg Pred Value : 0.8447         \n",
       "             Prevalence : 0.4541         \n",
       "         Detection Rate : 0.3762         \n",
       "   Detection Prevalence : 0.4984         \n",
       "      Balanced Accuracy : 0.8023         \n",
       "                                         \n",
       "       'Positive' Class : yes            \n",
       "                                         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "set.seed(123)\n",
    "NB_model1 <- naiveBayes(as.factor(OK) ~ ., data=training.data1)\n",
    "NB_predict1 <- predict(NB_model1, testing.data1, type = \"class\")\n",
    "confusionMatrix(NB_predict1, as.factor(testing.data1$OK), positive = 'yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJPXgCYIYU78"
   },
   "source": [
    "**Support Vector Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "p_46U2nQYT3n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction  no yes\n",
       "       no  839 144\n",
       "       yes 184 707\n",
       "                                         \n",
       "               Accuracy : 0.825          \n",
       "                 95% CI : (0.807, 0.8419)\n",
       "    No Information Rate : 0.5459         \n",
       "    P-Value [Acc > NIR] : < 2e-16        \n",
       "                                         \n",
       "                  Kappa : 0.6484         \n",
       "                                         \n",
       " Mcnemar's Test P-Value : 0.03129        \n",
       "                                         \n",
       "            Sensitivity : 0.8308         \n",
       "            Specificity : 0.8201         \n",
       "         Pos Pred Value : 0.7935         \n",
       "         Neg Pred Value : 0.8535         \n",
       "             Prevalence : 0.4541         \n",
       "         Detection Rate : 0.3773         \n",
       "   Detection Prevalence : 0.4755         \n",
       "      Balanced Accuracy : 0.8255         \n",
       "                                         \n",
       "       'Positive' Class : yes            \n",
       "                                         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Support Vector Machine (NOTA: toma algunos minutos su ejecución)\n",
    "set.seed(123)\n",
    "SVM_model1 <- svm(as.factor(OK) ~ ., data = training.data1, cost = 10, scale = FALSE)\n",
    "SVM_predict1 <- predict(SVM_model1, testing.data1, type = \"class\")\n",
    "confusionMatrix(SVM_predict1, as.factor(testing.data1$OK), positive = 'yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction  no yes\n",
       "       no  434  46\n",
       "       yes  65 392\n",
       "                                          \n",
       "               Accuracy : 0.8815          \n",
       "                 95% CI : (0.8591, 0.9015)\n",
       "    No Information Rate : 0.5326          \n",
       "    P-Value [Acc > NIR] : < 2e-16         \n",
       "                                          \n",
       "                  Kappa : 0.7627          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.08755         \n",
       "                                          \n",
       "            Sensitivity : 0.8950          \n",
       "            Specificity : 0.8697          \n",
       "         Pos Pred Value : 0.8578          \n",
       "         Neg Pred Value : 0.9042          \n",
       "             Prevalence : 0.4674          \n",
       "         Detection Rate : 0.4184          \n",
       "   Detection Prevalence : 0.4877          \n",
       "      Balanced Accuracy : 0.8824          \n",
       "                                          \n",
       "       'Positive' Class : yes             \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction  no yes\n",
       "       no  379  74\n",
       "       yes 120 364\n",
       "                                          \n",
       "               Accuracy : 0.793           \n",
       "                 95% CI : (0.7656, 0.8185)\n",
       "    No Information Rate : 0.5326          \n",
       "    P-Value [Acc > NIR] : < 2.2e-16       \n",
       "                                          \n",
       "                  Kappa : 0.5868          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.001234        \n",
       "                                          \n",
       "            Sensitivity : 0.8311          \n",
       "            Specificity : 0.7595          \n",
       "         Pos Pred Value : 0.7521          \n",
       "         Neg Pred Value : 0.8366          \n",
       "             Prevalence : 0.4674          \n",
       "         Detection Rate : 0.3885          \n",
       "   Detection Prevalence : 0.5165          \n",
       "      Balanced Accuracy : 0.7953          \n",
       "                                          \n",
       "       'Positive' Class : yes             \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction  no yes\n",
       "       no  411  80\n",
       "       yes  88 358\n",
       "                                          \n",
       "               Accuracy : 0.8207          \n",
       "                 95% CI : (0.7946, 0.8448)\n",
       "    No Information Rate : 0.5326          \n",
       "    P-Value [Acc > NIR] : <2e-16          \n",
       "                                          \n",
       "                  Kappa : 0.6403          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.5892          \n",
       "                                          \n",
       "            Sensitivity : 0.8174          \n",
       "            Specificity : 0.8236          \n",
       "         Pos Pred Value : 0.8027          \n",
       "         Neg Pred Value : 0.8371          \n",
       "             Prevalence : 0.4674          \n",
       "         Detection Rate : 0.3821          \n",
       "   Detection Prevalence : 0.4760          \n",
       "      Balanced Accuracy : 0.8205          \n",
       "                                          \n",
       "       'Positive' Class : yes             \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se realiza la prueba con 90/10\n",
    "set.seed(123)\n",
    "ratio2 = sample(1:nrow(working.data), size = 0.90*nrow(working.data))\n",
    "training.data2 = working.data[ratio2,]\n",
    "testing.data2 = working.data[-ratio2,]\n",
    "\n",
    "# Random Forest\n",
    "\n",
    "RF_model2 <- randomForest(as.factor(OK) ~ ., data=training.data2, method=\"class\")\n",
    "RF_predict2 <- predict(RF_model2, testing.data2, type = \"class\")\n",
    "cat(\"Random Forest\")\n",
    "confusionMatrix(RF_predict2, as.factor(testing.data2$OK), positive = 'yes')\n",
    "\n",
    "# Naive Bayes\n",
    "NB_model2 <- naiveBayes(as.factor(OK) ~ ., data=training.data2)\n",
    "NB_predict2 <- predict(NB_model2, testing.data2, type = \"class\")\n",
    "cat(\"Naive Bayes\")\n",
    "confusionMatrix(NB_predict2, as.factor(testing.data2$OK), positive = 'yes')\n",
    "\n",
    "\n",
    "# Support Vector Machine (NOTA: toma algunos minutos su ejecución)\n",
    "SVM_model2 <- svm(as.factor(OK) ~ ., data = training.data2, cost = 10, scale = FALSE)\n",
    "SVM_predict2 <- predict(SVM_model2, testing.data2, type = \"class\")\n",
    "cat(\"Support Vector Machine\")\n",
    "confusionMatrix(SVM_predict2, as.factor(testing.data2$OK), positive = 'yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction   no  yes\n",
       "       no  1338  122\n",
       "       yes  208 1143\n",
       "                                          \n",
       "               Accuracy : 0.8826          \n",
       "                 95% CI : (0.8701, 0.8943)\n",
       "    No Information Rate : 0.55            \n",
       "    P-Value [Acc > NIR] : < 2.2e-16       \n",
       "                                          \n",
       "                  Kappa : 0.7643          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 2.881e-06       \n",
       "                                          \n",
       "            Sensitivity : 0.9036          \n",
       "            Specificity : 0.8655          \n",
       "         Pos Pred Value : 0.8460          \n",
       "         Neg Pred Value : 0.9164          \n",
       "             Prevalence : 0.4500          \n",
       "         Detection Rate : 0.4066          \n",
       "   Detection Prevalence : 0.4806          \n",
       "      Balanced Accuracy : 0.8845          \n",
       "                                          \n",
       "       'Positive' Class : yes             \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction   no  yes\n",
       "       no  1199  216\n",
       "       yes  347 1049\n",
       "                                          \n",
       "               Accuracy : 0.7997          \n",
       "                 95% CI : (0.7844, 0.8144)\n",
       "    No Information Rate : 0.55            \n",
       "    P-Value [Acc > NIR] : < 2.2e-16       \n",
       "                                          \n",
       "                  Kappa : 0.5992          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 4.281e-08       \n",
       "                                          \n",
       "            Sensitivity : 0.8292          \n",
       "            Specificity : 0.7755          \n",
       "         Pos Pred Value : 0.7514          \n",
       "         Neg Pred Value : 0.8473          \n",
       "             Prevalence : 0.4500          \n",
       "         Detection Rate : 0.3732          \n",
       "   Detection Prevalence : 0.4966          \n",
       "      Balanced Accuracy : 0.8024          \n",
       "                                          \n",
       "       'Positive' Class : yes             \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction   no  yes\n",
       "       no  1235  200\n",
       "       yes  311 1065\n",
       "                                          \n",
       "               Accuracy : 0.8182          \n",
       "                 95% CI : (0.8035, 0.8323)\n",
       "    No Information Rate : 0.55            \n",
       "    P-Value [Acc > NIR] : < 2.2e-16       \n",
       "                                          \n",
       "                  Kappa : 0.6357          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 1.138e-06       \n",
       "                                          \n",
       "            Sensitivity : 0.8419          \n",
       "            Specificity : 0.7988          \n",
       "         Pos Pred Value : 0.7740          \n",
       "         Neg Pred Value : 0.8606          \n",
       "             Prevalence : 0.4500          \n",
       "         Detection Rate : 0.3789          \n",
       "   Detection Prevalence : 0.4895          \n",
       "      Balanced Accuracy : 0.8204          \n",
       "                                          \n",
       "       'Positive' Class : yes             \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se realiza la prueba con 70/30\n",
    "set.seed(123)\n",
    "ratio3 = sample(1:nrow(working.data), size = 0.70*nrow(working.data))\n",
    "training.data3 = working.data[ratio3,]\n",
    "testing.data3 = working.data[-ratio3,]\n",
    "\n",
    "# Random Forest\n",
    "\n",
    "RF_model3 <- randomForest(as.factor(OK) ~ ., data=training.data3, method=\"class\")\n",
    "RF_predict3 <- predict(RF_model3, testing.data3, type = \"class\")\n",
    "cat(\"Random Forest\")\n",
    "confusionMatrix(RF_predict3, as.factor(testing.data3$OK), positive = 'yes')\n",
    "\n",
    "# Naive Bayes\n",
    "NB_model3 <- naiveBayes(as.factor(OK) ~ ., data=training.data3)\n",
    "NB_predict3 <- predict(NB_model3, testing.data3, type = \"class\")\n",
    "cat(\"Naive Bayes\")\n",
    "confusionMatrix(NB_predict3, as.factor(testing.data3$OK), positive = 'yes')\n",
    "\n",
    "\n",
    "# Support Vector Machine (NOTA: toma algunos minutos su ejecución)\n",
    "SVM_model3 <- svm(as.factor(OK) ~ ., data = training.data3, cost = 10, scale = FALSE)\n",
    "SVM_predict3 <- predict(SVM_model3, testing.data3, type = \"class\")\n",
    "cat(\"Support Vector Machine\")\n",
    "confusionMatrix(SVM_predict3, as.factor(testing.data3$OK), positive = 'yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction   no  yes\n",
       "       no  1792  158\n",
       "       yes  276 1521\n",
       "                                          \n",
       "               Accuracy : 0.8842          \n",
       "                 95% CI : (0.8735, 0.8943)\n",
       "    No Information Rate : 0.5519          \n",
       "    P-Value [Acc > NIR] : < 2.2e-16       \n",
       "                                          \n",
       "                  Kappa : 0.7674          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 1.952e-08       \n",
       "                                          \n",
       "            Sensitivity : 0.9059          \n",
       "            Specificity : 0.8665          \n",
       "         Pos Pred Value : 0.8464          \n",
       "         Neg Pred Value : 0.9190          \n",
       "             Prevalence : 0.4481          \n",
       "         Detection Rate : 0.4059          \n",
       "   Detection Prevalence : 0.4796          \n",
       "      Balanced Accuracy : 0.8862          \n",
       "                                          \n",
       "       'Positive' Class : yes             \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction   no  yes\n",
       "       no  1598  267\n",
       "       yes  470 1412\n",
       "                                          \n",
       "               Accuracy : 0.8033          \n",
       "                 95% CI : (0.7902, 0.8159)\n",
       "    No Information Rate : 0.5519          \n",
       "    P-Value [Acc > NIR] : < 2.2e-16       \n",
       "                                          \n",
       "                  Kappa : 0.6068          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 1.001e-13       \n",
       "                                          \n",
       "            Sensitivity : 0.8410          \n",
       "            Specificity : 0.7727          \n",
       "         Pos Pred Value : 0.7503          \n",
       "         Neg Pred Value : 0.8568          \n",
       "             Prevalence : 0.4481          \n",
       "         Detection Rate : 0.3768          \n",
       "   Detection Prevalence : 0.5023          \n",
       "      Balanced Accuracy : 0.8069          \n",
       "                                          \n",
       "       'Positive' Class : yes             \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction   no  yes\n",
       "       no  1650  257\n",
       "       yes  418 1422\n",
       "                                         \n",
       "               Accuracy : 0.8199         \n",
       "                 95% CI : (0.8072, 0.832)\n",
       "    No Information Rate : 0.5519         \n",
       "    P-Value [Acc > NIR] : < 2.2e-16      \n",
       "                                         \n",
       "                  Kappa : 0.639          \n",
       "                                         \n",
       " Mcnemar's Test P-Value : 7.348e-10      \n",
       "                                         \n",
       "            Sensitivity : 0.8469         \n",
       "            Specificity : 0.7979         \n",
       "         Pos Pred Value : 0.7728         \n",
       "         Neg Pred Value : 0.8652         \n",
       "             Prevalence : 0.4481         \n",
       "         Detection Rate : 0.3795         \n",
       "   Detection Prevalence : 0.4911         \n",
       "      Balanced Accuracy : 0.8224         \n",
       "                                         \n",
       "       'Positive' Class : yes            \n",
       "                                         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se realiza la prueba con 60/40\n",
    "set.seed(123)\n",
    "ratio4 = sample(1:nrow(working.data), size = 0.60*nrow(working.data))\n",
    "training.data4 = working.data[ratio4,]\n",
    "testing.data4 = working.data[-ratio4,]\n",
    "\n",
    "# Random Forest\n",
    "\n",
    "RF_model4 <- randomForest(as.factor(OK) ~ ., data=training.data4, method=\"class\")\n",
    "RF_predict4 <- predict(RF_model4, testing.data4, type = \"class\")\n",
    "cat(\"Random Forest\")\n",
    "confusionMatrix(RF_predict4, as.factor(testing.data4$OK), positive = 'yes')\n",
    "\n",
    "# Naive Bayes\n",
    "NB_model4 <- naiveBayes(as.factor(OK) ~ ., data=training.data4)\n",
    "NB_predict4 <- predict(NB_model4, testing.data4, type = \"class\")\n",
    "cat(\"Naive Bayes\")\n",
    "confusionMatrix(NB_predict4, as.factor(testing.data4$OK), positive = 'yes')\n",
    "\n",
    "\n",
    "# Support Vector Machine (NOTA: toma algunos minutos su ejecución)\n",
    "SVM_model4 <- svm(as.factor(OK) ~ ., data = training.data4, cost = 10, scale = FALSE)\n",
    "SVM_predict4 <- predict(SVM_model4, testing.data4, type = \"class\")\n",
    "cat(\"Support Vector Machine\")\n",
    "confusionMatrix(SVM_predict4, as.factor(testing.data4$OK), positive = 'yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0lOmoAidQun"
   },
   "source": [
    "# Ejercicio 3: Implementación de una Red Neuronal\n",
    "A continuación se declara, entrena y evalúa un modelo de Red Neuronal. Esta primera declaración viene con una configuración inicial, que se podrá modificar para ver posibles mejoras en el desempeño de esta red.\n",
    "\n",
    "Esta configuración considera lo siguiente:\n",
    "\n",
    "*     **Nótese que sólo se utilizan algunos atributos del dataset**, que vienen en la declaración de la fórmula (1er argumento) de nnet(). Se pueden eliminar algunos y ver si mejora el desempeño.\n",
    "\n",
    "*     Se usa una única capa escondida o intermedia. Su cantidad de nodos está dada por el atributo 'size'. Se puede agrandar o reducir para ver posibles mejoras.\n",
    "\n",
    "*     La cantidad de iteraciones para mejorar el entrenamiento se da por el atributo 'maxit'. Se puede aumentar, esperando mejorar el desempeño.\n",
    "\n",
    "*     El atributo 'maxNWts' limita el tamaño interno de la red, que dadas las restricciones de capacidad de procesamiento que entrega Google Colab, conviene acotarlo, para evitar sobrepasar la memora y tener una ejecución fallida. No es necesario modificar este atributo.\n",
    "\n",
    "Hay otros atributos posibles de analizar y modificar en https://www.rdocumentation.org/packages/nnet/versions/7.3-14/topics/nnet. Nótese que la configuración por defecto usa una activación logística, pero es posible aplicar softmax o linout, pero eso requiere de parámetros adicionales.\n",
    "\n",
    "Ojo/recomendación: dada la naturaleza aleatoria del comportamiento del entrenamiento, en ocasiones la red neuronal no entrega resultados para la clase menos representada y genera un error. En cuyo caso, sólo basta con volver a ejecutar el código, para que - aleatoriamente - logre dar resultados en dicha clase.\n",
    "\n",
    "**Ejercicio 3:**\n",
    "\n",
    "Probar diferentes versiones del modelo, cambiando:\n",
    "*     Los atributos considerados. Por simplicidad se recomienda sólo eliminar algunos de la lista original, para ver si en alguna ejecución esa eliminación genera mejores resultados.\n",
    "*     La cantidad de nodos de la capa escondida (size).\n",
    "*     La cantidad de iteraciones (maxit).\n",
    "\n",
    "Por simplicidad de este ejercicio, se recomienda sólo probar 4 combinaciones de cada uno de los 3 elementos a cambiar. Se pueden elegir los valores de esos cambios y documentar en una tabla de ejecuciones comparadas para contestar la pregunta 3.1.\n",
    "\n",
    "**Preg 3.1** (1.8 puntos): ¿Cuáles son los parámetros de ejecución del modelo que dan el mejor desempeño de la Red Neuronal?\n",
    "\n",
    "**Preg 3.2** (0.7 puntos): ¿Logra superar al mejor modelo de los primeros 3 modelos? ¿Por qué considera que si o no y qué caracteristica distinta entre estos 2 modelos hace la diferencia? (En cualquier caso, se pide una posible y teórica explicación de por qué es mejor/peor que ese otro modelo.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinaciones de atributos\n",
    "atributos1 = as.factor(OK) ~ Edad + Ocupación + EstadoCivil + Educación + Duración + NumContactos + EmpTasaVar + NumEmpleados\n",
    "atributos2 = as.factor(OK) ~ Edad + Ocupación + EstadoCivil + Educación + Duración + NumContactos + EmpTasaVar\n",
    "atributos3 = as.factor(OK) ~ Edad + Ocupación + EstadoCivil + Educación + Duración + NumContactos\n",
    "atributos4 = as.factor(OK) ~ Edad + Ocupación + Educación + Duración + NumContactos\n",
    "atributos = c(atributos1, atributos2, atributos3, atributos4)\n",
    "\n",
    "# Combinaciones de cantidad de nodos de la capa intermedia\n",
    "nodos1 = 25\n",
    "nodos2 = NULL\n",
    "nodos3 = NULL\n",
    "nodos4 = NULL\n",
    "nodos = c(nodos1, nodos2, nodos3, nodos4)\n",
    "\n",
    "# Combinaciones de cantidad de iteraciones\n",
    "iteraciones1 = 3000\n",
    "iteraciones2 = NULL\n",
    "iteraciones3 = NULL\n",
    "iteraciones4 = NULL\n",
    "iteraciones = c(iteraciones1, iteraciones2, iteraciones3, iteraciones4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Edad             Ocupación      EstadoCivil                 Educación   \n",
       " Min.   :18.00   admin.     :2048   divorced: 776   basic.4y           : 783  \n",
       " 1st Qu.:32.00   blue-collar:1461   married :4432   basic.6y           : 399  \n",
       " Median :37.00   technician :1206   single  :2285   basic.9y           : 985  \n",
       " Mean   :40.19   services   : 656                   high.school        :1805  \n",
       " 3rd Qu.:48.00   management : 564                   illiterate         :   4  \n",
       " Max.   :98.00   retired    : 456                   professional.course: 979  \n",
       "                 (Other)    :1102                   university.degree  :2538  \n",
       " Hipotecario          Consumo            Contacto             Mes           \n",
       " Length:7493        Length:7493        Length:7493        Length:7493       \n",
       " Class :character   Class :character   Class :character   Class :character  \n",
       " Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n",
       "                                                                            \n",
       "                                                                            \n",
       "                                                                            \n",
       "                                                                            \n",
       "     Día               Duración       NumContactos    ResultadoPrevio   \n",
       " Length:7493        Min.   :   1.0   Min.   : 1.000   Length:7493       \n",
       " Class :character   1st Qu.: 137.0   1st Qu.: 1.000   Class :character  \n",
       " Mode  :character   Median : 255.0   Median : 2.000   Mode  :character  \n",
       "                    Mean   : 373.3   Mean   : 2.359                     \n",
       "                    3rd Qu.: 501.0   3rd Qu.: 3.000                     \n",
       "                    Max.   :4199.0   Max.   :41.000                     \n",
       "                                                                        \n",
       "   EmpTasaVar           IPC             ICC          NumEmpleados \n",
       " Min.   :-3.4000   Min.   :92.20   Min.   :-50.80   Min.   :4964  \n",
       " 1st Qu.:-1.8000   1st Qu.:92.89   1st Qu.:-42.70   1st Qu.:5099  \n",
       " Median :-0.1000   Median :93.44   Median :-41.80   Median :5191  \n",
       " Mean   :-0.4178   Mean   :93.49   Mean   :-40.27   Mean   :5140  \n",
       " 3rd Qu.: 1.4000   3rd Qu.:93.99   3rd Qu.:-36.40   3rd Qu.:5228  \n",
       " Max.   : 1.4000   Max.   :94.77   Max.   :-26.90   Max.   :5228  \n",
       "                                                                  \n",
       "      OK           \n",
       " Length:7493       \n",
       " Class :character  \n",
       " Mode  :character  \n",
       "                   \n",
       "                   \n",
       "                   \n",
       "                   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training.data1$Ocupación <- as.factor(training.data1$Ocupación)\n",
    "training.data1$EstadoCivil <- as.factor(training.data1$EstadoCivil)\n",
    "training.data1$Educación <- as.factor(training.data1$Educación)\n",
    "summary(training.data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "WkQR7kxddP_P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# weights:  626\n",
      "initial  value 5261.260805 \n",
      "iter  10 value 4304.832801\n",
      "iter  20 value 4012.487322\n",
      "iter  30 value 3341.109773\n",
      "iter  40 value 2944.893959\n",
      "iter  50 value 2887.548570\n",
      "iter  60 value 2852.089537\n",
      "iter  70 value 2699.855088\n",
      "iter  80 value 2529.102310\n",
      "iter  90 value 2499.641387\n",
      "iter 100 value 2495.193127\n",
      "iter 110 value 2492.793068\n",
      "final  value 2492.633366 \n",
      "converged\n"
     ]
    }
   ],
   "source": [
    "# Red Neuronal\n",
    "# Lista original de atributos: Edad+Ocupación+EstadoCivil+Educación+Duración+NumContactos+EmpTasaVar+NumEmpleados\n",
    "set.seed(123)\n",
    "NN_model <- nnet(\n",
    "    atributos1,\n",
    "    data = training.data1, MaxNWts = 10000,\n",
    "    size = nodos1, maxit = iteraciones1 # Combinación 1\n",
    ")\n",
    "NN_predict <- predict(NN_model, testing.data1, type=\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados Red Neuronal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          Observación\n",
       "Predicción  no yes\n",
       "       no  843  94\n",
       "       yes 180 757"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:     0.8537887\n",
      "Sensitivity:  0.8240469\n",
      "Specificity:  0.8895417"
     ]
    }
   ],
   "source": [
    "# A continuación se muestra el resultado de evaluación\n",
    "cat(\"Resultados Red Neuronal\\n\")\n",
    "confTable <- table(\"Predicción\" = NN_predict, \"Observación\" = testing.data1$OK)\n",
    "confTable\n",
    "\n",
    "accuracy <- (confTable[1,1] + confTable[2,2]) / dim(testing.data1)[1]\n",
    "cat(\"\\nAccuracy:    \", accuracy)\n",
    "\n",
    "sensitivity <- confTable[1,1] / (confTable[1, 1] + confTable[2, 1])\n",
    "cat(\"\\nSensitivity: \", sensitivity)\n",
    "\n",
    "specificity <- confTable[2,2] / (confTable[1, 2] + confTable[2, 2])\n",
    "cat(\"\\nSpecificity: \", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction  no yes\n",
       "       no  843  94\n",
       "       yes 180 757\n",
       "                                         \n",
       "               Accuracy : 0.8538         \n",
       "                 95% CI : (0.837, 0.8695)\n",
       "    No Information Rate : 0.5459         \n",
       "    P-Value [Acc > NIR] : < 2.2e-16      \n",
       "                                         \n",
       "                  Kappa : 0.7076         \n",
       "                                         \n",
       " Mcnemar's Test P-Value : 2.821e-07      \n",
       "                                         \n",
       "            Sensitivity : 0.8240         \n",
       "            Specificity : 0.8895         \n",
       "         Pos Pred Value : 0.8997         \n",
       "         Neg Pred Value : 0.8079         \n",
       "             Prevalence : 0.5459         \n",
       "         Detection Rate : 0.4498         \n",
       "   Detection Prevalence : 0.5000         \n",
       "      Balanced Accuracy : 0.8568         \n",
       "                                         \n",
       "       'Positive' Class : no             \n",
       "                                         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temporal <- confusionMatrix(data = as.factor(NN_predict), reference = as.factor(testing.data1$OK), positive = 'no')\n",
    "temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para comparar desempeño de Redes neuronales\n",
    "\n",
    "comparador_RRNN <- function(\n",
    "    datos_entrenamiento,\n",
    "    datos_validacion,\n",
    "    atributos = c(atributos1),\n",
    "    nodos = c(nodos1),\n",
    "    iteraciones = c(iteraciones1)\n",
    ") {\n",
    "    hora_inicio = Sys.time()\n",
    "    contador = 1\n",
    "    rows = length(atributos) * length(nodos) * length(iteraciones)\n",
    "    \n",
    "    dataframe_final <- data.frame(\n",
    "        Modelos = NA * 1:rows,\n",
    "        Atributos = NA * 1:rows,\n",
    "        Nodos = NA * 1:rows,\n",
    "        Nodos_Valor = NA * 1:rows,\n",
    "        Iteraciones = NA * 1:rows,\n",
    "        Iteraciones_Valor = NA * 1:rows,\n",
    "        Exactitud = NA * 1:rows,\n",
    "        Sensibilidad = NA * 1:rows,\n",
    "        Especificidad= NA * 1:rows\n",
    "    )\n",
    "    \n",
    "    for(atributo in seq_along(atributos)) {\n",
    "        for(nodo in seq_along(nodos)) {\n",
    "            for(iteracion in seq_along(iteraciones)) {\n",
    "                cat(paste0(\"\\nModelo \", contador, \", atributo: \", atributo, \", nodo: \", nodo, \", iteración: \", iteracion, \"\\n\"))\n",
    "                modelo_RN <- nnet(\n",
    "                    atributos[[atributo]], data = datos_entrenamiento, MaxNWts = 10000,\n",
    "                    size = nodos[[nodo]], maxit = iteraciones[[iteracion]]\n",
    "                )\n",
    "                prediccion_RN <- predict(modelo_RN, datos_validacion, type=\"class\")\n",
    "                matriz <- confusionMatrix(data = as.factor(prediccion_RN), reference = as.factor(datos_validacion$OK), positive = \"no\")\n",
    "    \n",
    "                dataframe_final[contador, 1] <- paste(\"Modelo\", contador)\n",
    "                dataframe_final[contador, 2] <- paste0(\"atributo\", atributo)\n",
    "                dataframe_final[contador, 3] <- paste0(\"nodo\", nodo)\n",
    "                dataframe_final[contador, 4] <- nodos[[nodo]]\n",
    "                dataframe_final[contador, 5] <- paste0(\"iteracion\", iteracion)\n",
    "                dataframe_final[contador, 6] <- iteraciones[[iteracion]]\n",
    "                dataframe_final[contador, 7] <- round(matriz$overall[1], 4)\n",
    "                dataframe_final[contador, 8] <- round(matriz$byClass[1], 4)\n",
    "                dataframe_final[contador, 9] <- round(matriz$byClass[2], 4)\n",
    "                contador <- contador + 1\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return(dataframe_final)\n",
    "    hora_final = Sys.time()\n",
    "    hora_inicio - hora_final\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo 1, atributo: 1, nodo: 1, iteración: 1\n",
      "# weights:  626\n",
      "initial  value 5261.260805 \n",
      "iter  10 value 4304.832801\n",
      "iter  20 value 4012.487322\n",
      "iter  30 value 3341.109773\n",
      "iter  40 value 2944.893959\n",
      "iter  50 value 2887.548570\n",
      "iter  60 value 2852.089537\n",
      "iter  70 value 2699.855088\n",
      "iter  80 value 2529.102310\n",
      "iter  90 value 2499.641387\n",
      "iter 100 value 2495.193127\n",
      "iter 110 value 2492.793068\n",
      "final  value 2492.633366 \n",
      "converged\n",
      "\n",
      "Modelo 2, atributo: 2, nodo: 1, iteración: 1\n",
      "# weights:  601\n",
      "initial  value 9915.831567 \n",
      "iter  10 value 4133.443479\n",
      "iter  20 value 3480.557350\n",
      "iter  30 value 3163.188380\n",
      "iter  40 value 3031.025201\n",
      "iter  50 value 2909.736355\n",
      "iter  60 value 2723.522435\n",
      "iter  70 value 2570.083174\n",
      "iter  80 value 2530.584332\n",
      "iter  90 value 2509.133175\n",
      "iter 100 value 2498.056506\n",
      "iter 110 value 2496.795128\n",
      "iter 120 value 2493.391109\n",
      "iter 130 value 2490.446985\n",
      "iter 140 value 2483.948190\n",
      "iter 150 value 2483.713730\n",
      "iter 160 value 2482.988487\n",
      "iter 170 value 2478.755285\n",
      "iter 180 value 2474.613826\n",
      "iter 190 value 2469.980785\n",
      "iter 200 value 2458.597119\n",
      "iter 210 value 2452.862476\n",
      "iter 220 value 2448.704953\n",
      "iter 230 value 2447.864959\n",
      "final  value 2447.846843 \n",
      "converged\n",
      "\n",
      "Modelo 3, atributo: 3, nodo: 1, iteración: 1\n",
      "# weights:  576\n",
      "initial  value 5418.149868 \n",
      "iter  10 value 4137.522829\n",
      "iter  20 value 3882.808905\n",
      "iter  30 value 3707.204364\n",
      "iter  40 value 3582.437673\n",
      "iter  50 value 3487.374958\n",
      "iter  60 value 3438.693883\n",
      "iter  70 value 3423.267094\n",
      "iter  80 value 3406.327786\n",
      "iter  90 value 3385.297895\n",
      "iter 100 value 3366.757747\n",
      "iter 110 value 3350.433267\n",
      "iter 120 value 3337.489958\n",
      "iter 130 value 3329.867373\n",
      "iter 140 value 3325.430110\n",
      "iter 150 value 3317.037455\n",
      "iter 160 value 3306.848172\n",
      "iter 170 value 3294.825247\n",
      "iter 180 value 3285.435616\n",
      "iter 190 value 3279.424118\n",
      "iter 200 value 3275.463630\n",
      "iter 210 value 3272.160742\n",
      "iter 220 value 3268.812762\n",
      "iter 230 value 3266.914641\n",
      "iter 240 value 3265.633376\n",
      "iter 250 value 3264.335264\n",
      "iter 260 value 3263.235860\n",
      "iter 270 value 3262.248513\n",
      "iter 280 value 3261.787584\n",
      "iter 290 value 3261.552639\n",
      "iter 300 value 3261.279584\n",
      "iter 310 value 3260.994574\n",
      "iter 320 value 3260.638444\n",
      "iter 330 value 3260.447205\n",
      "iter 340 value 3260.236288\n",
      "iter 350 value 3260.120476\n",
      "iter 360 value 3259.953778\n",
      "iter 370 value 3259.721418\n",
      "iter 380 value 3259.598078\n",
      "iter 390 value 3259.503594\n",
      "iter 400 value 3259.354713\n",
      "iter 410 value 3259.292901\n",
      "iter 420 value 3259.177101\n",
      "iter 430 value 3259.081599\n",
      "iter 440 value 3258.957082\n",
      "iter 450 value 3258.851386\n",
      "iter 460 value 3258.773305\n",
      "final  value 3258.690637 \n",
      "converged\n",
      "\n",
      "Modelo 4, atributo: 4, nodo: 1, iteración: 1\n",
      "# weights:  526\n",
      "initial  value 6165.647542 \n",
      "iter  10 value 4291.739618\n",
      "iter  20 value 4085.072398\n",
      "iter  30 value 4003.866727\n",
      "iter  40 value 3801.773839\n",
      "iter  50 value 3703.061253\n",
      "iter  60 value 3556.268751\n",
      "iter  70 value 3518.557465\n",
      "iter  80 value 3500.847885\n",
      "iter  90 value 3492.802646\n",
      "iter 100 value 3459.895278\n",
      "iter 110 value 3416.238381\n",
      "iter 120 value 3394.843046\n",
      "iter 130 value 3385.703785\n",
      "iter 140 value 3372.579931\n",
      "iter 150 value 3358.605683\n",
      "iter 160 value 3349.634693\n",
      "iter 170 value 3344.373841\n",
      "iter 180 value 3339.862456\n",
      "iter 190 value 3336.871108\n",
      "iter 200 value 3334.457655\n",
      "iter 210 value 3331.205991\n",
      "iter 220 value 3329.162008\n",
      "iter 230 value 3327.976865\n",
      "iter 240 value 3326.960277\n",
      "iter 250 value 3326.343242\n",
      "iter 260 value 3325.768303\n",
      "iter 270 value 3325.269575\n",
      "iter 280 value 3324.951636\n",
      "iter 290 value 3324.795488\n",
      "iter 300 value 3324.576192\n",
      "iter 310 value 3324.379403\n",
      "iter 320 value 3324.281257\n",
      "iter 330 value 3324.206984\n",
      "iter 340 value 3324.072675\n",
      "iter 350 value 3324.000357\n",
      "iter 360 value 3323.953487\n",
      "iter 370 value 3323.902473\n",
      "iter 380 value 3323.797440\n",
      "iter 390 value 3323.653026\n",
      "final  value 3323.599991 \n",
      "converged\n"
     ]
    }
   ],
   "source": [
    "set.seed(123)\n",
    "\n",
    "compara_nodos <- comparador_RRNN(\n",
    "    datos_entrenamiento = training.data1,\n",
    "    datos_validacion = testing.data1,\n",
    "    atributos = atributos,\n",
    "    nodos = nodos,\n",
    "    iteraciones = iteraciones\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 4 × 9</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Modelos</th><th scope=col>Atributos</th><th scope=col>Nodos</th><th scope=col>Nodos_Valor</th><th scope=col>Iteraciones</th><th scope=col>Iteraciones_Valor</th><th scope=col>Exactitud</th><th scope=col>Sensibilidad</th><th scope=col>Especificidad</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Modelo 1</td><td>atributo1</td><td>nodo1</td><td>25</td><td>iteracion1</td><td>3000</td><td>0.8538</td><td>0.8240</td><td>0.8895</td></tr>\n",
       "\t<tr><td>Modelo 2</td><td>atributo2</td><td>nodo1</td><td>25</td><td>iteracion1</td><td>3000</td><td>0.8410</td><td>0.8016</td><td>0.8884</td></tr>\n",
       "\t<tr><td>Modelo 3</td><td>atributo3</td><td>nodo1</td><td>25</td><td>iteracion1</td><td>3000</td><td>0.7732</td><td>0.7879</td><td>0.7556</td></tr>\n",
       "\t<tr><td>Modelo 4</td><td>atributo4</td><td>nodo1</td><td>25</td><td>iteracion1</td><td>3000</td><td>0.7748</td><td>0.7703</td><td>0.7803</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 4 × 9\n",
       "\\begin{tabular}{lllllllll}\n",
       " Modelos & Atributos & Nodos & Nodos\\_Valor & Iteraciones & Iteraciones\\_Valor & Exactitud & Sensibilidad & Especificidad\\\\\n",
       " <chr> & <chr> & <chr> & <dbl> & <chr> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t Modelo 1 & atributo1 & nodo1 & 25 & iteracion1 & 3000 & 0.8538 & 0.8240 & 0.8895\\\\\n",
       "\t Modelo 2 & atributo2 & nodo1 & 25 & iteracion1 & 3000 & 0.8410 & 0.8016 & 0.8884\\\\\n",
       "\t Modelo 3 & atributo3 & nodo1 & 25 & iteracion1 & 3000 & 0.7732 & 0.7879 & 0.7556\\\\\n",
       "\t Modelo 4 & atributo4 & nodo1 & 25 & iteracion1 & 3000 & 0.7748 & 0.7703 & 0.7803\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 4 × 9\n",
       "\n",
       "| Modelos &lt;chr&gt; | Atributos &lt;chr&gt; | Nodos &lt;chr&gt; | Nodos_Valor &lt;dbl&gt; | Iteraciones &lt;chr&gt; | Iteraciones_Valor &lt;dbl&gt; | Exactitud &lt;dbl&gt; | Sensibilidad &lt;dbl&gt; | Especificidad &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| Modelo 1 | atributo1 | nodo1 | 25 | iteracion1 | 3000 | 0.8538 | 0.8240 | 0.8895 |\n",
       "| Modelo 2 | atributo2 | nodo1 | 25 | iteracion1 | 3000 | 0.8410 | 0.8016 | 0.8884 |\n",
       "| Modelo 3 | atributo3 | nodo1 | 25 | iteracion1 | 3000 | 0.7732 | 0.7879 | 0.7556 |\n",
       "| Modelo 4 | atributo4 | nodo1 | 25 | iteracion1 | 3000 | 0.7748 | 0.7703 | 0.7803 |\n",
       "\n"
      ],
      "text/plain": [
       "  Modelos  Atributos Nodos Nodos_Valor Iteraciones Iteraciones_Valor Exactitud\n",
       "1 Modelo 1 atributo1 nodo1 25          iteracion1  3000              0.8538   \n",
       "2 Modelo 2 atributo2 nodo1 25          iteracion1  3000              0.8410   \n",
       "3 Modelo 3 atributo3 nodo1 25          iteracion1  3000              0.7732   \n",
       "4 Modelo 4 atributo4 nodo1 25          iteracion1  3000              0.7748   \n",
       "  Sensibilidad Especificidad\n",
       "1 0.8240       0.8895       \n",
       "2 0.8016       0.8884       \n",
       "3 0.7879       0.7556       \n",
       "4 0.7703       0.7803       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compara_nodos$Nodos <- as.factor(compara_nodos$Nodos)\n",
    "compara_nodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAIAAAByhViMAAAACXBIWXMAABJ0AAASdAHeZh94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\nAAAsgWAHAAAAwBL/Bw+o4iTyq7onAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(compara_nodos, mapping = aes(x = Atributos, group = 1)) +\n",
    "    geom_line(mapping = aes(y = Exactitud), colour = \"red\") +\n",
    "    geom_line(mapping = aes(y = Sensibilidad), colour = \"green\") +\n",
    "    geom_line(mapping = aes(y = Especificidad), colour = \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 17 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Atributos</th><th scope=col>Nodos</th><th scope=col>Iteraciones</th><th scope=col>Exactitud</th><th scope=col>Sensibilidad</th><th scope=col>Especificidad</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>11</th><td>atributo1</td><td>nodo3</td><td>iteracion3</td><td>0.5459</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>17</th><td>atributo2</td><td>nodo1</td><td>iteracion1</td><td>0.5459</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>18</th><td>atributo2</td><td>nodo1</td><td>iteracion2</td><td>0.5459</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>19</th><td>atributo2</td><td>nodo1</td><td>iteracion3</td><td>0.5459</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>20</th><td>atributo2</td><td>nodo1</td><td>iteracion4</td><td>0.5459</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>21</th><td>atributo2</td><td>nodo2</td><td>iteracion1</td><td>0.5459</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>22</th><td>atributo2</td><td>nodo2</td><td>iteracion2</td><td>0.5459</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>23</th><td>atributo2</td><td>nodo2</td><td>iteracion3</td><td>0.5459</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>24</th><td>atributo2</td><td>nodo2</td><td>iteracion4</td><td>0.5459</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>25</th><td>atributo2</td><td>nodo3</td><td>iteracion1</td><td>0.5459</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>26</th><td>atributo2</td><td>nodo3</td><td>iteracion2</td><td>0.5459</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>27</th><td>atributo2</td><td>nodo3</td><td>iteracion3</td><td>0.5459</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>28</th><td>atributo2</td><td>nodo3</td><td>iteracion4</td><td>0.5459</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>29</th><td>atributo2</td><td>nodo4</td><td>iteracion1</td><td>0.5459</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>30</th><td>atributo2</td><td>nodo4</td><td>iteracion2</td><td>0.5459</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>31</th><td>atributo2</td><td>nodo4</td><td>iteracion3</td><td>0.5459</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>32</th><td>atributo2</td><td>nodo4</td><td>iteracion4</td><td>0.5459</td><td>1</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 17 × 6\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & Atributos & Nodos & Iteraciones & Exactitud & Sensibilidad & Especificidad\\\\\n",
       "  & <chr> & <chr> & <chr> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t11 & atributo1 & nodo3 & iteracion3 & 0.5459 & 1 & 0\\\\\n",
       "\t17 & atributo2 & nodo1 & iteracion1 & 0.5459 & 1 & 0\\\\\n",
       "\t18 & atributo2 & nodo1 & iteracion2 & 0.5459 & 1 & 0\\\\\n",
       "\t19 & atributo2 & nodo1 & iteracion3 & 0.5459 & 1 & 0\\\\\n",
       "\t20 & atributo2 & nodo1 & iteracion4 & 0.5459 & 1 & 0\\\\\n",
       "\t21 & atributo2 & nodo2 & iteracion1 & 0.5459 & 1 & 0\\\\\n",
       "\t22 & atributo2 & nodo2 & iteracion2 & 0.5459 & 1 & 0\\\\\n",
       "\t23 & atributo2 & nodo2 & iteracion3 & 0.5459 & 1 & 0\\\\\n",
       "\t24 & atributo2 & nodo2 & iteracion4 & 0.5459 & 1 & 0\\\\\n",
       "\t25 & atributo2 & nodo3 & iteracion1 & 0.5459 & 1 & 0\\\\\n",
       "\t26 & atributo2 & nodo3 & iteracion2 & 0.5459 & 1 & 0\\\\\n",
       "\t27 & atributo2 & nodo3 & iteracion3 & 0.5459 & 1 & 0\\\\\n",
       "\t28 & atributo2 & nodo3 & iteracion4 & 0.5459 & 1 & 0\\\\\n",
       "\t29 & atributo2 & nodo4 & iteracion1 & 0.5459 & 1 & 0\\\\\n",
       "\t30 & atributo2 & nodo4 & iteracion2 & 0.5459 & 1 & 0\\\\\n",
       "\t31 & atributo2 & nodo4 & iteracion3 & 0.5459 & 1 & 0\\\\\n",
       "\t32 & atributo2 & nodo4 & iteracion4 & 0.5459 & 1 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 17 × 6\n",
       "\n",
       "| <!--/--> | Atributos &lt;chr&gt; | Nodos &lt;chr&gt; | Iteraciones &lt;chr&gt; | Exactitud &lt;dbl&gt; | Sensibilidad &lt;dbl&gt; | Especificidad &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 11 | atributo1 | nodo3 | iteracion3 | 0.5459 | 1 | 0 |\n",
       "| 17 | atributo2 | nodo1 | iteracion1 | 0.5459 | 1 | 0 |\n",
       "| 18 | atributo2 | nodo1 | iteracion2 | 0.5459 | 1 | 0 |\n",
       "| 19 | atributo2 | nodo1 | iteracion3 | 0.5459 | 1 | 0 |\n",
       "| 20 | atributo2 | nodo1 | iteracion4 | 0.5459 | 1 | 0 |\n",
       "| 21 | atributo2 | nodo2 | iteracion1 | 0.5459 | 1 | 0 |\n",
       "| 22 | atributo2 | nodo2 | iteracion2 | 0.5459 | 1 | 0 |\n",
       "| 23 | atributo2 | nodo2 | iteracion3 | 0.5459 | 1 | 0 |\n",
       "| 24 | atributo2 | nodo2 | iteracion4 | 0.5459 | 1 | 0 |\n",
       "| 25 | atributo2 | nodo3 | iteracion1 | 0.5459 | 1 | 0 |\n",
       "| 26 | atributo2 | nodo3 | iteracion2 | 0.5459 | 1 | 0 |\n",
       "| 27 | atributo2 | nodo3 | iteracion3 | 0.5459 | 1 | 0 |\n",
       "| 28 | atributo2 | nodo3 | iteracion4 | 0.5459 | 1 | 0 |\n",
       "| 29 | atributo2 | nodo4 | iteracion1 | 0.5459 | 1 | 0 |\n",
       "| 30 | atributo2 | nodo4 | iteracion2 | 0.5459 | 1 | 0 |\n",
       "| 31 | atributo2 | nodo4 | iteracion3 | 0.5459 | 1 | 0 |\n",
       "| 32 | atributo2 | nodo4 | iteracion4 | 0.5459 | 1 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "   Atributos Nodos Iteraciones Exactitud Sensibilidad Especificidad\n",
       "11 atributo1 nodo3 iteracion3  0.5459    1            0            \n",
       "17 atributo2 nodo1 iteracion1  0.5459    1            0            \n",
       "18 atributo2 nodo1 iteracion2  0.5459    1            0            \n",
       "19 atributo2 nodo1 iteracion3  0.5459    1            0            \n",
       "20 atributo2 nodo1 iteracion4  0.5459    1            0            \n",
       "21 atributo2 nodo2 iteracion1  0.5459    1            0            \n",
       "22 atributo2 nodo2 iteracion2  0.5459    1            0            \n",
       "23 atributo2 nodo2 iteracion3  0.5459    1            0            \n",
       "24 atributo2 nodo2 iteracion4  0.5459    1            0            \n",
       "25 atributo2 nodo3 iteracion1  0.5459    1            0            \n",
       "26 atributo2 nodo3 iteracion2  0.5459    1            0            \n",
       "27 atributo2 nodo3 iteracion3  0.5459    1            0            \n",
       "28 atributo2 nodo3 iteracion4  0.5459    1            0            \n",
       "29 atributo2 nodo4 iteracion1  0.5459    1            0            \n",
       "30 atributo2 nodo4 iteracion2  0.5459    1            0            \n",
       "31 atributo2 nodo4 iteracion3  0.5459    1            0            \n",
       "32 atributo2 nodo4 iteracion4  0.5459    1            0            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataframe_final[dataframe_final$Sensibilidad == 1 | dataframe_final$Especificidad == 1, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# weights:  806\n",
      "initial  value 5953.492023 \n",
      "final  value 5162.944800 \n",
      "converged\n",
      "Niveles de la predicción: no \n",
      "Niveles de la observación: no yes \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in confusionMatrix.default(data = as.factor(prediccion_RN_rara), :\n",
      "“Levels are not in the same order for reference and data. Refactoring data to match.”\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction   no  yes\n",
       "       no  1023  851\n",
       "       yes    0    0\n",
       "                                         \n",
       "               Accuracy : 0.5459         \n",
       "                 95% CI : (0.523, 0.5686)\n",
       "    No Information Rate : 0.5459         \n",
       "    P-Value [Acc > NIR] : 0.5095         \n",
       "                                         \n",
       "                  Kappa : 0              \n",
       "                                         \n",
       " Mcnemar's Test P-Value : <2e-16         \n",
       "                                         \n",
       "            Sensitivity : 1.0000         \n",
       "            Specificity : 0.0000         \n",
       "         Pos Pred Value : 0.5459         \n",
       "         Neg Pred Value :    NaN         \n",
       "             Prevalence : 0.5459         \n",
       "         Detection Rate : 0.5459         \n",
       "   Detection Prevalence : 1.0000         \n",
       "      Balanced Accuracy : 0.5000         \n",
       "                                         \n",
       "       'Positive' Class : no             \n",
       "                                         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Análisis de modelos raros\n",
    "\n",
    "modelo_RN_raro <- nnet(\n",
    "    atributos[[2]], data = datos_entrenamiento, MaxNWts = 10000,\n",
    "    size = nodos[[3]], maxit = iteraciones[[3]]\n",
    ")\n",
    "prediccion_RN_rara <- predict(modelo_RN_raro, datos_validacion, type=\"class\")\n",
    "cat(\"Niveles de la predicción:\", levels(as.factor(prediccion_RN_rara)), \"\\n\")\n",
    "cat(\"Niveles de la observación:\", levels(as.factor(datos_validacion$OK)), \"\\n\")\n",
    "matriz_rara <- confusionMatrix(data = as.factor(prediccion_RN_rara), reference = as.factor(datos_validacion$OK), positive = \"no\")\n",
    "matriz_rara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEKlHstgEOG1"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Complemento: Ejercicio de comprobación manual**\n",
    "\n",
    "\n",
    "Para verificar que alguno de los modelos realmente predice correctamente, se comprueba con los datos de una persona en particular, pidiendo la predicción al modelo. A continuación hay dos ejemplos, que se pueden modificar para ver su resultado, cambiando valores y también, cambiando el modelo a utilizar en la predicción. No se necesita modificar, ni comentar esta parte en la entrega, sino que se entrega como complemento para quienes tengan el interés de ver cómo se aplica un modelo entrenado en un contexto práctico (en producción)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "tZaYo2bG58aA",
    "outputId": "8532b716-9725-462a-f68f-eca35b8465d9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 1 × 17</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Edad</th><th scope=col>Ocupación</th><th scope=col>EstadoCivil</th><th scope=col>Educación</th><th scope=col>Hipotecario</th><th scope=col>Consumo</th><th scope=col>Contacto</th><th scope=col>Mes</th><th scope=col>Día</th><th scope=col>Duración</th><th scope=col>NumContactos</th><th scope=col>ResultadoPrevio</th><th scope=col>EmpTasaVar</th><th scope=col>IPC</th><th scope=col>ICC</th><th scope=col>NumEmpleados</th><th scope=col>OK</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>76</th><td>32</td><td>admin.</td><td>single</td><td>university.degree</td><td>yes</td><td>no</td><td>telephone</td><td>may</td><td>mon</td><td>1575</td><td>1</td><td>nonexistent</td><td>1.1</td><td>93.994</td><td>-36.4</td><td>5191</td><td>yes</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 17\n",
       "\\begin{tabular}{r|lllllllllllllllll}\n",
       "  & Edad & Ocupación & EstadoCivil & Educación & Hipotecario & Consumo & Contacto & Mes & Día & Duración & NumContactos & ResultadoPrevio & EmpTasaVar & IPC & ICC & NumEmpleados & OK\\\\\n",
       "  & <dbl> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <int> & <int> & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t76 & 32 & admin. & single & university.degree & yes & no & telephone & may & mon & 1575 & 1 & nonexistent & 1.1 & 93.994 & -36.4 & 5191 & yes\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 17\n",
       "\n",
       "| <!--/--> | Edad &lt;dbl&gt; | Ocupación &lt;chr&gt; | EstadoCivil &lt;chr&gt; | Educación &lt;chr&gt; | Hipotecario &lt;chr&gt; | Consumo &lt;chr&gt; | Contacto &lt;chr&gt; | Mes &lt;chr&gt; | Día &lt;chr&gt; | Duración &lt;int&gt; | NumContactos &lt;int&gt; | ResultadoPrevio &lt;chr&gt; | EmpTasaVar &lt;dbl&gt; | IPC &lt;dbl&gt; | ICC &lt;dbl&gt; | NumEmpleados &lt;dbl&gt; | OK &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 76 | 32 | admin. | single | university.degree | yes | no | telephone | may | mon | 1575 | 1 | nonexistent | 1.1 | 93.994 | -36.4 | 5191 | yes |\n",
       "\n"
      ],
      "text/plain": [
       "   Edad Ocupación EstadoCivil Educación         Hipotecario Consumo Contacto \n",
       "76 32   admin.    single      university.degree yes         no      telephone\n",
       "   Mes Día Duración NumContactos ResultadoPrevio EmpTasaVar IPC    ICC  \n",
       "76 may mon 1575     1            nonexistent     1.1        93.994 -36.4\n",
       "   NumEmpleados OK \n",
       "76 5191         yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>76:</strong> yes\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<style>\n",
       "\t.list-inline {list-style: none; margin:0; padding: 0}\n",
       "\t.list-inline>li {display: inline-block}\n",
       "\t.list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "\t</style>\n",
       "\t<ol class=list-inline><li>'no'</li><li>'yes'</li></ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\textbf{76:} yes\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item 'no'\n",
       "\\item 'yes'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "**76:** yes\n",
       "**Levels**: 1. 'no'\n",
       "2. 'yes'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " 76 \n",
       "yes \n",
       "Levels: no yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 1 × 17</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Edad</th><th scope=col>Ocupación</th><th scope=col>EstadoCivil</th><th scope=col>Educación</th><th scope=col>Hipotecario</th><th scope=col>Consumo</th><th scope=col>Contacto</th><th scope=col>Mes</th><th scope=col>Día</th><th scope=col>Duración</th><th scope=col>NumContactos</th><th scope=col>ResultadoPrevio</th><th scope=col>EmpTasaVar</th><th scope=col>IPC</th><th scope=col>ICC</th><th scope=col>NumEmpleados</th><th scope=col>OK</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>76</th><td>41</td><td>blue-collar</td><td>divorced</td><td>basic.4y</td><td>yes</td><td>no</td><td>telephone</td><td>may</td><td>mon</td><td>10</td><td>1</td><td>nonexistent</td><td>1.1</td><td>93.994</td><td>-36.4</td><td>5191</td><td>yes</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 17\n",
       "\\begin{tabular}{r|lllllllllllllllll}\n",
       "  & Edad & Ocupación & EstadoCivil & Educación & Hipotecario & Consumo & Contacto & Mes & Día & Duración & NumContactos & ResultadoPrevio & EmpTasaVar & IPC & ICC & NumEmpleados & OK\\\\\n",
       "  & <int> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <dbl> & <int> & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t76 & 41 & blue-collar & divorced & basic.4y & yes & no & telephone & may & mon & 10 & 1 & nonexistent & 1.1 & 93.994 & -36.4 & 5191 & yes\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 17\n",
       "\n",
       "| <!--/--> | Edad &lt;int&gt; | Ocupación &lt;chr&gt; | EstadoCivil &lt;chr&gt; | Educación &lt;chr&gt; | Hipotecario &lt;chr&gt; | Consumo &lt;chr&gt; | Contacto &lt;chr&gt; | Mes &lt;chr&gt; | Día &lt;chr&gt; | Duración &lt;dbl&gt; | NumContactos &lt;int&gt; | ResultadoPrevio &lt;chr&gt; | EmpTasaVar &lt;dbl&gt; | IPC &lt;dbl&gt; | ICC &lt;dbl&gt; | NumEmpleados &lt;dbl&gt; | OK &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 76 | 41 | blue-collar | divorced | basic.4y | yes | no | telephone | may | mon | 10 | 1 | nonexistent | 1.1 | 93.994 | -36.4 | 5191 | yes |\n",
       "\n"
      ],
      "text/plain": [
       "   Edad Ocupación   EstadoCivil Educación Hipotecario Consumo Contacto  Mes Día\n",
       "76 41   blue-collar divorced    basic.4y  yes         no      telephone may mon\n",
       "   Duración NumContactos ResultadoPrevio EmpTasaVar IPC    ICC   NumEmpleados\n",
       "76 10       1            nonexistent     1.1        93.994 -36.4 5191        \n",
       "   OK \n",
       "76 yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>76:</strong> no\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<style>\n",
       "\t.list-inline {list-style: none; margin:0; padding: 0}\n",
       "\t.list-inline>li {display: inline-block}\n",
       "\t.list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "\t</style>\n",
       "\t<ol class=list-inline><li>'no'</li><li>'yes'</li></ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\textbf{76:} no\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item 'no'\n",
       "\\item 'yes'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "**76:** no\n",
       "**Levels**: 1. 'no'\n",
       "2. 'yes'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "76 \n",
       "no \n",
       "Levels: no yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ejemplo 1: La predicción debería ser \"YES\"\n",
    "set.seed(123)\n",
    "sample_x <- clean.subdata[1,]\n",
    "sample_x[1,1] <- 32       # Edad\n",
    "sample_x[1,2] <- 'admin.' # Ocupación\n",
    "sample_x[1,3] <- 'single' # EstadoCivil\n",
    "sample_x[1,4] <- 'university.degree'  # Educación\n",
    "sample_x\n",
    "\n",
    "prediction <- predict(RF_model, sample_x)\n",
    "prediction\n",
    "\n",
    "\n",
    "# Ejemplo 2: La predicción debería ser \"NO\"\n",
    "sample_x2 <- clean.subdata[1,]\n",
    "sample_x2[1,10] <- 10   # Duración\n",
    "sample_x2\n",
    "\n",
    "prediction <- predict(RF_model, sample_x2)\n",
    "prediction\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
