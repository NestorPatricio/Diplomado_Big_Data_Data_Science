{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.3.1"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BhFF63rsMfbI"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEA4r6FfIRE5"
      },
      "source": [
        "# Ejercicio 1 - Mejoras en el Desempeño de Modelos de Clasificación\n",
        "\n",
        "Este ejercicio se centra en el entrenamiento y evaluación de algunos modelos modelos de clasificación, sobre un conjunto de datos de campañas de marketing de productos bancarios, aplicando algunas estrategias de mejora del rendimiento de los modelos. Al considerar técnicas previas a los modelos se busca demostrar que el desempeño de éstos depende fuertemente del pre-procesamiento de los datos, más que un afinamiento de sus parámetros.\n",
        "\n",
        "## Contexto: Análisis de éxito en campaña de marketing\n",
        "\n",
        "Fuente: https://archive.ics.uci.edu/ml/datasets/Bank+Marketing\n",
        "\n",
        "El *dataset* para este ejercicio contiene resultados de personas contactadas por una campaña de marketing y que compraron la oferta (atributo \"OK\" = yes o no), con cerca de 41.200 registros de personas.\n",
        "\n",
        "Este conjunto de datos (abierto para este tipo de usos instruccionales), consiste en 20 atributos y 1 clase de etiquetas (totalizando 21 columnas) y corresponde a los datos de una campaña telefónica en Portugal, ofreciéndoles la contratación de un depósito a plazo. En varios casos, un cliente fue contactado varias veces antes de aceptar (OK = yes).\n",
        "\n",
        "Algunos de los atributos relevantes son (combinando atributos categóricos, con numéricos):\n",
        "* **Datos personales**: Edad, Ocupación, Estado Civil, Nivel de Educación.\n",
        "* **Datos financieros**: Su casa tiene crédito hipotecario, default: si el crédito ha caído en quiebra; tiene un crédito de consumo.\n",
        "* **Datos de contactos de la campaña actual**: Tipo de Comunicación (celular o teléfono fijo); Mes del último contacto; Día de la semana del contacto; duración de la llamada (segundos); Contacto: N° de contactos durante la campaña; DíasAtrás: días transcurridos desde último contacto; Resultado: resultado de la última llamada (falló, no-existe, éxito)\n",
        "* **Datos socioeconómicos**: EmpTasaVar: tasa de variación de empleabilidad; IPC: índice de precios consumidor mensual; ICC: índice de confianza consumidor mensual; Euribor3m: tasa euribor de 3 meses indicador diario; NumEmpleados: cantidad de gente empleada, en indicador trimestral.\n",
        "\n",
        "Esta adaptación en particular, por Rodrigo Sandoval y el equipo de R:Solver (RSolver.com), enfrenta diferentes objetivos de aprendizaje dentro de los cursos de Big Data y Machine Learning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhFF63rsMfbI"
      },
      "source": [
        "## Instrucciones Generales\n",
        "En este caso, se busca entender el comportamiento y desempeño de diferentes modelos de clasificación sobre este conjunto de datos, para predecir la variable de interés: **OK**, que servirá para predecir en casos futuros, según los datos de contactabilidad de un cliente, si el cliente aceptará o no contratar el depósito a plazo.\n",
        "\n",
        "Todos los alumnos deben contestar las preguntas que se indican en las secciones de \"Preguntas\", más adelante, las que se enfocan en tareas de pre-procesamiento del conjunto de datos, para lograr mejoras en el desempeño del modelo de predicción categórica. Se puede recurrir a ejercicios de otras fuentes, así como al material de clases. Deben entregar un informe simple (de 1 ó 2 páginas) en formato PDF solamente, en el que se incluyen los nombres de los integrantes ordenados alfabéticamente por apellido dentro de la primera página.\n",
        "\n",
        "La plantilla de informe está en http://dcc.rsolver.com/dcc/docs/InformeActividad.docx\n",
        "\n",
        "El informe en formato PDF debe ser subido por sólo uno de los integrantes a la siguiente URL\n",
        "\n",
        "http://aiker.rsolver.com/aiker/DocUpload.aspx (*)\n",
        "\n",
        "(*) Sólo si hay problemas en la carga, enviar el PDF a rsandova@ing.puc.cl y cc: ayudante@aiker.ai, pero no se requiere como respaldo de la entrega."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbsvny1wYwsT"
      },
      "source": [
        "## Paso 1: Instalación de las librerías de modelos de clasificación\n",
        "\n",
        "Esto se ejecuta sólo una vez al comienzo de la sesión de cada persona. No se necesita volver a ejecutar con cada nueva prueba del resto de los scripts o bloques."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr8D6ajXY2T9"
      },
      "source": [
        "install.packages('e1071')\n",
        "install.packages('caret')\n",
        "install.packages('rpart')\n",
        "install.packages('rpart.plot')\n",
        "install.packages('randomForest')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q3bYb0RM5bx"
      },
      "source": [
        "## Paso 2: Carga de los datos\n",
        "\n",
        "En este bloque se cargan los datos desde la URL de origen y luego muestra un encabezado con las primeras filas del dataset, para demostrar la disponibilidad de los datos.\n",
        "\n",
        "Esto también puede ser ejecutado una sola vez, o volver a ejecutar cuando nuevamente se necesite trabajar con los datos originales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIIKPnj-IRE8"
      },
      "source": [
        "# Se declara la URL de dónde obtener los datos\n",
        "theUrlMain <- \"http://www.rsolver.com/dcc/docs/bank-additional-full.csv\"\n",
        "\n",
        "# Se declaran los nombres de las columnas\n",
        "columnas = c(\"Edad\",\"Ocupación\",\"EstadoCivil\",\"Educación\",\"Default\",\"Hipotecario\",\"Consumo\",\"Contacto\",\"Mes\",\"Día\",\n",
        "             \"Duración\",\"NumContactos\",\"DíasAtrás\",\"Previo\",\"ResultadoPrevio\", \"EmpTasaVar\", \"IPC\", \"ICC\", \"Euribor3m\", \"NumEmpleados\", \"OK\")\n",
        "\n",
        "# Se cargan datos principales a una estructura (marketing.data), asignando nombres de atributos a las columnas.\n",
        "# Nótese que se incluye la conversión de valores \"unknown\" a \"NA\" para facilitar la gestión vacíos más adelante.\n",
        "marketing.data <- read.table(file = theUrlMain, header = TRUE, sep = \";\", col.names = columnas, na.strings=c(\"unknown\",\"NA\"))\n",
        "\n",
        "# Se muestran las primeras líneas del dataset, incluyendo nombres asignados a las columnas.\n",
        "# Nótese que ya no hay \"unknown\", sino que sólo \"NA\", lo que permite a las operaciones is.na() y na.omit() operar fácilmente\n",
        "head(marketing.data, 20)\n",
        "dim(marketing.data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ihz_3Pj9n_lu"
      },
      "source": [
        "## Paso 3: Complemento de Clasificación Inicial\n",
        "\n",
        "A continuación se implementa un proceso de clasificación inicial, sin alterar el conjunto de ejemplos y teniendo una proporción genérica de hold-out, con 60% de ejemplos para entrenamiento y 40% de ejemplos para evaluación. Se termina ejecutando un Decision Tree, mostrando sus indicadores de desempeño.\n",
        "\n",
        "Esta ejecución de un modelo inicial sirve de comparación, evaluando cuánto influyen las mejoras al dataset y entrenamiento, que son parte de los ejercicios, en el desempeño de otros modelos más adelante.\n",
        "\n",
        "**Análisis del desempeño del modelo de referencia**\n",
        "\n",
        "Nótese que se muestra el desempeño del modelo con los datos de entrenamiento y a continuación con los datos de evaluación. Dentro de lo esperable, el accuracy para el conjunto entrenamiento tiende a ser levemente mejor.\n",
        "\n",
        "Adicionalmente, se puede ver que el sensitivity (desempeño de la clase positiva o \"yes\") es notoriamente menor que el specificity, lo que evidencia un sobreajuste a responder \"no\" de parte del modelo, que se interpreta como una limitación o desempeño deficiente, que se espera poder mejorar.\n",
        "\n",
        "Finalmente, el gráfico del Árbol de Decisión muestra que, de todos los atributos del dataset, los dos más significativos para armar las reglas de decisión de este Árbol de Decisión, son \"NumEmpleados\", \"Duración\" y \"DíasAtrás\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFf68LhyoGkZ"
      },
      "source": [
        "# Primero se separa el conjunto de ejemplos (marketing.data) en 2,\n",
        "# uno de entrenamiento y otro de evaluación usando la técnica hold-out,\n",
        "# que consiste en crear dos conjuntos disjuntos en una proporción dada\n",
        "\n",
        "ratio = sample(1:nrow(marketing.data), size = 0.60*nrow(marketing.data)) # Proporción: 60% / 40%\n",
        "training.data = marketing.data[ratio,]\n",
        "testing.data = marketing.data[-ratio,]\n",
        "\n",
        "# Se muestra la cantidad de ejemplos de cada uno de los dos conjuntos (en la proporción indicada)\n",
        "dim(training.data)\n",
        "dim(testing.data)\n",
        "\n",
        "# Luego se entrena un modelo de clasificación Decision Tree usando el conjunto Train\n",
        "# y posteriormente se evalúa con predict() para obtener los indicadores de desempeño\n",
        "\n",
        "library(caret)\n",
        "library(rpart)\n",
        "library(rpart.plot)\n",
        "\n",
        "# Decision Tree\n",
        "DT_model <- rpart(as.factor(OK) ~ ., data=training.data, method=\"class\", minbucket=10)\n",
        "\n",
        "cat(\"\\n****Desempeño Decision Tree en conjunto de entrenamiento****\\n\")\n",
        "DT_predict_train <- predict(DT_model, training.data, type = \"class\")\n",
        "confusionMatrix(DT_predict_train, as.factor(training.data$OK), positive=\"yes\")\n",
        "\n",
        "cat(\"\\n---------------------------------------------------------\\n\")\n",
        "cat(\"\\n****Desempeño Decision Tree en conjunto de evaluación****\\n\")\n",
        "DT_predict_test <- predict(DT_model, testing.data, type = \"class\")\n",
        "confusionMatrix(DT_predict_test, as.factor(testing.data$OK), positive=\"yes\")\n",
        "rpart.plot(DT_model)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX9lYmofTUJx"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Ejercicio: Limpieza, balanceo de datos y preparación conjuntos de entrenamiento y evaluación\n",
        "\n",
        "El siguiente código prepara los datos para el entrenamiento y evaluación, realizando algunas operaciones de limpieza de datos y balanceo entre clases. Hay diferentes elementos de análisis y acciones de mejora del dataset, entre los que se incluye (pero no reduce a):\n",
        "\n",
        "*   Ya incluido: eliminación de los registros incompletos (que tienen un 'NA' en alguna columna) con na.omit(). Pero adicionalmente se puede optar por lo siguiente.\n",
        "*   (A) **Eliminar algunas columnas**, considerando aquellas que tengan datos de bajo aporte o interés, o cuya distribución de valores sea irregular, lo que llevaría a un modelo a dar predicciones ruidosas. (Como referencia de análisis de posibles columnas candidatas a ser eliminadas, observe el caso de DíasAtrás = 999, que se define como el \"valor nulo\", que implica que no se ha hecho contacto anteriormente).\n",
        "*   (B) **Balance entre clases**, considerando que el dataset original tiene una gran proporción de clientes que NO compraron, a diferencia de los que SI, se incluye una variable balance_ratio, donde 1.0 implica igualar la cantidad de ejemplos de NO y SI, mientras que agrandar ese valor implica agrandar la cantidad de ejemplos NO por sobre los YES. Nótese que este balance es sólo relevante para el conjunto de entrenamiento y no para el de evaluación o test.\n",
        "\n",
        "**Pregunta 1**  (1 punto): En (A) ¿cuáles columnas se eliminaron logrando mejorar el desempeño de los modelos? (Considere al menos 2)\n",
        "\n",
        "**Pregunta 2**  (2 puntos): En (B) ¿qué proporción (Probar: 0.8, 0.9, 1.0, 1.2, 1.5) de ejemplos NO/YES se eligió y por qué? Entonces, ¿de qué dimensiones quedó el dataset de entrenamiento modificado?\n",
        "\n",
        "Al contestar incluya una tabla de ejecuciones comparadas, para demostrar que su decisión está basada en resultados de evidencia.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLCP0L1mv5pT"
      },
      "source": [
        "# Primero, se eliminan los registros que tienen algún NA (antes: 'unknown')\n",
        "marketing.clean <- na.omit(marketing.data)\n",
        "dim(marketing.clean) # Sólo quedan poco más de 30.000 filas (de las 41.000 originales)\n",
        "\n",
        "\n",
        "# (A) ¿Cuáles columnas se pueden eliminar para mejorar la calidad de los datos? (Consider al menos 2)\n",
        "# Se elimina columnas con la siguiente instrucción de ejemplo:\n",
        "# marketing.clean$ICC <- NULL\n",
        "\n",
        "\n",
        "dim(marketing.clean)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtDvRkkmpJIS"
      },
      "source": [
        "# Aquí se arman dos subconjuntos con los datos de cada una de las dos clases.\n",
        "# Se pueden ver los respectivos tamaños al terminar, evidenciando un desbalance.\n",
        "clean.data.YES <- marketing.clean[marketing.clean$OK == 'yes',]\n",
        "clean.data.NO <- marketing.clean[marketing.clean$OK == 'no',]\n",
        "dim(clean.data.YES) # Se ve que este es el conjunto más pequeño\n",
        "dim(clean.data.NO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-mX7rVWoOK_"
      },
      "source": [
        "# (B) Se balancean las clases para entrenar: se busca acercar la cantidad de ejemplos positivos, con los negativos.\n",
        "# Para esto se puede definir la cantidad de ejemplos de la clase más abundante (NO)\n",
        "# en una proporción (balance_ratio) de la cantidad de registros de la clase menos abundante (YES)\n",
        "# balance_ratio = 1.0 implica la misma cantidad para NO y para YES ¿Cuál es la mejor? (Probar: 0.8, 0.9, 1.0, 1.2, 1.5)\n",
        "balance_ratio <- 1.0\n",
        "\n",
        "clean.subdata.YES <- clean.data.YES  # No se aplica sample(): se usan todos los ejemplos de la clase OK (que es la que tiene menos ejemplos)\n",
        "clean.subdata.NO <- clean.data.NO[sample(nrow(clean.data.NO), balance_ratio*dim(clean.data.YES)[1]), ]\n",
        "\n",
        "# Muestra cantidad de ejemplos contenidos en cada subconjunto\n",
        "dim(clean.subdata.YES)\n",
        "dim(clean.subdata.NO)\n",
        "\n",
        "# Se juntan para el conjunto de referencia, ahora más balanceado\n",
        "clean.subdata <- rbind(clean.subdata.YES, clean.subdata.NO)\n",
        "\n",
        "# Ahora se configuran los conjuntos de entrenamiento y testing en una proporción\n",
        "# (por ej: 0.85 = 85% para training y el resto para evaluación o testing)\n",
        "ratio = sample(1:nrow(clean.subdata), size = 0.85*nrow(clean.subdata))\n",
        "training.data = clean.subdata[ratio,]\n",
        "testing.data = clean.subdata[-ratio,]\n",
        "\n",
        "# Se comparan los tamaños de ejemplos para entrenamiento y evaluación.\n",
        "dim(training.data)\n",
        "dim(testing.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82LcskQOnNmH"
      },
      "source": [
        "## Complemento: Implementación de un modelo Random Forest para comparar\n",
        "\n",
        "Esta sección implementa un Random Forest, como modelo de clasificación de referencia, cuyo desempeño será comparado con el Árbol de Decisión anterior, que no tuvo aplicación de las mejoras al dataset del ejercicio anterior.\n",
        "\n",
        "**Pregunta 3** (1,5 puntos): Si se compara con el desempeño del Árbol de Decisión en el paso 3 anterior ¿Qué diferencia fundamental (ventaja/desventaja) se ve en los indicadores de desempeño y por qué se podría haber logrado esta diferencia?\n",
        "\n",
        "**Pregunta 4** (1,5 puntos): Al comparar el desempeño del modelo con los datos de entrenamiento y con los datos de evaluación, se puede ver una diferencia importante. ¿Cómo se interpreta esta diferencia y, en teoría, cómo se podría resolver?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM91HnJqh7D6"
      },
      "source": [
        "**Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUkbhaJ0CGDm"
      },
      "source": [
        "library(randomForest)\n",
        "library(caret)\n",
        "\n",
        "# Random Forest\n",
        "RF_model <- randomForest(as.factor(OK) ~ ., data=training.data, method=\"class\")\n",
        "\n",
        "cat(\"\\n****Desempeño Random Forest en conjunto de entrenamiento****\\n\")\n",
        "RF_predict_train <- predict(RF_model, training.data, type = \"class\")\n",
        "confusionMatrix(RF_predict_train, as.factor(training.data$OK), positive=\"yes\")\n",
        "\n",
        "cat(\"\\n---------------------------------------------------------\\n\")\n",
        "cat(\"\\n****Desempeño Random Forest en conjunto de evaluación****\\n\")\n",
        "RF_predict <- predict(RF_model, testing.data, type = \"class\")\n",
        "confusionMatrix(RF_predict, as.factor(testing.data$OK), positive=\"yes\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5qIup56Sdrp"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "**Complemento: Ejercicio de comprobación manual**\n",
        "\n",
        "\n",
        "Para verificar que alguno de los modelos realmente predice correctamente, se comprueba con los datos de una persona en particular, pidiendo la predicción al modelo. A continuación hay dos ejemplos, que se pueden modificar para ver su resultado, cambiando valores y también, cambiando el modelo a utilizar en la predicción. No se necesita modificar, ni comentar esta parte en la entrega."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilmHuN-1SmXY"
      },
      "source": [
        "# Ejemplo 1: La predicción debería ser \"YES\"\n",
        "sample_x <- clean.subdata[1,]\n",
        "sample_x[1,1] <- 32       # Edad\n",
        "sample_x[1,2] <- 'admin.' # Ocupación\n",
        "sample_x[1,3] <- 'single' # EstadoCivil\n",
        "sample_x[1,4] <- 'university.degree'  # Educación\n",
        "sample_x\n",
        "\n",
        "prediction <- predict(RF_model, sample_x)\n",
        "prediction\n",
        "\n",
        "\n",
        "# Ejemplo 2: La predicción debería ser \"NO\"\n",
        "sample_x2 <- clean.subdata[1,]\n",
        "sample_x2[1,1] <- 42\n",
        "sample_x2[1,11] <- 10   # Duración\n",
        "sample_x2[1,19] <- 5000  # NumEmpleados\n",
        "sample_x2\n",
        "\n",
        "prediction <- predict(RF_model, sample_x2)\n",
        "prediction\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}